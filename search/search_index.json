{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"CovidRt.jl \u00b6 CovidRt.CovidRt CovidRt.lagdiff CovidRt.smooth # CovidRt.CovidRt \u2014 Module . module CovidRt Compute time and area specific estimates of the reproductive number of Covid. source # CovidRt.lagdiff \u2014 Function . function lagdiff(x::AbstractVector, d=1) Returns out[i] = x[i] - x[i-d] with out padded with missings so that length(out)==length(x) . source # CovidRt.smooth \u2014 Method . function smooth(x::AbstractVector; w=pdf(Normal(), range(-3, 3, length=7))) Returns the running weighted mean of x*w. When n=length(w) , then out[i] = sum(x[i - n\u00f72 + j-1] * w[j] for j in 1:n)/sum(w) . source","title":"Package Docs"},{"location":"#covidrtjl","text":"CovidRt.CovidRt CovidRt.lagdiff CovidRt.smooth # CovidRt.CovidRt \u2014 Module . module CovidRt Compute time and area specific estimates of the reproductive number of Covid. source # CovidRt.lagdiff \u2014 Function . function lagdiff(x::AbstractVector, d=1) Returns out[i] = x[i] - x[i-d] with out padded with missings so that length(out)==length(x) . source # CovidRt.smooth \u2014 Method . function smooth(x::AbstractVector; w=pdf(Normal(), range(-3, 3, length=7))) Returns the running weighted mean of x*w. When n=length(w) , then out[i] = sum(x[i - n\u00f72 + j-1] * w[j] for j in 1:n)/sum(w) . source","title":"CovidRt.jl"},{"location":"Rt/","text":"This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License Model \u00b6 Following Kevin Systrom , we adapt the approach of (Bettencourt 2008 ) to compute real-time rolling estimates of pandemic parameters. (Bettencourt 2008 ) begin from a SIR model, \\begin{align*} \\dot{S} & = -\\frac{S}{N} \\beta I \\\\ \\dot{I} & = \\frac{S}{N} \\beta I - \\gamma I \\\\ \\dot{R} & = \\gamma I \\end{align*} To this we add the possibility that not all cases are known. Cases get get detected at rate $I$, so cumulative confirmed cases, $C$, evolves as \\dot{C} = \\tau I Question Should we add other states to this model? If yes, how? I think using death and hospitalization numbers in estimation makes sense. The number of new confirmed cases from time $t$ to $t+\\delta$ is then: We will allow for the testing rate, $\\tau$, and infection rate, $\\beta$, to vary over time. k_t \\equiv \\frac{C(t+\\delta) - C(t)}{\\delta} = \\int_t^{t+\\delta} \\tau(s) I(s) ds \\approx \\tau(t) I(t) As in (Bettencourt 2008 ), \\begin{align*} I(t) = & I(t-\\delta) \\int_{t-\\delta}^{t} e^{\\frac{S(s)}{N} \\beta(s) - \\gamma} ds \\\\ \\approx & I(t-\\delta) e^{\\delta \\left( \\frac{S(t-\\delta)}{N} \\beta(t-\\delta) - \\gamma \\right)} \\end{align*} Note The reproductive number is: $R_t \\equiv \\frac{S(t)}{N}\\frac{\\beta(t)}{\\gamma}$. Substituting the expression for $I_t$ into $k_t$, we have \\begin{align*} k_t \\approx & \\tau(t) I(t-\\delta) e^{\\delta \\left( \\frac{S(t-\\delta)}{N} \\beta(t-\\delta) - \\gamma\\right)} \\\\ \\approx & k_{t-\\delta} \\frac{\\tau(t)}{\\tau(t-\\delta)} e^{\\delta \\left(\\frac{S(t-\\delta)}{N} \\beta(t-\\delta) - \\gamma \\right)} \\end{align*} Data \u00b6 We use data as on US states on Covid cases, deaths, policies, and other variables. The data combines information on Daily case counts and deaths from NYTimes Daily Hospitalizations, recoveries, and testing from the Covid Tracking Project Covid related policy changes from Raifman et al Movements from Google Mobility Reports Hourly workers from Hoembase Statistical Model \u00b6 The above theoretical model gives a deterministic relationship between $k_t$ and $k_{t-1}$ given the parameters. To bring it to data we must add stochasticity. Systrom\u2019s approach \u00b6 First we describe what Systrom does. He assumes that $R_{0} \\sim Gamma(4,1)$. Then for $t=1, \u2026, T$, he computes $P(R_t|k_{t}, k_{t-1}, \u2026 ,k_0)$ iteratively using Bayes\u2019 rules. Specifically, he assumes k_t | R_t, k_{t-1}, ... \\sim Poisson(k_{t-1} e^{\\gamma(R_t - 1)}) and that $R_t$ follows a random walk, so the prior of $R_t | R_{t-1}$ is R_t | R_{t-1} \\sim N(R_{t-1}, \\sigma^2) so that P(R_t|k_{t}, k_{t-1}, ... ,k_0) = \\frac{P(k_t | R_t, k_{t-1}) P(R_t | R_{t-1}) P(R_{t-1} | k_{t-1}, ...)} {P(k_t)} Note that this computes posteriors of $R_t$ given current and past cases. Future cases are also informative of $R_t$, and you could instead compute $P(R_t | k_0, k_1, \u2026, k_T)$. The notebook makes some mentions of Gaussian processes. There\u2019s likely some way to recast the random walk assumption as a Gaussian process prior (the kernel would be $\\kappa(t,t\u2019) = \\min{t,t\u2019} \\sigma^2$), but that seems to me like an unusual way to describe it. Code \u00b6 Let\u2019s see how Systrom\u2019s method works. First the load data. using Pkg try using CovidData catch pkg\"registry add https://github.com/schrimpf/julia-registry.git\" Pkg.develop(\"CovidData\") Pkg.develop(\"CovidRt\") end using DataFrames, Plots, StatsPlots, CovidRt, CovidData Plots.pyplot() df = CovidData.statedata() df = filter(x->x.fips<60, df) # focus on 10 states with most cases as of April 1, 2020 sdf = select(df[df[!,:date].==Dates.Date(\"2020-04-01\"),:], Symbol(\"cases.nyt\"), :state) |> x->sort(x,Symbol(\"cases.nyt\"), rev=true) states=sdf[1:10,:state] sdf = select(filter(r->r[:state] \u2208 states, df), Symbol(\"cases.nyt\"), :state, :date) sdf = sort(sdf, [:state, :date]) sdf[!,:newcases] = by(sdf, :state, newcases = Symbol(\"cases.nyt\") => x->(vcat(missing, diff(x))))[!,:newcases] figs = [] for gdf in groupby(sdf, :state) f = @df gdf plot(:date, :newcases, legend=:none, linewidth=2, title=unique(gdf.state)[1]) global figs = vcat(figs,f) end display(plot(figs[1:9]..., layout=(3,3))) From this we can see that new cases are very noisy. This is especially problematic when cases jump from near 0 to very high values, such as in Illinois. The median value of and variance of new cases, $k_t$, are both $k_{t-1} e^{\\gamma(R_t - 1)}$. Only huge changes in $R_t$ can rationalize huge jumps in new cases. Let\u2019s compute posteriors for each state. using Interpolations, Distributions function rtpost(cases, \u03b3, \u03c3, prior0, casepdf) (rgrid, postgrid, ll) = rtpostgrid(cases)(\u03b3, \u03c3, prior0, casepdf) w = rgrid[2] - rgrid[1] T = length(cases) p = [LinearInterpolation(rgrid, postgrid[:,t]) for t in 1:T] coverage = 0.9 cr = zeros(T,2) mu = vec(rgrid' * postgrid*w) for t in 1:T l = findfirst(cumsum(postgrid[:,t].*w).>(1-coverage)/2) h = findlast(cumsum(postgrid[:,t].*w).<(1-(1-coverage)/2)) if !(l === nothing || h === nothing) cr[t,:] = [rgrid[l], rgrid[h]] end end return(p, mu, cr) end function rtpostgrid(cases) # We'll compute the posterior on these values of R_t rlo = 0 rhi = 8 steps = 500 rgrid = range(rlo, rhi, length=steps) \u0394grid = range(0.05, 0.95, length=10) w = rgrid[2] - rgrid[1] dr = rgrid .- rgrid' fn=function(\u03b3, \u03c3, prior0, casepdf) prr = pdf.(Normal(0,\u03c3), dr) # P(r_{t+1} | r_t) for i in 1:size(prr,1) prr[i, : ] ./= sum(prr[i,:].*w) end postgrid = Matrix{typeof(\u03c3)}(undef,length(rgrid), length(cases)) # P(R_t | k_t, k_{t-1},...) like = similar(postgrid, length(cases)) for t in 1:length(cases) if (t==1) postgrid[:,t] .= prior0.(rgrid) else if (cases[t-1]===missing || cases[t]===missing) pkr = 1 # P(k_t | R_t) else \u03bb = max(cases[t-1],1).* exp.(\u03b3 .* (rgrid .- 1)) #r = \u03bb*nbp/(1-nbp) #pkr = pdf.(NegativeBinomial.(r,nbp), cases[t]) pkr = casepdf.(\u03bb, cases[t]) if (all(pkr.==0)) @warn \"all pkr=0\" #@show t, cases[t], cases[t-1] pkr .= 1 end end postgrid[:,t] = pkr.*(prr*postgrid[:,t-1]) like[t] = sum(postgrid[:,t].*w) postgrid[:,t] ./= max(like[t], 1e-15) end end ll = try sum(log.(like)) catch -710*length(like) end return((rgrid, postgrid, ll)) end return(fn) end for \u03c3 in [0.1, 0.25, 1] \u03b3 =1/7 nbp = 0.01 figs = [] for gdf in groupby(sdf, :state) p, m, cr = rtpost(gdf.newcases, \u03b3, \u03c3, x->pdf(truncated(Gamma(4,1),0,8), x), (\u03bb,x)->pdf(Poisson(\u03bb),x)) f = plot(gdf.date, m, ribbon=(m-cr[:,1], cr[:,2] - m), title=unique(gdf.state)[1], legend=:none, ylabel=\"R\u209c\") f = hline!(f,[1.0]) figs = vcat(figs, f) end l = @layout [a{.1h};grid(1,1)] display(plot(plot(annotation=(0.5,0.5, \"Poisson & \u03c3=$\u03c3\"), framestyle = :none), plot(figs[1:9]..., layout=(3,3)), layout=l)) end In these results, what is happening is that when new cases fluctuate too much, the likelihood is identically 0, causing the posterior calculation to break down. Increasing the variance of changes in $R_t$, widens the posterior confidence intervals, but does not solve the problem of vanishing likelihoods. One thing that can \u201csolve\u201d the problem is choosing a distribution of $k_t | \\lambda, k_{t-1}$ with higher variance. The negative binomial with parameters $\\lambda p/(1-p)$ and $p$ has mean $\\lambda$ and variance $\\lambda/p$. \u03b3 =1/7 \u03c3 = 0.25 Plots.closeall() for \u03c3 in [0.1, 0.25, 0.5] for nbp in [0.5, 0.1, 0.01] figs = [] for gdf in groupby(sdf, :state) p, m, cr = rtpost(gdf.newcases, \u03b3, \u03c3, x->pdf(truncated(Gamma(4,1),0,8), x), (\u03bb,x)->pdf(NegativeBinomial(\u03bb*nbp/(1-nbp), nbp),x)); f = plot(gdf.date, m, ribbon=(m-cr[:,1], cr[:,2] - m), title=unique(gdf.state)[1], legend=:none, ylabel=\"R\u209c\") f = hline!(f,[1.0]) figs = vcat(figs, f) end l = @layout [a{.1h};grid(1,1)] display(plot(plot(annotation=(0.5,0.5, \"Negative binomial, p=$nbp, & \u03c3=$\u03c3\"), framestyle = :none), plot(figs[1:9]..., layout=(3,3)), layout=l, reuse=false)) end end What Systrom did was smooth the new cases before using the Poisson distribution. He used a window width of $7$ and Gaussian weights with standard deviation $2$. \u03c3 = 0.25 Plots.closeall() for w in [3, 7, 11] for s in [0.5, 2, 4] \u03b3 =1/7 nbp = 0.01 figs = [] for gdf in groupby(sdf, :state) windowsize = w weights = pdf(Normal(0, s), -floor(windowsize/2):floor(windowsize/2)) weights = weights/sum(weights) smoothcases = smooth(gdf.newcases, w=weights) p, m, cr = rtpost(smoothcases, \u03b3, \u03c3, x->pdf(truncated(Gamma(4,1),0,8), x), (\u03bb,x)->pdf(Poisson(\u03bb),x)) f = plot(gdf.date, m, ribbon=(m-cr[:,1], cr[:,2] - m), title=unique(gdf.state)[1], legend=:none, ylabel=\"R\u209c\") f = hline!(f,[1.0]) figs = vcat(figs, f) end l = @layout [a{.1h};grid(1,1)] display(plot(plot(annotation=(0.5,0.5, \"Poisson & \u03c3=$\u03c3, s=$s, w=$w\"), framestyle = :none), plot(figs[1:9]..., layout=(3,3)), layout=l, reuse=false)) end end Here we see that we can get a variety of results depending on the smoothing used. All of these posteriors ignore the uncertainty in the choice of smoothing parameters (and procedure). An alternative approach \u00b6 Here we follow an approach similar in spirit to Systrom, with a few modifications and additions. The primary modification is that we alter the model of $k_t|k_{t-1}, R_t$ to allow measurement error in both $k_t$ and $k_{t-1}$. We make four additions. First, we utilize data on movement and business operations as auxillary noisy measures of $R_t$. Second, we allow state policies to shift the mean of $R_t$. Third, we combine data from all states to improve precision in each. Fourth, we incorporate testing numbers into the data. As above, we begin from the approximation k^*_{s,t} \\approx k^*_{s,t-1} \\frac{\\tau_{s,t}}{\\tau_{s,t-1}} e^{\\gamma(R_{st} - 1)}) where $k^*$ is the true, unobserved number of new cases. Taking logs and rearranging we have \\log(k^*_{s,t}) - \\log(k^*_{s,t-1}) = \\gamma(R_{s,t} - 1) + \\log\\left(\\frac{\\tau_{s,t}}{\\tau_{s,t-1}}\\right) Let $k_{s,t}$ be the noisy observed value of $k^*_{s,t}$, then \\log(k_{s,t}) - \\log(k_{s,t-1}) = \\gamma(R_{s,t} - 1) + \\log\\left(\\frac{\\tau_{s,t}}{\\tau_{s,t-1}}\\right) - \\epsilon_{s,t} + \\epsilon_{s,t-1} where \\log(k^*_{s,t}) = \\log(k_{s,t}) +\\epsilon_{s,t} and $\\epsilon_{s,t}$ is measurement error. With appropriate assumptions on $\\epsilon$, $\\tau$, $R$ and other observables, we can then use regression to estimate $R$. As a simple example, let\u2019s assume $R_{s,t} = R_{s,0} + \\alpha d_{s,t}$ where $d_{s,t}$ are indicators for NPI\u2019s being in place. That $\\tau_{s,t}$ is constant over time for each $s$ $E[\\epsilon_{s,t} - \\epsilon_{s,t-1}|d] = 0$ and $\\epsilon_{s,t} - \\epsilon_{s,t-1}$ is uncorrelated over time (just to simplify; this is not a good assumption). ```{=html} ``` julia using GLM, RegressionTables pvars = [Symbol(\"Stay.at.home..shelter.in.place\"), Symbol(\"State.of.emergency\"), Symbol(\"Date.closed.K.12.schools\"), Symbol(\"Closed.gyms\"), Symbol(\"Closed.movie.theaters\"), Symbol(\"Closed.day.cares\"), Symbol(\"Date.banned.visitors.to.nursing.homes\"), Symbol(\"Closed.non.essential.businesses\"), Symbol(\"Closed.restaurants.except.take.out\")] sdf = copy(df) for p in pvars sdf[!,p] = by(sdf, :state, (:date, p) => x->(!ismissing(unique(x[p])[1]) .& (x.date .>= unique(x[p])[1]))).x1 end sdf = sort(sdf, [:state, :date]) sdf[!,:newcases] = by(sdf, :state, newcases = Symbol(\"cases.nyt\") => x->(vcat(missing, diff(x))))[!,:newcases] sdf[!,:dlogk] = by(sdf, :state, dlogk = :newcases => x->(vcat(missing, diff(log.(max.(x,0.1))))))[!,:dlogk] fmla = FormulaTerm(Term(:dlogk), Tuple(Term.(vcat(pvars,:state)))) reg = lm(fmla, sdf) regtable(reg, renderSettings=asciiOutput()) ----------------------------------------------- dlogk ------- (1) ----------------------------------------------- (Intercept) 0.175 (0.171) Stay.at.home..shelter.in.place 0.009 (0.060) State.of.emergency -0.093 (0.077) Date.closed.K.12.schools 0.047 (0.081) Closed.gyms -0.080 (0.120) Closed.movie.theaters 0.111 (0.127) Closed.day.cares 0.100 (0.056) Date.banned.visitors.to.nursing.homes -0.009 (0.047) Closed.non.essential.businesses -0.060 (0.069) Closed.restaurants.except.take.out -0.072 (0.107) state: Alaska 0.012 (0.227) state: Arizona -0.023 (0.198) state: Arkansas -0.037 (0.226) state: California -0.025 (0.197) state: Colorado -0.002 (0.219) state: Connecticut 0.032 (0.222) state: Delaware 0.024 (0.225) state: District of Columbia 0.052 (0.221) state: Florida 0.067 (0.216) state: Georgia 0.059 (0.217) state: Hawaii -0.025 (0.220) state: Idaho -0.036 (0.228) state: Illinois 0.007 (0.197) state: Indiana 0.089 (0.220) state: Iowa 0.014 (0.222) state: Kansas 0.073 (0.221) state: Kentucky 0.071 (0.220) state: Louisiana -0.001 (0.223) state: Maine -0.019 (0.227) state: Maryland 0.083 (0.219) state: Massachusetts 0.020 (0.200) state: Michigan 0.112 (0.224) state: Minnesota 0.073 (0.220) state: Mississippi 0.078 (0.226) state: Missouri 0.063 (0.221) state: Montana -0.089 (0.228) state: Nebraska 0.002 (0.207) state: Nevada 0.041 (0.219) state: New Hampshire -0.020 (0.217) state: New Jersey 0.048 (0.218) state: New Mexico 0.006 (0.226) state: New York 0.088 (0.216) state: North Carolina 0.057 (0.218) state: North Dakota 0.047 (0.226) state: Ohio 0.080 (0.224) state: Oklahoma 0.040 (0.221) state: Oregon -0.004 (0.215) state: Pennsylvania 0.028 (0.221) state: Rhode Island 0.036 (0.216) state: South Carolina 0.036 (0.221) state: South Dakota -0.035 (0.225) state: Tennessee 0.050 (0.220) state: Texas -0.018 (0.205) state: Utah 0.011 (0.212) state: Vermont 0.002 (0.222) state: Virginia 0.051 (0.222) state: Washington -0.022 (0.196) state: West Virginia -0.009 (0.234) state: Wisconsin -0.004 (0.201) state: Wyoming 0.015 (0.226) ----------------------------------------------- Estimator OLS ----------------------------------------------- N 2,876 R2 0.004 ----------------------------------------------- From this we get that if we assume $\\gamma = 1/7$, then the the baseline estimate of $R$ in Illinois is $7(0.046 + 0.034) + 1\\approx 1.56$ with a stay at home order, $R$ in Illinois becomes $7(0.046 + 0.035 - 0.147) + 1 \\approx 0.53$. Some of the policies have positive coefficient estimates, which is strange. This is likely due to assumption 1 being incorrect. There is likely an unobserved component of $R_{s,t}$ that is positively correlated with policy indicators. State space model \u00b6 A direct analog of Systrom\u2019s approach is to treat $R_{s,t}$ as an unobserved latent process. Specifically, we will assume that \\begin{align*} \\tilde{R}_{s,0} & \\sim N(\\alpha_0, \\sigma^2_{R,0}) \\\\ \\tilde{R}_{s,t} & = \\rho \\tilde{R}_{s,t} + u_{s,t} \\;,\\; u_{s,t} \\sim N(0, \\sigma^2_R) \\\\ R_{s,t} & = \\alpha + \\tilde{R}_{s,t} \\\\ \\Delta \\log(k)_{s,t} & = \\gamma (R_{s,t} - 1) + \\epsilon_{s,t} - \\epsilon_{s,t-1} \\;, \\; \\epsilon_{s,t} \\sim N(0, \\sigma^2_k) \\end{align*} Note that the Poisson assumption on the distribution of $k_{s,t}$ used by Systrom implies an extremely small $\\sigma^2_k$, since the variance of log Poisson($\\lambda$) distribution is $1/\\lambda$. If $\\epsilon_{s,t} - \\epsilon_{s,t-1}$ weere independent over $t$, we could compute the likelihood and posteriors of $R_{s,t}$ through the standard Kalman filter. Of course, $\\epsilon_{s,t} - \\epsilon_{s,t-1}$ is not independent over time, so we must adjust the Kalman filter accordingly. We follow the approach of (Kurtz and Lin 2019 ) to make this adjustment. Question Is there a better reference? I\u2019m sure someone did this much earlier than 2019\u2026 We estimate the parameters using data from US states. We set time 0 as the first day in which a state had at least 10 cumulative cases. We then compute posteriors for the parameters by MCMC. We place the following priors on the parameters. using Distributions, TransformVariables, DynamicHMC, MCMCChains, Plots, StatsPlots, LogDensityProblems, Random, LinearAlgebra, JLD2 rlo=-1 rhi=1.1 priors = (\u03b3 = truncated(Normal(1/7,1/7), 1/28, 1/1), \u03c3R0 = truncated(Normal(1, 3), 0, Inf), \u03b10 = MvNormal([1], 3), \u03c3R = truncated(Normal(0.25,1),0,Inf), \u03c3k = truncated(Normal(0.1, 5), 0, Inf), \u03b1 = MvNormal([1], 3), \u03c1 = Uniform(rlo, rhi)) (\u03b3 = Truncated(Distributions.Normal{Float64}(\u03bc=0.14285714285714285, \u03c3=0.142 85714285714285), range=(0.03571428571428571, 1.0)), \u03c3R0 = Truncated(Distrib utions.Normal{Float64}(\u03bc=1.0, \u03c3=3.0), range=(0.0, Inf)), \u03b10 = IsoNormal( dim: 1 \u03bc: [1.0] \u03a3: [9.0] ) , \u03c3R = Truncated(Distributions.Normal{Float64}(\u03bc=0.25, \u03c3=1.0), range=(0.0, Inf)), \u03c3k = Truncated(Distributions.Normal{Float64}(\u03bc=0.1, \u03c3=5.0), range=(0 .0, Inf)), \u03b1 = IsoNormal( dim: 1 \u03bc: [1.0] \u03a3: [9.0] ) , \u03c1 = Distributions.Uniform{Float64}(a=-1.0, b=1.1)) The estimation is fast and the chain appears to mix well. reestimate=false sdf = sort(sdf, (:state, :date)); dlogk = [filter(x->((x.state==st) .& (x.cases .>=10)), sdf).dlogk for st in unique(sdf.state)]; dates = [filter(x->((x.state==st) .& (x.cases .>=10)), sdf).date for st in unique(sdf.state)]; mdl = RtModel(dlogk, priors) trans = as( (\u03b3 = as\u211d\u208a, \u03c3R0 = as\u211d\u208a, \u03b10 = as(Array, 1), \u03c3R = as\u211d\u208a, \u03c3k = as\u211d\u208a, \u03b1 = as(Array,1), \u03c1=as(Real, rlo, rhi)) ) P = TransformedLogDensity(trans, mdl) \u2207P = ADgradient(:ForwardDiff, P) p0 = (\u03b3 = 1/7, \u03c3R0=1.0, \u03b10=[4.0],\u03c3R=0.25, \u03c3k=2.0, \u03b1=[1], \u03c1=0.9) x0 = inverse(trans,p0) @time LogDensityProblems.logdensity_and_gradient(\u2207P, x0); 3.330265 seconds (6.58 M allocations: 327.353 MiB, 4.54% gc time) rng = MersenneTwister() steps = 100 warmup=default_warmup_stages(local_optimization=nothing, stepsize_search=nothing, init_steps=steps, middle_steps=steps, terminating_steps=2*steps, doubling_stages=3, M=Symmetric) x0 = x0 if (!isfile(\"rt1.jld2\") || reestimate) res = DynamicHMC.mcmc_keep_warmup(rng, \u2207P, 2000;initialization = (q = x0, \u03f5=0.1), reporter = LogProgressReport(nothing, 25, 15), warmup_stages =warmup); post = transform.(trans,res.inference.chain) @save \"rt1.jld2\" post end @load \"rt1.jld2\" post p = post[1] vals = hcat([vcat([length(v)==1 ? v : vec(v) for v in values(p)]...) for p in post]...)' vals = reshape(vals, size(vals)..., 1) names = vcat([length(p[s])==1 ? String(s) : String.(s).*\"[\".*string.(1:length(p[s])).*\"]\" for s in keys(p)]...) cc = MCMCChains.Chains(vals, names) display(cc) Object of type Chains, with data of type 2000\u00d77\u00d71 reshape(::LinearAlgebra.A djoint{Float64,Array{Float64,2}}, 2000, 7, 1) with eltype Float64 Iterations = 1:2000 Thinning interval = 1 Chains = 1 Samples per chain = 2000 parameters = \u03b3, \u03c3R0, \u03b10, \u03c3R, \u03c3k, \u03b1, \u03c1 2-element Array{MCMCChains.ChainDataFrame,1} Summary Statistics parameters mean std naive_se mcse ess r_hat \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u03b3 0.0919 0.0339 0.0008 0.0017 455.3275 1.0009 \u03c3R0 1.0223 0.6973 0.0156 0.0317 673.2799 0.9996 \u03b10 5.1918 1.7792 0.0398 0.0909 401.6285 1.0001 \u03c3R 0.0887 0.0735 0.0016 0.0027 821.3143 1.0004 \u03c3k 0.5507 0.0082 0.0002 0.0001 3009.0575 0.9997 \u03b1 0.4512 0.4386 0.0098 0.0249 307.9202 0.9996 \u03c1 0.9394 0.0122 0.0003 0.0005 787.5179 1.0002 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u03b3 0.0451 0.0665 0.0849 0.1101 0.1721 \u03c3R0 0.0534 0.5141 0.8979 1.3925 2.7113 \u03b10 2.4360 3.8546 4.9722 6.3808 9.1091 \u03c3R 0.0028 0.0327 0.0722 0.1248 0.2819 \u03c3k 0.5345 0.5453 0.5505 0.5560 0.5677 \u03b1 -0.5931 0.2494 0.5305 0.7539 1.0493 \u03c1 0.9140 0.9315 0.9402 0.9481 0.9618 display(plot(cc)) The posterior for the initial distribution of $R_{0,s}$ is not very precise. The other parameters have fairly precise posteriors. Systrom fixed all these parameters, except $\\sigma_R$, which he estimated by maximum likelihood to be 0.25. In these posteriors, a 95% credible region for $\\sigma_R$ contains his estimate. The posterior of $\\rho$ is not far from his imposed value of $1$, although $1$ is out of the 95% credible region. A 95% posterior region for $\\gamma$ contains Systrom\u2019s calibrated value of $1/7$. It is worth noting that the estimate of $\\sigma_k$ is large compared to $\\sigma_r$. This will cause new observations of $\\Delta \\log k$ will have a small effect on the posterior mean of $R$. Given values of the parameters, we can compute state and time specific posterior estimates of $R_{s,t}$. states = unique(sdf.state) s = findfirst(states.==\"New York\") figr = plotpostr(dates[s],dlogk[s],post, ones(length(dlogk[s]),1), [1]) display(plot(figr, ylim=(-1,10))) This figure shows the posterior distribution of $R_{s,t}$ in New York. The black line is the posterior mean. The dark grey region is the average (over model parameters) of a 90% credible region conditional on the model parameters. This is comparable to what Systrom (and many others) report, and ignores uncertainty in the model parameters. The light grey region is a 90% credile region taking into account parameter uncertainty. The points and error bars are mean and 90% credible regions for \\Delta \\log k_{t}/\\gamma + 1 = R_{t} + \\epsilon_t/\\gamma Posteriors for additional states \u00b6 states_to_plot = [\"New Jersey\",\"Massachusetts\",\"California\", \"Georgia\",\"Illinois\",\"Michigan\", \"Ohio\",\"Wisconsin\",\"Washington\"] S = length(states_to_plot) figs = fill(plot(), 9*(S \u00f7 9 + 1)) for (i,st) in enumerate(states_to_plot) s = findfirst(states.==st) figr = plotpostr(dates[s],dlogk[s],post, ones(length(dlogk[s]),1),[1]) l = @layout [a{.1h}; grid(1,1)] figs[i] = plot(plot(annotation=(0.5,0.5, st), framestyle = :none), plot(figr, ylim=(-1,10)), layout=l) if ((i % 9) ==0 || ( i==length(states_to_plot))) display(plot(figs[(i-8):i]..., layout=(3,3), reuse=false)) end end We can see that the posteriors vary very little from state to state. The model picks up a general downward trend in $\\Delta \\log k$ through the slightly less than 1 estimate of $\\rho$. This drives the posteriors of $R_{s,t}$ in every state to decrease over time. Since $\\sigma_k >> \\sigma_R$, the actual realizations of $\\Delta \\log k$ do not affect the state-specific posteriors very much. Note I also tried fixing $\\rho=1$. This gives similar results in terms of $\\sigma_k >> \\sigma_R$, and gives a posterior for $R_{s,t}$ that is approximately constant over time. Bettencourt, Ruy M., Lu\u00eds M. A. AND Ribeiro. 2008. \u201cReal Time Bayesian Estimation of the Epidemic Potential of Emerging Infectious Diseases.\u201d PLOS ONE 3 (5): 1\u20139. https://doi.org/10.1371/journal.pone.0002185 . Kurtz, Vince, and Hai Lin. 2019. \u201cKalman Filtering with Gaussian Processes Measurement Noise.\u201d","title":"Systrom Approach"},{"location":"Rt/#model","text":"Following Kevin Systrom , we adapt the approach of (Bettencourt 2008 ) to compute real-time rolling estimates of pandemic parameters. (Bettencourt 2008 ) begin from a SIR model, \\begin{align*} \\dot{S} & = -\\frac{S}{N} \\beta I \\\\ \\dot{I} & = \\frac{S}{N} \\beta I - \\gamma I \\\\ \\dot{R} & = \\gamma I \\end{align*} To this we add the possibility that not all cases are known. Cases get get detected at rate $I$, so cumulative confirmed cases, $C$, evolves as \\dot{C} = \\tau I Question Should we add other states to this model? If yes, how? I think using death and hospitalization numbers in estimation makes sense. The number of new confirmed cases from time $t$ to $t+\\delta$ is then: We will allow for the testing rate, $\\tau$, and infection rate, $\\beta$, to vary over time. k_t \\equiv \\frac{C(t+\\delta) - C(t)}{\\delta} = \\int_t^{t+\\delta} \\tau(s) I(s) ds \\approx \\tau(t) I(t) As in (Bettencourt 2008 ), \\begin{align*} I(t) = & I(t-\\delta) \\int_{t-\\delta}^{t} e^{\\frac{S(s)}{N} \\beta(s) - \\gamma} ds \\\\ \\approx & I(t-\\delta) e^{\\delta \\left( \\frac{S(t-\\delta)}{N} \\beta(t-\\delta) - \\gamma \\right)} \\end{align*} Note The reproductive number is: $R_t \\equiv \\frac{S(t)}{N}\\frac{\\beta(t)}{\\gamma}$. Substituting the expression for $I_t$ into $k_t$, we have \\begin{align*} k_t \\approx & \\tau(t) I(t-\\delta) e^{\\delta \\left( \\frac{S(t-\\delta)}{N} \\beta(t-\\delta) - \\gamma\\right)} \\\\ \\approx & k_{t-\\delta} \\frac{\\tau(t)}{\\tau(t-\\delta)} e^{\\delta \\left(\\frac{S(t-\\delta)}{N} \\beta(t-\\delta) - \\gamma \\right)} \\end{align*}","title":"Model"},{"location":"Rt/#data","text":"We use data as on US states on Covid cases, deaths, policies, and other variables. The data combines information on Daily case counts and deaths from NYTimes Daily Hospitalizations, recoveries, and testing from the Covid Tracking Project Covid related policy changes from Raifman et al Movements from Google Mobility Reports Hourly workers from Hoembase","title":"Data"},{"location":"Rt/#statistical-model","text":"The above theoretical model gives a deterministic relationship between $k_t$ and $k_{t-1}$ given the parameters. To bring it to data we must add stochasticity.","title":"Statistical Model"},{"location":"Rt/#systroms-approach","text":"First we describe what Systrom does. He assumes that $R_{0} \\sim Gamma(4,1)$. Then for $t=1, \u2026, T$, he computes $P(R_t|k_{t}, k_{t-1}, \u2026 ,k_0)$ iteratively using Bayes\u2019 rules. Specifically, he assumes k_t | R_t, k_{t-1}, ... \\sim Poisson(k_{t-1} e^{\\gamma(R_t - 1)}) and that $R_t$ follows a random walk, so the prior of $R_t | R_{t-1}$ is R_t | R_{t-1} \\sim N(R_{t-1}, \\sigma^2) so that P(R_t|k_{t}, k_{t-1}, ... ,k_0) = \\frac{P(k_t | R_t, k_{t-1}) P(R_t | R_{t-1}) P(R_{t-1} | k_{t-1}, ...)} {P(k_t)} Note that this computes posteriors of $R_t$ given current and past cases. Future cases are also informative of $R_t$, and you could instead compute $P(R_t | k_0, k_1, \u2026, k_T)$. The notebook makes some mentions of Gaussian processes. There\u2019s likely some way to recast the random walk assumption as a Gaussian process prior (the kernel would be $\\kappa(t,t\u2019) = \\min{t,t\u2019} \\sigma^2$), but that seems to me like an unusual way to describe it.","title":"Systrom\u2019s approach"},{"location":"Rt/#code","text":"Let\u2019s see how Systrom\u2019s method works. First the load data. using Pkg try using CovidData catch pkg\"registry add https://github.com/schrimpf/julia-registry.git\" Pkg.develop(\"CovidData\") Pkg.develop(\"CovidRt\") end using DataFrames, Plots, StatsPlots, CovidRt, CovidData Plots.pyplot() df = CovidData.statedata() df = filter(x->x.fips<60, df) # focus on 10 states with most cases as of April 1, 2020 sdf = select(df[df[!,:date].==Dates.Date(\"2020-04-01\"),:], Symbol(\"cases.nyt\"), :state) |> x->sort(x,Symbol(\"cases.nyt\"), rev=true) states=sdf[1:10,:state] sdf = select(filter(r->r[:state] \u2208 states, df), Symbol(\"cases.nyt\"), :state, :date) sdf = sort(sdf, [:state, :date]) sdf[!,:newcases] = by(sdf, :state, newcases = Symbol(\"cases.nyt\") => x->(vcat(missing, diff(x))))[!,:newcases] figs = [] for gdf in groupby(sdf, :state) f = @df gdf plot(:date, :newcases, legend=:none, linewidth=2, title=unique(gdf.state)[1]) global figs = vcat(figs,f) end display(plot(figs[1:9]..., layout=(3,3))) From this we can see that new cases are very noisy. This is especially problematic when cases jump from near 0 to very high values, such as in Illinois. The median value of and variance of new cases, $k_t$, are both $k_{t-1} e^{\\gamma(R_t - 1)}$. Only huge changes in $R_t$ can rationalize huge jumps in new cases. Let\u2019s compute posteriors for each state. using Interpolations, Distributions function rtpost(cases, \u03b3, \u03c3, prior0, casepdf) (rgrid, postgrid, ll) = rtpostgrid(cases)(\u03b3, \u03c3, prior0, casepdf) w = rgrid[2] - rgrid[1] T = length(cases) p = [LinearInterpolation(rgrid, postgrid[:,t]) for t in 1:T] coverage = 0.9 cr = zeros(T,2) mu = vec(rgrid' * postgrid*w) for t in 1:T l = findfirst(cumsum(postgrid[:,t].*w).>(1-coverage)/2) h = findlast(cumsum(postgrid[:,t].*w).<(1-(1-coverage)/2)) if !(l === nothing || h === nothing) cr[t,:] = [rgrid[l], rgrid[h]] end end return(p, mu, cr) end function rtpostgrid(cases) # We'll compute the posterior on these values of R_t rlo = 0 rhi = 8 steps = 500 rgrid = range(rlo, rhi, length=steps) \u0394grid = range(0.05, 0.95, length=10) w = rgrid[2] - rgrid[1] dr = rgrid .- rgrid' fn=function(\u03b3, \u03c3, prior0, casepdf) prr = pdf.(Normal(0,\u03c3), dr) # P(r_{t+1} | r_t) for i in 1:size(prr,1) prr[i, : ] ./= sum(prr[i,:].*w) end postgrid = Matrix{typeof(\u03c3)}(undef,length(rgrid), length(cases)) # P(R_t | k_t, k_{t-1},...) like = similar(postgrid, length(cases)) for t in 1:length(cases) if (t==1) postgrid[:,t] .= prior0.(rgrid) else if (cases[t-1]===missing || cases[t]===missing) pkr = 1 # P(k_t | R_t) else \u03bb = max(cases[t-1],1).* exp.(\u03b3 .* (rgrid .- 1)) #r = \u03bb*nbp/(1-nbp) #pkr = pdf.(NegativeBinomial.(r,nbp), cases[t]) pkr = casepdf.(\u03bb, cases[t]) if (all(pkr.==0)) @warn \"all pkr=0\" #@show t, cases[t], cases[t-1] pkr .= 1 end end postgrid[:,t] = pkr.*(prr*postgrid[:,t-1]) like[t] = sum(postgrid[:,t].*w) postgrid[:,t] ./= max(like[t], 1e-15) end end ll = try sum(log.(like)) catch -710*length(like) end return((rgrid, postgrid, ll)) end return(fn) end for \u03c3 in [0.1, 0.25, 1] \u03b3 =1/7 nbp = 0.01 figs = [] for gdf in groupby(sdf, :state) p, m, cr = rtpost(gdf.newcases, \u03b3, \u03c3, x->pdf(truncated(Gamma(4,1),0,8), x), (\u03bb,x)->pdf(Poisson(\u03bb),x)) f = plot(gdf.date, m, ribbon=(m-cr[:,1], cr[:,2] - m), title=unique(gdf.state)[1], legend=:none, ylabel=\"R\u209c\") f = hline!(f,[1.0]) figs = vcat(figs, f) end l = @layout [a{.1h};grid(1,1)] display(plot(plot(annotation=(0.5,0.5, \"Poisson & \u03c3=$\u03c3\"), framestyle = :none), plot(figs[1:9]..., layout=(3,3)), layout=l)) end In these results, what is happening is that when new cases fluctuate too much, the likelihood is identically 0, causing the posterior calculation to break down. Increasing the variance of changes in $R_t$, widens the posterior confidence intervals, but does not solve the problem of vanishing likelihoods. One thing that can \u201csolve\u201d the problem is choosing a distribution of $k_t | \\lambda, k_{t-1}$ with higher variance. The negative binomial with parameters $\\lambda p/(1-p)$ and $p$ has mean $\\lambda$ and variance $\\lambda/p$. \u03b3 =1/7 \u03c3 = 0.25 Plots.closeall() for \u03c3 in [0.1, 0.25, 0.5] for nbp in [0.5, 0.1, 0.01] figs = [] for gdf in groupby(sdf, :state) p, m, cr = rtpost(gdf.newcases, \u03b3, \u03c3, x->pdf(truncated(Gamma(4,1),0,8), x), (\u03bb,x)->pdf(NegativeBinomial(\u03bb*nbp/(1-nbp), nbp),x)); f = plot(gdf.date, m, ribbon=(m-cr[:,1], cr[:,2] - m), title=unique(gdf.state)[1], legend=:none, ylabel=\"R\u209c\") f = hline!(f,[1.0]) figs = vcat(figs, f) end l = @layout [a{.1h};grid(1,1)] display(plot(plot(annotation=(0.5,0.5, \"Negative binomial, p=$nbp, & \u03c3=$\u03c3\"), framestyle = :none), plot(figs[1:9]..., layout=(3,3)), layout=l, reuse=false)) end end What Systrom did was smooth the new cases before using the Poisson distribution. He used a window width of $7$ and Gaussian weights with standard deviation $2$. \u03c3 = 0.25 Plots.closeall() for w in [3, 7, 11] for s in [0.5, 2, 4] \u03b3 =1/7 nbp = 0.01 figs = [] for gdf in groupby(sdf, :state) windowsize = w weights = pdf(Normal(0, s), -floor(windowsize/2):floor(windowsize/2)) weights = weights/sum(weights) smoothcases = smooth(gdf.newcases, w=weights) p, m, cr = rtpost(smoothcases, \u03b3, \u03c3, x->pdf(truncated(Gamma(4,1),0,8), x), (\u03bb,x)->pdf(Poisson(\u03bb),x)) f = plot(gdf.date, m, ribbon=(m-cr[:,1], cr[:,2] - m), title=unique(gdf.state)[1], legend=:none, ylabel=\"R\u209c\") f = hline!(f,[1.0]) figs = vcat(figs, f) end l = @layout [a{.1h};grid(1,1)] display(plot(plot(annotation=(0.5,0.5, \"Poisson & \u03c3=$\u03c3, s=$s, w=$w\"), framestyle = :none), plot(figs[1:9]..., layout=(3,3)), layout=l, reuse=false)) end end Here we see that we can get a variety of results depending on the smoothing used. All of these posteriors ignore the uncertainty in the choice of smoothing parameters (and procedure).","title":"Code"},{"location":"Rt/#an-alternative-approach","text":"Here we follow an approach similar in spirit to Systrom, with a few modifications and additions. The primary modification is that we alter the model of $k_t|k_{t-1}, R_t$ to allow measurement error in both $k_t$ and $k_{t-1}$. We make four additions. First, we utilize data on movement and business operations as auxillary noisy measures of $R_t$. Second, we allow state policies to shift the mean of $R_t$. Third, we combine data from all states to improve precision in each. Fourth, we incorporate testing numbers into the data. As above, we begin from the approximation k^*_{s,t} \\approx k^*_{s,t-1} \\frac{\\tau_{s,t}}{\\tau_{s,t-1}} e^{\\gamma(R_{st} - 1)}) where $k^*$ is the true, unobserved number of new cases. Taking logs and rearranging we have \\log(k^*_{s,t}) - \\log(k^*_{s,t-1}) = \\gamma(R_{s,t} - 1) + \\log\\left(\\frac{\\tau_{s,t}}{\\tau_{s,t-1}}\\right) Let $k_{s,t}$ be the noisy observed value of $k^*_{s,t}$, then \\log(k_{s,t}) - \\log(k_{s,t-1}) = \\gamma(R_{s,t} - 1) + \\log\\left(\\frac{\\tau_{s,t}}{\\tau_{s,t-1}}\\right) - \\epsilon_{s,t} + \\epsilon_{s,t-1} where \\log(k^*_{s,t}) = \\log(k_{s,t}) +\\epsilon_{s,t} and $\\epsilon_{s,t}$ is measurement error. With appropriate assumptions on $\\epsilon$, $\\tau$, $R$ and other observables, we can then use regression to estimate $R$. As a simple example, let\u2019s assume $R_{s,t} = R_{s,0} + \\alpha d_{s,t}$ where $d_{s,t}$ are indicators for NPI\u2019s being in place. That $\\tau_{s,t}$ is constant over time for each $s$ $E[\\epsilon_{s,t} - \\epsilon_{s,t-1}|d] = 0$ and $\\epsilon_{s,t} - \\epsilon_{s,t-1}$ is uncorrelated over time (just to simplify; this is not a good assumption). ```{=html} ``` julia using GLM, RegressionTables pvars = [Symbol(\"Stay.at.home..shelter.in.place\"), Symbol(\"State.of.emergency\"), Symbol(\"Date.closed.K.12.schools\"), Symbol(\"Closed.gyms\"), Symbol(\"Closed.movie.theaters\"), Symbol(\"Closed.day.cares\"), Symbol(\"Date.banned.visitors.to.nursing.homes\"), Symbol(\"Closed.non.essential.businesses\"), Symbol(\"Closed.restaurants.except.take.out\")] sdf = copy(df) for p in pvars sdf[!,p] = by(sdf, :state, (:date, p) => x->(!ismissing(unique(x[p])[1]) .& (x.date .>= unique(x[p])[1]))).x1 end sdf = sort(sdf, [:state, :date]) sdf[!,:newcases] = by(sdf, :state, newcases = Symbol(\"cases.nyt\") => x->(vcat(missing, diff(x))))[!,:newcases] sdf[!,:dlogk] = by(sdf, :state, dlogk = :newcases => x->(vcat(missing, diff(log.(max.(x,0.1))))))[!,:dlogk] fmla = FormulaTerm(Term(:dlogk), Tuple(Term.(vcat(pvars,:state)))) reg = lm(fmla, sdf) regtable(reg, renderSettings=asciiOutput()) ----------------------------------------------- dlogk ------- (1) ----------------------------------------------- (Intercept) 0.175 (0.171) Stay.at.home..shelter.in.place 0.009 (0.060) State.of.emergency -0.093 (0.077) Date.closed.K.12.schools 0.047 (0.081) Closed.gyms -0.080 (0.120) Closed.movie.theaters 0.111 (0.127) Closed.day.cares 0.100 (0.056) Date.banned.visitors.to.nursing.homes -0.009 (0.047) Closed.non.essential.businesses -0.060 (0.069) Closed.restaurants.except.take.out -0.072 (0.107) state: Alaska 0.012 (0.227) state: Arizona -0.023 (0.198) state: Arkansas -0.037 (0.226) state: California -0.025 (0.197) state: Colorado -0.002 (0.219) state: Connecticut 0.032 (0.222) state: Delaware 0.024 (0.225) state: District of Columbia 0.052 (0.221) state: Florida 0.067 (0.216) state: Georgia 0.059 (0.217) state: Hawaii -0.025 (0.220) state: Idaho -0.036 (0.228) state: Illinois 0.007 (0.197) state: Indiana 0.089 (0.220) state: Iowa 0.014 (0.222) state: Kansas 0.073 (0.221) state: Kentucky 0.071 (0.220) state: Louisiana -0.001 (0.223) state: Maine -0.019 (0.227) state: Maryland 0.083 (0.219) state: Massachusetts 0.020 (0.200) state: Michigan 0.112 (0.224) state: Minnesota 0.073 (0.220) state: Mississippi 0.078 (0.226) state: Missouri 0.063 (0.221) state: Montana -0.089 (0.228) state: Nebraska 0.002 (0.207) state: Nevada 0.041 (0.219) state: New Hampshire -0.020 (0.217) state: New Jersey 0.048 (0.218) state: New Mexico 0.006 (0.226) state: New York 0.088 (0.216) state: North Carolina 0.057 (0.218) state: North Dakota 0.047 (0.226) state: Ohio 0.080 (0.224) state: Oklahoma 0.040 (0.221) state: Oregon -0.004 (0.215) state: Pennsylvania 0.028 (0.221) state: Rhode Island 0.036 (0.216) state: South Carolina 0.036 (0.221) state: South Dakota -0.035 (0.225) state: Tennessee 0.050 (0.220) state: Texas -0.018 (0.205) state: Utah 0.011 (0.212) state: Vermont 0.002 (0.222) state: Virginia 0.051 (0.222) state: Washington -0.022 (0.196) state: West Virginia -0.009 (0.234) state: Wisconsin -0.004 (0.201) state: Wyoming 0.015 (0.226) ----------------------------------------------- Estimator OLS ----------------------------------------------- N 2,876 R2 0.004 ----------------------------------------------- From this we get that if we assume $\\gamma = 1/7$, then the the baseline estimate of $R$ in Illinois is $7(0.046 + 0.034) + 1\\approx 1.56$ with a stay at home order, $R$ in Illinois becomes $7(0.046 + 0.035 - 0.147) + 1 \\approx 0.53$. Some of the policies have positive coefficient estimates, which is strange. This is likely due to assumption 1 being incorrect. There is likely an unobserved component of $R_{s,t}$ that is positively correlated with policy indicators.","title":"An alternative approach"},{"location":"Rt/#state-space-model","text":"A direct analog of Systrom\u2019s approach is to treat $R_{s,t}$ as an unobserved latent process. Specifically, we will assume that \\begin{align*} \\tilde{R}_{s,0} & \\sim N(\\alpha_0, \\sigma^2_{R,0}) \\\\ \\tilde{R}_{s,t} & = \\rho \\tilde{R}_{s,t} + u_{s,t} \\;,\\; u_{s,t} \\sim N(0, \\sigma^2_R) \\\\ R_{s,t} & = \\alpha + \\tilde{R}_{s,t} \\\\ \\Delta \\log(k)_{s,t} & = \\gamma (R_{s,t} - 1) + \\epsilon_{s,t} - \\epsilon_{s,t-1} \\;, \\; \\epsilon_{s,t} \\sim N(0, \\sigma^2_k) \\end{align*} Note that the Poisson assumption on the distribution of $k_{s,t}$ used by Systrom implies an extremely small $\\sigma^2_k$, since the variance of log Poisson($\\lambda$) distribution is $1/\\lambda$. If $\\epsilon_{s,t} - \\epsilon_{s,t-1}$ weere independent over $t$, we could compute the likelihood and posteriors of $R_{s,t}$ through the standard Kalman filter. Of course, $\\epsilon_{s,t} - \\epsilon_{s,t-1}$ is not independent over time, so we must adjust the Kalman filter accordingly. We follow the approach of (Kurtz and Lin 2019 ) to make this adjustment. Question Is there a better reference? I\u2019m sure someone did this much earlier than 2019\u2026 We estimate the parameters using data from US states. We set time 0 as the first day in which a state had at least 10 cumulative cases. We then compute posteriors for the parameters by MCMC. We place the following priors on the parameters. using Distributions, TransformVariables, DynamicHMC, MCMCChains, Plots, StatsPlots, LogDensityProblems, Random, LinearAlgebra, JLD2 rlo=-1 rhi=1.1 priors = (\u03b3 = truncated(Normal(1/7,1/7), 1/28, 1/1), \u03c3R0 = truncated(Normal(1, 3), 0, Inf), \u03b10 = MvNormal([1], 3), \u03c3R = truncated(Normal(0.25,1),0,Inf), \u03c3k = truncated(Normal(0.1, 5), 0, Inf), \u03b1 = MvNormal([1], 3), \u03c1 = Uniform(rlo, rhi)) (\u03b3 = Truncated(Distributions.Normal{Float64}(\u03bc=0.14285714285714285, \u03c3=0.142 85714285714285), range=(0.03571428571428571, 1.0)), \u03c3R0 = Truncated(Distrib utions.Normal{Float64}(\u03bc=1.0, \u03c3=3.0), range=(0.0, Inf)), \u03b10 = IsoNormal( dim: 1 \u03bc: [1.0] \u03a3: [9.0] ) , \u03c3R = Truncated(Distributions.Normal{Float64}(\u03bc=0.25, \u03c3=1.0), range=(0.0, Inf)), \u03c3k = Truncated(Distributions.Normal{Float64}(\u03bc=0.1, \u03c3=5.0), range=(0 .0, Inf)), \u03b1 = IsoNormal( dim: 1 \u03bc: [1.0] \u03a3: [9.0] ) , \u03c1 = Distributions.Uniform{Float64}(a=-1.0, b=1.1)) The estimation is fast and the chain appears to mix well. reestimate=false sdf = sort(sdf, (:state, :date)); dlogk = [filter(x->((x.state==st) .& (x.cases .>=10)), sdf).dlogk for st in unique(sdf.state)]; dates = [filter(x->((x.state==st) .& (x.cases .>=10)), sdf).date for st in unique(sdf.state)]; mdl = RtModel(dlogk, priors) trans = as( (\u03b3 = as\u211d\u208a, \u03c3R0 = as\u211d\u208a, \u03b10 = as(Array, 1), \u03c3R = as\u211d\u208a, \u03c3k = as\u211d\u208a, \u03b1 = as(Array,1), \u03c1=as(Real, rlo, rhi)) ) P = TransformedLogDensity(trans, mdl) \u2207P = ADgradient(:ForwardDiff, P) p0 = (\u03b3 = 1/7, \u03c3R0=1.0, \u03b10=[4.0],\u03c3R=0.25, \u03c3k=2.0, \u03b1=[1], \u03c1=0.9) x0 = inverse(trans,p0) @time LogDensityProblems.logdensity_and_gradient(\u2207P, x0); 3.330265 seconds (6.58 M allocations: 327.353 MiB, 4.54% gc time) rng = MersenneTwister() steps = 100 warmup=default_warmup_stages(local_optimization=nothing, stepsize_search=nothing, init_steps=steps, middle_steps=steps, terminating_steps=2*steps, doubling_stages=3, M=Symmetric) x0 = x0 if (!isfile(\"rt1.jld2\") || reestimate) res = DynamicHMC.mcmc_keep_warmup(rng, \u2207P, 2000;initialization = (q = x0, \u03f5=0.1), reporter = LogProgressReport(nothing, 25, 15), warmup_stages =warmup); post = transform.(trans,res.inference.chain) @save \"rt1.jld2\" post end @load \"rt1.jld2\" post p = post[1] vals = hcat([vcat([length(v)==1 ? v : vec(v) for v in values(p)]...) for p in post]...)' vals = reshape(vals, size(vals)..., 1) names = vcat([length(p[s])==1 ? String(s) : String.(s).*\"[\".*string.(1:length(p[s])).*\"]\" for s in keys(p)]...) cc = MCMCChains.Chains(vals, names) display(cc) Object of type Chains, with data of type 2000\u00d77\u00d71 reshape(::LinearAlgebra.A djoint{Float64,Array{Float64,2}}, 2000, 7, 1) with eltype Float64 Iterations = 1:2000 Thinning interval = 1 Chains = 1 Samples per chain = 2000 parameters = \u03b3, \u03c3R0, \u03b10, \u03c3R, \u03c3k, \u03b1, \u03c1 2-element Array{MCMCChains.ChainDataFrame,1} Summary Statistics parameters mean std naive_se mcse ess r_hat \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u03b3 0.0919 0.0339 0.0008 0.0017 455.3275 1.0009 \u03c3R0 1.0223 0.6973 0.0156 0.0317 673.2799 0.9996 \u03b10 5.1918 1.7792 0.0398 0.0909 401.6285 1.0001 \u03c3R 0.0887 0.0735 0.0016 0.0027 821.3143 1.0004 \u03c3k 0.5507 0.0082 0.0002 0.0001 3009.0575 0.9997 \u03b1 0.4512 0.4386 0.0098 0.0249 307.9202 0.9996 \u03c1 0.9394 0.0122 0.0003 0.0005 787.5179 1.0002 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u03b3 0.0451 0.0665 0.0849 0.1101 0.1721 \u03c3R0 0.0534 0.5141 0.8979 1.3925 2.7113 \u03b10 2.4360 3.8546 4.9722 6.3808 9.1091 \u03c3R 0.0028 0.0327 0.0722 0.1248 0.2819 \u03c3k 0.5345 0.5453 0.5505 0.5560 0.5677 \u03b1 -0.5931 0.2494 0.5305 0.7539 1.0493 \u03c1 0.9140 0.9315 0.9402 0.9481 0.9618 display(plot(cc)) The posterior for the initial distribution of $R_{0,s}$ is not very precise. The other parameters have fairly precise posteriors. Systrom fixed all these parameters, except $\\sigma_R$, which he estimated by maximum likelihood to be 0.25. In these posteriors, a 95% credible region for $\\sigma_R$ contains his estimate. The posterior of $\\rho$ is not far from his imposed value of $1$, although $1$ is out of the 95% credible region. A 95% posterior region for $\\gamma$ contains Systrom\u2019s calibrated value of $1/7$. It is worth noting that the estimate of $\\sigma_k$ is large compared to $\\sigma_r$. This will cause new observations of $\\Delta \\log k$ will have a small effect on the posterior mean of $R$. Given values of the parameters, we can compute state and time specific posterior estimates of $R_{s,t}$. states = unique(sdf.state) s = findfirst(states.==\"New York\") figr = plotpostr(dates[s],dlogk[s],post, ones(length(dlogk[s]),1), [1]) display(plot(figr, ylim=(-1,10))) This figure shows the posterior distribution of $R_{s,t}$ in New York. The black line is the posterior mean. The dark grey region is the average (over model parameters) of a 90% credible region conditional on the model parameters. This is comparable to what Systrom (and many others) report, and ignores uncertainty in the model parameters. The light grey region is a 90% credile region taking into account parameter uncertainty. The points and error bars are mean and 90% credible regions for \\Delta \\log k_{t}/\\gamma + 1 = R_{t} + \\epsilon_t/\\gamma","title":"State space model"},{"location":"Rt/#posteriors-for-additional-states","text":"states_to_plot = [\"New Jersey\",\"Massachusetts\",\"California\", \"Georgia\",\"Illinois\",\"Michigan\", \"Ohio\",\"Wisconsin\",\"Washington\"] S = length(states_to_plot) figs = fill(plot(), 9*(S \u00f7 9 + 1)) for (i,st) in enumerate(states_to_plot) s = findfirst(states.==st) figr = plotpostr(dates[s],dlogk[s],post, ones(length(dlogk[s]),1),[1]) l = @layout [a{.1h}; grid(1,1)] figs[i] = plot(plot(annotation=(0.5,0.5, st), framestyle = :none), plot(figr, ylim=(-1,10)), layout=l) if ((i % 9) ==0 || ( i==length(states_to_plot))) display(plot(figs[(i-8):i]..., layout=(3,3), reuse=false)) end end We can see that the posteriors vary very little from state to state. The model picks up a general downward trend in $\\Delta \\log k$ through the slightly less than 1 estimate of $\\rho$. This drives the posteriors of $R_{s,t}$ in every state to decrease over time. Since $\\sigma_k >> \\sigma_R$, the actual realizations of $\\Delta \\log k$ do not affect the state-specific posteriors very much. Note I also tried fixing $\\rho=1$. This gives similar results in terms of $\\sigma_k >> \\sigma_R$, and gives a posterior for $R_{s,t}$ that is approximately constant over time. Bettencourt, Ruy M., Lu\u00eds M. A. AND Ribeiro. 2008. \u201cReal Time Bayesian Estimation of the Epidemic Potential of Emerging Infectious Diseases.\u201d PLOS ONE 3 (5): 1\u20139. https://doi.org/10.1371/journal.pone.0002185 . Kurtz, Vince, and Hai Lin. 2019. \u201cKalman Filtering with Gaussian Processes Measurement Noise.\u201d","title":"Posteriors for additional states"},{"location":"exploratory/","text":"Introduction \u00b6 This section contains some exploratory plots. using CovidData using CovidRt Error: importing CovidRt into Main conflicts with an existing identifier using TransformVariables, Parameters, Plots, StatsPlots, DataFrames, Dates, LinearAlgebra, Distributions, Random, LogDensityProblems, DynamicHMC, MCMCChains, JLD2, Latexify Plots.pyplot() using ColorSchemes colors = ColorSchemes.Set1_9 df = CovidData.statedata(policies=:indicators, fillmissingmobility=true) df[!,:log_encounters_rate] = log.(1 .+ df[!,:encounters_rate]) # create \u0394log\u0394cases sdf = filter(x->x.fips < 60, df) sort!(sdf, (:state, :date)) L1 = L2 = 7 sdf[!,:\u0394cases] = by(sdf, :state, \u0394cases = Symbol(\"cases.nyt\") => x->lagdiff(x, L1))[!,:\u0394cases]./L1 sdf[!,:\u0394log\u0394cases] = by(sdf, :state, \u0394log\u0394cases =:\u0394cases => x->lagdiff(log.(max.(x,0.1)), L2))[!,:\u0394log\u0394cases]./L2 googlevars = [:retail_and_recreation_percent_change_from_baseline, :grocery_and_pharmacy_percent_change_from_baseline, :parks_percent_change_from_baseline , :transit_stations_percent_change_from_baseline, :workplaces_percent_change_from_baseline, :residential_percent_change_from_baseline] homebasevars = [:percentchangehours, :percentchangebusinesses] unacastvars = [:n_grade_total, :daily_distance_diff, :n_grade_distance, :daily_visitation_diff, :n_grade_visitation, :log_encounters_rate, :n_grade_encounters] 7-element Array{Symbol,1}: :n_grade_total :daily_distance_diff :n_grade_distance :daily_visitation_diff :n_grade_visitation :log_encounters_rate :n_grade_encounters Choosing lag length \u00b6 Here we plot time series of $\\Delta \\log(\\Delta cases)$ and each of the activity measurements. We also plot the covariances of $\\Delta \\log(\\Delta cases)$ and $m(t+\\ell)$ as a function of $\\ell$ for each of the activity measurement variables, $m$ datelim = (Date(\"2020-03-07\"), Dates.today()) xlim = Dates.value.(datelim) function acf(df, id, t, x, y, tdiffs=[-20:20]; correlation=false) if !issorted(df, (id, t)) @error \"df not sorted\" end X = df[!,x] c = zeros(size(tdiffs)) cfn = correlation ? cor : cov for (i, t) in enumerate(tdiffs) ylag = by(df, id, ylag= y => z->CovidRt.lag(z,t))[!,:ylag] inc = .!ismissing.(X) .& .!(ismissing.(ylag)) c[i] = cfn(X[inc],ylag[inc]) end return(c) end states_to_plot = [\"New York\", \"New Jersey\",\"Massachusetts\",\"California\", \"Georgia\",\"Illinois\",\"Michigan\", \"Ohio\",\"Wisconsin\",\"Washington\"] vars = vcat(googlevars, homebasevars, unacastvars) states_to_plot = [\"New York\", \"New Jersey\",\"Massachusetts\",\"California\", \"Georgia\",\"Illinois\",\"Michigan\", \"Ohio\",\"Wisconsin\",\"Washington\"] vars = vcat(googlevars, homebasevars, unacastvars) function explorelags(vars, sdf, states_to_plot; toplot=vars, tdiffs=-10:40, correlation=true) argmaxc = zeros(Int64,length(vars)) maxc = zeros(length(vars)) for (j,v) in enumerate(vars) if v in toplot fig = Vector{Any}(undef, length(states_to_plot)) for (i, st) in enumerate(states_to_plot) subdf = filter(x->x.state.==st, sdf) fig[i] = @df subdf plot(:date, :\u0394log\u0394cases, title=st, color=colors[1], ylab=\"\u0394log\u0394cases\", xlim=xlim, legend=:topleft, labels=\"\u0394log\u0394cases\") fig[i] = twinx() fig[i] = plot!(fig[i],subdf[!,:date], subdf[!,v], color=colors[2], labels=string(v), ylab=string(v), xlim=xlim, legend=:topright) end display(plot(fig[1:4]..., layout=(2,2), reuse=false)) display(plot(fig[5:8]..., layout=(2,2), reuse=false)) end c = acf(sdf, :state, :date, :\u0394log\u0394cases, v, tdiffs, correlation=correlation) a = argmax(abs.(c)) argmaxc[j] = tdiffs[a] maxc[j] = c[a] cword = correlation ? \"Correlation\" : \"Covariance\" if v in toplot fig=plot(tdiffs, c, title=\"$cword of \u0394log\u0394cases[t] & $(string(v))[t+\u2113]\", xlab=\"\u2113\", ylab=\"$cword\", legend=:none, linewidth=1.5) display(plot(fig, reuse=false)) end end cword = correlation ? \"cor\" : \"cov\" tbl = vcat([\"Variable\" \"\u2113 maximum $cword\" \"maximum $cword\"],[replace.(string.(vars),r\"\\_\"=>s\" \") argmaxc maxc]) if !correlation tbl=hcat(tbl, [\"variance\", [var(skipmissing(sdf[!,v])) for v in vars]...]) end return(latexify(tbl, env=:mdtable, latex=false, fmt=\"%.2f\")) end tbl=explorelags(vars, sdf, states_to_plot; toplot=[:residential_percent_change_from_baseline, :percentchangebusinesses, :n_grade_total, :daily_visitation_diff, :log_encounters_rate]); println(tbl) Variable \u2113 maximum cor maximum cor retail and recreation percent change from baseline 15.00 0.80 grocery and pharmacy percent change from baseline 11.00 0.66 parks percent change from baseline 16.00 0.27 transit stations percent change from baseline 15.00 0.72 workplaces percent change from baseline 15.00 0.80 residential percent change from baseline 15.00 -0.75 percentchangehours 15.00 0.80 percentchangebusinesses 14.00 0.79 n grade total 14.00 -0.67 daily distance diff 14.00 0.75 n grade distance 14.00 -0.63 daily visitation diff 15.00 0.79 n grade visitation 15.00 -0.47 log encounters rate 16.00 0.49 n grade encounters 15.00 -0.44 Some comments: There is are noticeable weekend effects, especially in residential percent change from baseline from Google mobility reports. There\u2019s some effect of Easter visible in percent change business The variables n grade total , daily visitation diff and encounters rate are from Unacast . It is not just a coincidence that the maximum autocovariance is at $14 = L_1 + L_2$. The timing convention being followed here is that (\\Delta \\log \\Delta cases)[t] = \\log(cases[t] - cases[t-L_1]) - \\log(cases[t-L_2] - cases[t-L_2-L1]) so it is no surprise that lags of these measurement errors are correletaed with $\\Delta log \\Delta cases[t]$. Given the long differencing, what are the correct lags of measurement variables to use? \u00b6 In discrete time, the model is \\begin{align*} \\Delta C_t & = \\tau I_t \\\\ I_t & = (1+\\gamma (R_t - 1)) I_{t-1} \\end{align*} Combining these we get \\begin{align*} C_{t} - C_{t - L_1} = & \\sum_{s=t-L_1+1}^{t} \\left(\\prod_{r=t-L_1+1}^s 1 + \\gamma (R_r - 1) \\right) I_{t-L_1} \\\\ = & (1+\\gamma(\\overline{R}_{t-L_1,t}) ) I_{t-L_1} \\\\ = & (1+\\gamma(\\overline{R}_{t-L_1,t})) (1+\\gamma(\\overline{R}_{t-L_1-L_2,t-L_1})) I_{t-L_1-L2} \\end{align*} where $\\overline{R}_{t-L_1, t}$ is the \u201caverage\u201d 1 effective reproductive from time $t-L_1$ to $t$. Similarly, C_{t-L_2} - C_{t - L_2 - L_1} = (1+\\gamma(\\overline{R}_{t-L_1-L_2,t-L_2}) ) I_{t-L_1-L_2} If $L_1 = L_2$, then we get some convenient cancellations when taking the log difference: \\begin{align*} \\log (C_t - C_{t-L}) - \\log(C_{t-L} - C_{t - 2L}) = & \\log( 1 + \\gamma(\\overline{R}_{t-L,t}) ) \\\\ \\approx & \\gamma (\\overline{R}_{t-L,t} - 1) \\end{align*} !!! question Is this $L_1 = L_2$ condition correct and general? Or some artifact of this derivation? I think it would appear if the model were in continuous time as well. From this derivation, we see that \u0394log\u0394cases[t] should depend on the reproductive number of confirmed cases from time $t-L$ to $t$. Since there is a delay between infection and detection, the reproductive number of confirmed cases, depends on actual conditions some time further in the past. Moving average measurement variables \u00b6 Motivated by the analysis in the previous section, we will use the moving average from $t-L$ to time $t$ in place of each measurement variable at time $t$. Plots.closeall() L = 7 sdf = filter(x->x.fips < 60, df) sort!(sdf, (:state, :date)) sdf[!,:\u0394cases] = by(sdf, :state, \u0394cases = Symbol(\"cases.nyt\") => x->lagdiff(x, L))[!,:\u0394cases]./L sdf[!,:\u0394log\u0394cases] = by(sdf, :state, \u0394log\u0394cases =:\u0394cases => x->lagdiff(log.(max.(x,0.1)), L))[!,:\u0394log\u0394cases]./L w = vcat(ones(L+1), zeros(L)) for v in vcat(googlevars, homebasevars, unacastvars) sdf[!,v]=by(sdf, :state, x = v => x->CovidRt.smooth(x,w=w))[!,:x] end tbl=explorelags(vars, sdf, states_to_plot; toplot=[:residential_percent_change_from_baseline, :percentchangebusinesses, :n_grade_total, :log_encounters_rate], correlation=false); println(tbl) Variable \u2113 maximum cov maximum cov variance retail and recreation percent change from baseline 14.00 2.24 426.19 grocery and pharmacy percent change from baseline 9.00 1.23 184.22 parks percent change from baseline 13.00 1.23 855.44 transit stations percent change from baseline 14.00 2.14 534.46 workplaces percent change from baseline 14.00 2.03 363.65 residential percent change from baseline 14.00 -0.79 57.28 percentchangehours 14.00 2.68 636.21 percentchangebusinesses 13.00 2.02 401.74 n grade total 12.00 -0.08 0.71 daily distance diff 14.00 0.02 0.03 n grade distance 11.00 -0.07 0.67 daily visitation diff 14.00 0.02 0.05 n grade visitation 10.00 -0.08 1.26 log encounters rate 14.00 0.11 3.13 n grade encounters 14.00 -0.08 2.16 Even after this adjustment, there is some mechanical dependence between when the maximum correlation occurs and $L$. Plots.closeall() for L in [1, 3, 7, 10, 14] sdf = filter(x->x.fips < 60, df) sort!(sdf, (:state, :date)) sdf[!,:\u0394cases] = by(sdf, :state, \u0394cases = Symbol(\"cases.nyt\") => x->lagdiff(x, L))[!,:\u0394cases]./L sdf[!,:\u0394log\u0394cases] = by(sdf, :state, \u0394log\u0394cases =:\u0394cases => x->lagdiff(log.(max.(x,0.1)), L))[!,:\u0394log\u0394cases]./L w = vcat(ones(L+1), zeros(L)) for v in vcat(googlevars, homebasevars, unacastvars) sdf[!,v]=by(sdf, :state, x = v => x->CovidRt.smooth(x,w=w))[!,:x] end @show L tbl=explorelags(vars, sdf, states_to_plot; toplot=[], correlation=false) println() println(\"### L = $L\") println() println(tbl) end L = 1 L = 1 \u00b6 Variable \u2113 maximum cov maximum cov variance retail and recreation percent change from baseline 7.00 2.57 404.51 grocery and pharmacy percent change from baseline 5.00 1.77 206.00 parks percent change from baseline 9.00 1.70 1435.15 transit stations percent change from baseline 4.00 2.55 513.03 workplaces percent change from baseline 4.00 2.61 340.96 residential percent change from baseline 4.00 -1.01 58.31 percentchangehours 8.00 3.05 580.19 percentchangebusinesses 7.00 2.56 383.69 n grade total 7.00 -0.10 0.76 daily distance diff 7.00 0.02 0.03 n grade distance 0.00 -0.10 0.76 daily visitation diff 7.00 0.03 0.05 n grade visitation 7.00 -0.12 1.58 log encounters rate 7.00 0.12 3.07 n grade encounters 7.00 -0.09 2.23 L = 3 L = 3 \u00b6 Variable \u2113 maximum cov maximum cov variance retail and recreation percent change from baseline 8.00 2.39 410.84 grocery and pharmacy percent change from baseline 6.00 1.51 193.41 parks percent change from baseline 10.00 1.37 1116.30 transit stations percent change from baseline 6.00 2.37 520.55 workplaces percent change from baseline 6.00 2.23 346.41 residential percent change from baseline 11.00 -0.85 56.31 percentchangehours 7.00 2.91 601.86 percentchangebusinesses 6.00 2.32 390.19 n grade total 8.00 -0.09 0.72 daily distance diff 8.00 0.02 0.03 n grade distance 7.00 -0.09 0.70 daily visitation diff 8.00 0.03 0.05 n grade visitation 8.00 -0.09 1.40 log encounters rate 9.00 0.11 3.08 n grade encounters 8.00 -0.09 2.19 L = 7 L = 7 \u00b6 Variable \u2113 maximum cov maximum cov variance retail and recreation percent change from baseline 14.00 2.24 426.19 grocery and pharmacy percent change from baseline 9.00 1.23 184.22 parks percent change from baseline 13.00 1.23 855.44 transit stations percent change from baseline 14.00 2.14 534.46 workplaces percent change from baseline 14.00 2.03 363.65 residential percent change from baseline 14.00 -0.79 57.28 percentchangehours 14.00 2.68 636.21 percentchangebusinesses 13.00 2.02 401.74 n grade total 12.00 -0.08 0.71 daily distance diff 14.00 0.02 0.03 n grade distance 11.00 -0.07 0.67 daily visitation diff 14.00 0.02 0.05 n grade visitation 10.00 -0.08 1.26 log encounters rate 14.00 0.11 3.13 n grade encounters 14.00 -0.08 2.16 L = 10 L = 10 \u00b6 Variable \u2113 maximum cov maximum cov variance retail and recreation percent change from baseline 17.00 1.84 433.12 grocery and pharmacy percent change from baseline 12.00 1.02 179.09 parks percent change from baseline 16.00 1.01 771.06 transit stations percent change from baseline 17.00 1.73 538.38 workplaces percent change from baseline 17.00 1.66 371.54 residential percent change from baseline 18.00 -0.65 58.46 percentchangehours 16.00 2.22 647.28 percentchangebusinesses 15.00 1.66 406.18 n grade total 14.00 -0.06 0.71 daily distance diff 16.00 0.01 0.03 n grade distance 14.00 -0.06 0.66 daily visitation diff 18.00 0.02 0.05 n grade visitation 14.00 -0.06 1.21 log encounters rate 17.00 0.09 3.17 n grade encounters 15.00 -0.07 2.14 L = 14 L = 14 \u00b6 Variable \u2113 maximum cov maximum cov variance retail and recreation percent change from baseline 20.00 1.27 432.02 grocery and pharmacy percent change from baseline 15.00 0.72 170.79 parks percent change from baseline 19.00 0.70 684.35 transit stations percent change from baseline 19.00 1.15 532.44 workplaces percent change from baseline 19.00 1.13 373.17 residential percent change from baseline 20.00 -0.44 58.48 percentchangehours 19.00 1.53 644.77 percentchangebusinesses 17.00 1.14 402.23 n grade total 16.00 -0.05 0.70 daily distance diff 19.00 0.01 0.03 n grade distance 16.00 -0.04 0.64 daily visitation diff 21.00 0.01 0.05 n grade visitation 16.00 -0.04 1.13 log encounters rate 19.00 0.07 3.20 n grade encounters 17.00 -0.05 2.12 Removing common time trends \u00b6 In large part, the correlation between lagged measurement variabales and $\\Delta \\log \\Delta C$ is driven by a common decreasing time trend. When this decrease occurs shifts with $L$, so that might explain why the maximal correlation depends on $L$. Here, we will repeat some of the above analysis after removing time effects. mvars = vcat(googlevars, homebasevars, unacastvars) adf = aggregate(select(sdf, :date, :\u0394log\u0394cases),:date, [x->mean(skipmissing(x)), x->sqrt(var(skipmissing(x))) ], sort=true) n = length(unique(sdf.state)) @df adf plot(:date, :\u0394log\u0394cases_function, legend=:none, xlim=xlim, ribbon=1.64/sqrt(n)*:\u0394log\u0394cases_function_1, ylab=\"\u0394log\u0394cases\", title=\"Average \u0394log\u0394cases\") for L in [1, 3, 7, 10, 14] sdf = filter(x->x.fips < 60, df) sort!(sdf, (:state, :date)) sdf[!,:\u0394cases] = by(sdf, :state, \u0394cases = Symbol(\"cases.nyt\") => x->lagdiff(x, L))[!,:\u0394cases]./L sdf[!,:\u0394log\u0394cases] = by(sdf, :state, \u0394log\u0394cases =:\u0394cases => x->lagdiff(log.(max.(x,0.1)), L))[!,:\u0394log\u0394cases]./L w = vcat(ones(L+1), zeros(L)) for v in mvars sdf[!,v]=by(sdf, :state, x = v => x->CovidRt.smooth(x,w=w))[!,:x] end adf = aggregate(select(sdf, :date, :\u0394log\u0394cases, mvars...),:date, [x->mean(skipmissing(x))], sort=true) sdf = join(sdf, adf, on=:date) for v in vcat(:\u0394log\u0394cases, mvars) sdf[!,v] .= sdf[!,v] .- sdf[!, Symbol(string(v)*\"_function\")] end toplot = L==7 ? [:residential_percent_change_from_baseline, :percentchangebusinesses, :n_grade_total, :log_encounters_rate] : [] tbl=explorelags(vars, sdf, states_to_plot; toplot=toplot, tdiffs=-10:40, correlation=false) println(\"\\n### L = $L \\n\") println(tbl) println() end L = 1 \u00b6 Variable \u2113 maximum cov maximum cov variance retail and recreation percent change from baseline 31.00 0.15 57.34 grocery and pharmacy percent change from baseline 31.00 0.23 52.65 parks percent change from baseline 37.00 0.93 1266.70 transit stations percent change from baseline 24.00 0.19 196.32 workplaces percent change from baseline -10.00 -0.08 36.79 residential percent change from baseline -10.00 0.06 8.43 percentchangehours 9.00 0.17 90.19 percentchangebusinesses 22.00 0.13 62.22 n grade total -9.00 -0.01 0.32 daily distance diff 18.00 0.00 0.01 n grade distance 19.00 -0.01 0.28 daily visitation diff 1.00 0.00 0.00 n grade visitation 18.00 -0.01 0.92 log encounters rate -9.00 0.04 2.52 n grade encounters -9.00 -0.04 1.88 L = 3 \u00b6 Variable \u2113 maximum cov maximum cov variance retail and recreation percent change from baseline 0.00 0.08 51.55 grocery and pharmacy percent change from baseline 40.00 0.09 46.27 parks percent change from baseline 18.00 0.38 983.44 transit stations percent change from baseline 25.00 0.11 187.14 workplaces percent change from baseline 0.00 0.05 34.53 residential percent change from baseline -10.00 0.02 7.71 percentchangehours 0.00 0.10 83.09 percentchangebusinesses 17.00 0.08 58.55 n grade total 3.00 -0.01 0.30 daily distance diff 2.00 0.00 0.01 n grade distance 26.00 -0.00 0.25 daily visitation diff 1.00 0.00 0.00 n grade visitation 18.00 -0.01 0.85 log encounters rate 9.00 0.02 2.53 n grade encounters -10.00 -0.02 1.84 L = 7 \u00b6 Variable \u2113 maximum cov maximum cov variance retail and recreation percent change from baseline 5.00 0.05 44.86 grocery and pharmacy percent change from baseline 3.00 0.05 40.90 parks percent change from baseline 15.00 0.30 751.90 transit stations percent change from baseline 4.00 0.08 173.74 workplaces percent change from baseline 18.00 0.03 31.80 residential percent change from baseline -10.00 0.02 7.00 percentchangehours 3.00 0.08 75.70 percentchangebusinesses 4.00 0.06 54.14 n grade total 4.00 -0.01 0.28 daily distance diff 5.00 0.00 0.01 n grade distance 26.00 -0.00 0.22 daily visitation diff -10.00 -0.00 0.00 n grade visitation -10.00 0.00 0.75 log encounters rate -3.00 0.02 2.55 n grade encounters -10.00 -0.02 1.79 L = 10 \u00b6 Variable \u2113 maximum cov maximum cov variance retail and recreation percent change from baseline 8.00 0.04 41.47 grocery and pharmacy percent change from baseline 9.00 0.05 38.83 parks percent change from baseline 16.00 0.26 676.17 transit stations percent change from baseline 6.00 0.07 164.66 workplaces percent change from baseline 15.00 0.03 30.17 residential percent change from baseline -10.00 0.02 6.58 percentchangehours 8.00 0.08 71.48 percentchangebusinesses 9.00 0.05 51.14 n grade total 4.00 -0.01 0.27 daily distance diff 6.00 0.00 0.01 n grade distance 12.00 -0.00 0.21 daily visitation diff -10.00 -0.00 0.00 n grade visitation -10.00 0.00 0.69 log encounters rate -10.00 0.02 2.57 n grade encounters -10.00 -0.02 1.77 L = 14 \u00b6 Variable \u2113 maximum cov maximum cov variance retail and recreation percent change from baseline 11.00 0.03 37.86 grocery and pharmacy percent change from baseline 11.00 0.04 36.64 parks percent change from baseline 17.00 0.22 595.81 transit stations percent change from baseline 10.00 0.05 153.38 workplaces percent change from baseline 14.00 0.03 28.19 residential percent change from baseline -10.00 0.02 6.10 percentchangehours 11.00 0.07 66.78 percentchangebusinesses 11.00 0.04 47.53 n grade total 5.00 -0.01 0.26 daily distance diff 9.00 0.00 0.01 n grade distance 15.00 -0.00 0.19 daily visitation diff -10.00 -0.00 0.00 n grade visitation -10.00 0.00 0.62 log encounters rate -8.00 0.02 2.60 n grade encounters -10.00 -0.02 1.75 The figures above are with $L=7$. In these tables, we see that removing time fixed effects, the covariance between \u0394log\u0394cases and the measurement variables is greatly reduced. There is not a super clear pattern about what lag has the highest covariance It is not the usual arithmetic mean, but whatever value makes the equality hold. Such an $\\overline{R}$ exists by the intermediate value theorem. \u21a9","title":"Exploratory Plots"},{"location":"exploratory/#introduction","text":"This section contains some exploratory plots. using CovidData using CovidRt Error: importing CovidRt into Main conflicts with an existing identifier using TransformVariables, Parameters, Plots, StatsPlots, DataFrames, Dates, LinearAlgebra, Distributions, Random, LogDensityProblems, DynamicHMC, MCMCChains, JLD2, Latexify Plots.pyplot() using ColorSchemes colors = ColorSchemes.Set1_9 df = CovidData.statedata(policies=:indicators, fillmissingmobility=true) df[!,:log_encounters_rate] = log.(1 .+ df[!,:encounters_rate]) # create \u0394log\u0394cases sdf = filter(x->x.fips < 60, df) sort!(sdf, (:state, :date)) L1 = L2 = 7 sdf[!,:\u0394cases] = by(sdf, :state, \u0394cases = Symbol(\"cases.nyt\") => x->lagdiff(x, L1))[!,:\u0394cases]./L1 sdf[!,:\u0394log\u0394cases] = by(sdf, :state, \u0394log\u0394cases =:\u0394cases => x->lagdiff(log.(max.(x,0.1)), L2))[!,:\u0394log\u0394cases]./L2 googlevars = [:retail_and_recreation_percent_change_from_baseline, :grocery_and_pharmacy_percent_change_from_baseline, :parks_percent_change_from_baseline , :transit_stations_percent_change_from_baseline, :workplaces_percent_change_from_baseline, :residential_percent_change_from_baseline] homebasevars = [:percentchangehours, :percentchangebusinesses] unacastvars = [:n_grade_total, :daily_distance_diff, :n_grade_distance, :daily_visitation_diff, :n_grade_visitation, :log_encounters_rate, :n_grade_encounters] 7-element Array{Symbol,1}: :n_grade_total :daily_distance_diff :n_grade_distance :daily_visitation_diff :n_grade_visitation :log_encounters_rate :n_grade_encounters","title":"Introduction"},{"location":"exploratory/#choosing-lag-length","text":"Here we plot time series of $\\Delta \\log(\\Delta cases)$ and each of the activity measurements. We also plot the covariances of $\\Delta \\log(\\Delta cases)$ and $m(t+\\ell)$ as a function of $\\ell$ for each of the activity measurement variables, $m$ datelim = (Date(\"2020-03-07\"), Dates.today()) xlim = Dates.value.(datelim) function acf(df, id, t, x, y, tdiffs=[-20:20]; correlation=false) if !issorted(df, (id, t)) @error \"df not sorted\" end X = df[!,x] c = zeros(size(tdiffs)) cfn = correlation ? cor : cov for (i, t) in enumerate(tdiffs) ylag = by(df, id, ylag= y => z->CovidRt.lag(z,t))[!,:ylag] inc = .!ismissing.(X) .& .!(ismissing.(ylag)) c[i] = cfn(X[inc],ylag[inc]) end return(c) end states_to_plot = [\"New York\", \"New Jersey\",\"Massachusetts\",\"California\", \"Georgia\",\"Illinois\",\"Michigan\", \"Ohio\",\"Wisconsin\",\"Washington\"] vars = vcat(googlevars, homebasevars, unacastvars) states_to_plot = [\"New York\", \"New Jersey\",\"Massachusetts\",\"California\", \"Georgia\",\"Illinois\",\"Michigan\", \"Ohio\",\"Wisconsin\",\"Washington\"] vars = vcat(googlevars, homebasevars, unacastvars) function explorelags(vars, sdf, states_to_plot; toplot=vars, tdiffs=-10:40, correlation=true) argmaxc = zeros(Int64,length(vars)) maxc = zeros(length(vars)) for (j,v) in enumerate(vars) if v in toplot fig = Vector{Any}(undef, length(states_to_plot)) for (i, st) in enumerate(states_to_plot) subdf = filter(x->x.state.==st, sdf) fig[i] = @df subdf plot(:date, :\u0394log\u0394cases, title=st, color=colors[1], ylab=\"\u0394log\u0394cases\", xlim=xlim, legend=:topleft, labels=\"\u0394log\u0394cases\") fig[i] = twinx() fig[i] = plot!(fig[i],subdf[!,:date], subdf[!,v], color=colors[2], labels=string(v), ylab=string(v), xlim=xlim, legend=:topright) end display(plot(fig[1:4]..., layout=(2,2), reuse=false)) display(plot(fig[5:8]..., layout=(2,2), reuse=false)) end c = acf(sdf, :state, :date, :\u0394log\u0394cases, v, tdiffs, correlation=correlation) a = argmax(abs.(c)) argmaxc[j] = tdiffs[a] maxc[j] = c[a] cword = correlation ? \"Correlation\" : \"Covariance\" if v in toplot fig=plot(tdiffs, c, title=\"$cword of \u0394log\u0394cases[t] & $(string(v))[t+\u2113]\", xlab=\"\u2113\", ylab=\"$cword\", legend=:none, linewidth=1.5) display(plot(fig, reuse=false)) end end cword = correlation ? \"cor\" : \"cov\" tbl = vcat([\"Variable\" \"\u2113 maximum $cword\" \"maximum $cword\"],[replace.(string.(vars),r\"\\_\"=>s\" \") argmaxc maxc]) if !correlation tbl=hcat(tbl, [\"variance\", [var(skipmissing(sdf[!,v])) for v in vars]...]) end return(latexify(tbl, env=:mdtable, latex=false, fmt=\"%.2f\")) end tbl=explorelags(vars, sdf, states_to_plot; toplot=[:residential_percent_change_from_baseline, :percentchangebusinesses, :n_grade_total, :daily_visitation_diff, :log_encounters_rate]); println(tbl) Variable \u2113 maximum cor maximum cor retail and recreation percent change from baseline 15.00 0.80 grocery and pharmacy percent change from baseline 11.00 0.66 parks percent change from baseline 16.00 0.27 transit stations percent change from baseline 15.00 0.72 workplaces percent change from baseline 15.00 0.80 residential percent change from baseline 15.00 -0.75 percentchangehours 15.00 0.80 percentchangebusinesses 14.00 0.79 n grade total 14.00 -0.67 daily distance diff 14.00 0.75 n grade distance 14.00 -0.63 daily visitation diff 15.00 0.79 n grade visitation 15.00 -0.47 log encounters rate 16.00 0.49 n grade encounters 15.00 -0.44 Some comments: There is are noticeable weekend effects, especially in residential percent change from baseline from Google mobility reports. There\u2019s some effect of Easter visible in percent change business The variables n grade total , daily visitation diff and encounters rate are from Unacast . It is not just a coincidence that the maximum autocovariance is at $14 = L_1 + L_2$. The timing convention being followed here is that (\\Delta \\log \\Delta cases)[t] = \\log(cases[t] - cases[t-L_1]) - \\log(cases[t-L_2] - cases[t-L_2-L1]) so it is no surprise that lags of these measurement errors are correletaed with $\\Delta log \\Delta cases[t]$.","title":"Choosing lag length"},{"location":"exploratory/#given-the-long-differencing-what-are-the-correct-lags-of-measurement-variables-to-use","text":"In discrete time, the model is \\begin{align*} \\Delta C_t & = \\tau I_t \\\\ I_t & = (1+\\gamma (R_t - 1)) I_{t-1} \\end{align*} Combining these we get \\begin{align*} C_{t} - C_{t - L_1} = & \\sum_{s=t-L_1+1}^{t} \\left(\\prod_{r=t-L_1+1}^s 1 + \\gamma (R_r - 1) \\right) I_{t-L_1} \\\\ = & (1+\\gamma(\\overline{R}_{t-L_1,t}) ) I_{t-L_1} \\\\ = & (1+\\gamma(\\overline{R}_{t-L_1,t})) (1+\\gamma(\\overline{R}_{t-L_1-L_2,t-L_1})) I_{t-L_1-L2} \\end{align*} where $\\overline{R}_{t-L_1, t}$ is the \u201caverage\u201d 1 effective reproductive from time $t-L_1$ to $t$. Similarly, C_{t-L_2} - C_{t - L_2 - L_1} = (1+\\gamma(\\overline{R}_{t-L_1-L_2,t-L_2}) ) I_{t-L_1-L_2} If $L_1 = L_2$, then we get some convenient cancellations when taking the log difference: \\begin{align*} \\log (C_t - C_{t-L}) - \\log(C_{t-L} - C_{t - 2L}) = & \\log( 1 + \\gamma(\\overline{R}_{t-L,t}) ) \\\\ \\approx & \\gamma (\\overline{R}_{t-L,t} - 1) \\end{align*} !!! question Is this $L_1 = L_2$ condition correct and general? Or some artifact of this derivation? I think it would appear if the model were in continuous time as well. From this derivation, we see that \u0394log\u0394cases[t] should depend on the reproductive number of confirmed cases from time $t-L$ to $t$. Since there is a delay between infection and detection, the reproductive number of confirmed cases, depends on actual conditions some time further in the past.","title":"Given the long differencing, what are the correct lags of measurement variables to use?"},{"location":"exploratory/#moving-average-measurement-variables","text":"Motivated by the analysis in the previous section, we will use the moving average from $t-L$ to time $t$ in place of each measurement variable at time $t$. Plots.closeall() L = 7 sdf = filter(x->x.fips < 60, df) sort!(sdf, (:state, :date)) sdf[!,:\u0394cases] = by(sdf, :state, \u0394cases = Symbol(\"cases.nyt\") => x->lagdiff(x, L))[!,:\u0394cases]./L sdf[!,:\u0394log\u0394cases] = by(sdf, :state, \u0394log\u0394cases =:\u0394cases => x->lagdiff(log.(max.(x,0.1)), L))[!,:\u0394log\u0394cases]./L w = vcat(ones(L+1), zeros(L)) for v in vcat(googlevars, homebasevars, unacastvars) sdf[!,v]=by(sdf, :state, x = v => x->CovidRt.smooth(x,w=w))[!,:x] end tbl=explorelags(vars, sdf, states_to_plot; toplot=[:residential_percent_change_from_baseline, :percentchangebusinesses, :n_grade_total, :log_encounters_rate], correlation=false); println(tbl) Variable \u2113 maximum cov maximum cov variance retail and recreation percent change from baseline 14.00 2.24 426.19 grocery and pharmacy percent change from baseline 9.00 1.23 184.22 parks percent change from baseline 13.00 1.23 855.44 transit stations percent change from baseline 14.00 2.14 534.46 workplaces percent change from baseline 14.00 2.03 363.65 residential percent change from baseline 14.00 -0.79 57.28 percentchangehours 14.00 2.68 636.21 percentchangebusinesses 13.00 2.02 401.74 n grade total 12.00 -0.08 0.71 daily distance diff 14.00 0.02 0.03 n grade distance 11.00 -0.07 0.67 daily visitation diff 14.00 0.02 0.05 n grade visitation 10.00 -0.08 1.26 log encounters rate 14.00 0.11 3.13 n grade encounters 14.00 -0.08 2.16 Even after this adjustment, there is some mechanical dependence between when the maximum correlation occurs and $L$. Plots.closeall() for L in [1, 3, 7, 10, 14] sdf = filter(x->x.fips < 60, df) sort!(sdf, (:state, :date)) sdf[!,:\u0394cases] = by(sdf, :state, \u0394cases = Symbol(\"cases.nyt\") => x->lagdiff(x, L))[!,:\u0394cases]./L sdf[!,:\u0394log\u0394cases] = by(sdf, :state, \u0394log\u0394cases =:\u0394cases => x->lagdiff(log.(max.(x,0.1)), L))[!,:\u0394log\u0394cases]./L w = vcat(ones(L+1), zeros(L)) for v in vcat(googlevars, homebasevars, unacastvars) sdf[!,v]=by(sdf, :state, x = v => x->CovidRt.smooth(x,w=w))[!,:x] end @show L tbl=explorelags(vars, sdf, states_to_plot; toplot=[], correlation=false) println() println(\"### L = $L\") println() println(tbl) end L = 1","title":"Moving average measurement variables"},{"location":"exploratory/#l-1","text":"Variable \u2113 maximum cov maximum cov variance retail and recreation percent change from baseline 7.00 2.57 404.51 grocery and pharmacy percent change from baseline 5.00 1.77 206.00 parks percent change from baseline 9.00 1.70 1435.15 transit stations percent change from baseline 4.00 2.55 513.03 workplaces percent change from baseline 4.00 2.61 340.96 residential percent change from baseline 4.00 -1.01 58.31 percentchangehours 8.00 3.05 580.19 percentchangebusinesses 7.00 2.56 383.69 n grade total 7.00 -0.10 0.76 daily distance diff 7.00 0.02 0.03 n grade distance 0.00 -0.10 0.76 daily visitation diff 7.00 0.03 0.05 n grade visitation 7.00 -0.12 1.58 log encounters rate 7.00 0.12 3.07 n grade encounters 7.00 -0.09 2.23 L = 3","title":"L = 1"},{"location":"exploratory/#l-3","text":"Variable \u2113 maximum cov maximum cov variance retail and recreation percent change from baseline 8.00 2.39 410.84 grocery and pharmacy percent change from baseline 6.00 1.51 193.41 parks percent change from baseline 10.00 1.37 1116.30 transit stations percent change from baseline 6.00 2.37 520.55 workplaces percent change from baseline 6.00 2.23 346.41 residential percent change from baseline 11.00 -0.85 56.31 percentchangehours 7.00 2.91 601.86 percentchangebusinesses 6.00 2.32 390.19 n grade total 8.00 -0.09 0.72 daily distance diff 8.00 0.02 0.03 n grade distance 7.00 -0.09 0.70 daily visitation diff 8.00 0.03 0.05 n grade visitation 8.00 -0.09 1.40 log encounters rate 9.00 0.11 3.08 n grade encounters 8.00 -0.09 2.19 L = 7","title":"L = 3"},{"location":"exploratory/#l-7","text":"Variable \u2113 maximum cov maximum cov variance retail and recreation percent change from baseline 14.00 2.24 426.19 grocery and pharmacy percent change from baseline 9.00 1.23 184.22 parks percent change from baseline 13.00 1.23 855.44 transit stations percent change from baseline 14.00 2.14 534.46 workplaces percent change from baseline 14.00 2.03 363.65 residential percent change from baseline 14.00 -0.79 57.28 percentchangehours 14.00 2.68 636.21 percentchangebusinesses 13.00 2.02 401.74 n grade total 12.00 -0.08 0.71 daily distance diff 14.00 0.02 0.03 n grade distance 11.00 -0.07 0.67 daily visitation diff 14.00 0.02 0.05 n grade visitation 10.00 -0.08 1.26 log encounters rate 14.00 0.11 3.13 n grade encounters 14.00 -0.08 2.16 L = 10","title":"L = 7"},{"location":"exploratory/#l-10","text":"Variable \u2113 maximum cov maximum cov variance retail and recreation percent change from baseline 17.00 1.84 433.12 grocery and pharmacy percent change from baseline 12.00 1.02 179.09 parks percent change from baseline 16.00 1.01 771.06 transit stations percent change from baseline 17.00 1.73 538.38 workplaces percent change from baseline 17.00 1.66 371.54 residential percent change from baseline 18.00 -0.65 58.46 percentchangehours 16.00 2.22 647.28 percentchangebusinesses 15.00 1.66 406.18 n grade total 14.00 -0.06 0.71 daily distance diff 16.00 0.01 0.03 n grade distance 14.00 -0.06 0.66 daily visitation diff 18.00 0.02 0.05 n grade visitation 14.00 -0.06 1.21 log encounters rate 17.00 0.09 3.17 n grade encounters 15.00 -0.07 2.14 L = 14","title":"L = 10"},{"location":"exploratory/#l-14","text":"Variable \u2113 maximum cov maximum cov variance retail and recreation percent change from baseline 20.00 1.27 432.02 grocery and pharmacy percent change from baseline 15.00 0.72 170.79 parks percent change from baseline 19.00 0.70 684.35 transit stations percent change from baseline 19.00 1.15 532.44 workplaces percent change from baseline 19.00 1.13 373.17 residential percent change from baseline 20.00 -0.44 58.48 percentchangehours 19.00 1.53 644.77 percentchangebusinesses 17.00 1.14 402.23 n grade total 16.00 -0.05 0.70 daily distance diff 19.00 0.01 0.03 n grade distance 16.00 -0.04 0.64 daily visitation diff 21.00 0.01 0.05 n grade visitation 16.00 -0.04 1.13 log encounters rate 19.00 0.07 3.20 n grade encounters 17.00 -0.05 2.12","title":"L = 14"},{"location":"exploratory/#removing-common-time-trends","text":"In large part, the correlation between lagged measurement variabales and $\\Delta \\log \\Delta C$ is driven by a common decreasing time trend. When this decrease occurs shifts with $L$, so that might explain why the maximal correlation depends on $L$. Here, we will repeat some of the above analysis after removing time effects. mvars = vcat(googlevars, homebasevars, unacastvars) adf = aggregate(select(sdf, :date, :\u0394log\u0394cases),:date, [x->mean(skipmissing(x)), x->sqrt(var(skipmissing(x))) ], sort=true) n = length(unique(sdf.state)) @df adf plot(:date, :\u0394log\u0394cases_function, legend=:none, xlim=xlim, ribbon=1.64/sqrt(n)*:\u0394log\u0394cases_function_1, ylab=\"\u0394log\u0394cases\", title=\"Average \u0394log\u0394cases\") for L in [1, 3, 7, 10, 14] sdf = filter(x->x.fips < 60, df) sort!(sdf, (:state, :date)) sdf[!,:\u0394cases] = by(sdf, :state, \u0394cases = Symbol(\"cases.nyt\") => x->lagdiff(x, L))[!,:\u0394cases]./L sdf[!,:\u0394log\u0394cases] = by(sdf, :state, \u0394log\u0394cases =:\u0394cases => x->lagdiff(log.(max.(x,0.1)), L))[!,:\u0394log\u0394cases]./L w = vcat(ones(L+1), zeros(L)) for v in mvars sdf[!,v]=by(sdf, :state, x = v => x->CovidRt.smooth(x,w=w))[!,:x] end adf = aggregate(select(sdf, :date, :\u0394log\u0394cases, mvars...),:date, [x->mean(skipmissing(x))], sort=true) sdf = join(sdf, adf, on=:date) for v in vcat(:\u0394log\u0394cases, mvars) sdf[!,v] .= sdf[!,v] .- sdf[!, Symbol(string(v)*\"_function\")] end toplot = L==7 ? [:residential_percent_change_from_baseline, :percentchangebusinesses, :n_grade_total, :log_encounters_rate] : [] tbl=explorelags(vars, sdf, states_to_plot; toplot=toplot, tdiffs=-10:40, correlation=false) println(\"\\n### L = $L \\n\") println(tbl) println() end","title":"Removing common time trends"},{"location":"exploratory/#l-1_1","text":"Variable \u2113 maximum cov maximum cov variance retail and recreation percent change from baseline 31.00 0.15 57.34 grocery and pharmacy percent change from baseline 31.00 0.23 52.65 parks percent change from baseline 37.00 0.93 1266.70 transit stations percent change from baseline 24.00 0.19 196.32 workplaces percent change from baseline -10.00 -0.08 36.79 residential percent change from baseline -10.00 0.06 8.43 percentchangehours 9.00 0.17 90.19 percentchangebusinesses 22.00 0.13 62.22 n grade total -9.00 -0.01 0.32 daily distance diff 18.00 0.00 0.01 n grade distance 19.00 -0.01 0.28 daily visitation diff 1.00 0.00 0.00 n grade visitation 18.00 -0.01 0.92 log encounters rate -9.00 0.04 2.52 n grade encounters -9.00 -0.04 1.88","title":"L = 1"},{"location":"exploratory/#l-3_1","text":"Variable \u2113 maximum cov maximum cov variance retail and recreation percent change from baseline 0.00 0.08 51.55 grocery and pharmacy percent change from baseline 40.00 0.09 46.27 parks percent change from baseline 18.00 0.38 983.44 transit stations percent change from baseline 25.00 0.11 187.14 workplaces percent change from baseline 0.00 0.05 34.53 residential percent change from baseline -10.00 0.02 7.71 percentchangehours 0.00 0.10 83.09 percentchangebusinesses 17.00 0.08 58.55 n grade total 3.00 -0.01 0.30 daily distance diff 2.00 0.00 0.01 n grade distance 26.00 -0.00 0.25 daily visitation diff 1.00 0.00 0.00 n grade visitation 18.00 -0.01 0.85 log encounters rate 9.00 0.02 2.53 n grade encounters -10.00 -0.02 1.84","title":"L = 3"},{"location":"exploratory/#l-7_1","text":"Variable \u2113 maximum cov maximum cov variance retail and recreation percent change from baseline 5.00 0.05 44.86 grocery and pharmacy percent change from baseline 3.00 0.05 40.90 parks percent change from baseline 15.00 0.30 751.90 transit stations percent change from baseline 4.00 0.08 173.74 workplaces percent change from baseline 18.00 0.03 31.80 residential percent change from baseline -10.00 0.02 7.00 percentchangehours 3.00 0.08 75.70 percentchangebusinesses 4.00 0.06 54.14 n grade total 4.00 -0.01 0.28 daily distance diff 5.00 0.00 0.01 n grade distance 26.00 -0.00 0.22 daily visitation diff -10.00 -0.00 0.00 n grade visitation -10.00 0.00 0.75 log encounters rate -3.00 0.02 2.55 n grade encounters -10.00 -0.02 1.79","title":"L = 7"},{"location":"exploratory/#l-10_1","text":"Variable \u2113 maximum cov maximum cov variance retail and recreation percent change from baseline 8.00 0.04 41.47 grocery and pharmacy percent change from baseline 9.00 0.05 38.83 parks percent change from baseline 16.00 0.26 676.17 transit stations percent change from baseline 6.00 0.07 164.66 workplaces percent change from baseline 15.00 0.03 30.17 residential percent change from baseline -10.00 0.02 6.58 percentchangehours 8.00 0.08 71.48 percentchangebusinesses 9.00 0.05 51.14 n grade total 4.00 -0.01 0.27 daily distance diff 6.00 0.00 0.01 n grade distance 12.00 -0.00 0.21 daily visitation diff -10.00 -0.00 0.00 n grade visitation -10.00 0.00 0.69 log encounters rate -10.00 0.02 2.57 n grade encounters -10.00 -0.02 1.77","title":"L = 10"},{"location":"exploratory/#l-14_1","text":"Variable \u2113 maximum cov maximum cov variance retail and recreation percent change from baseline 11.00 0.03 37.86 grocery and pharmacy percent change from baseline 11.00 0.04 36.64 parks percent change from baseline 17.00 0.22 595.81 transit stations percent change from baseline 10.00 0.05 153.38 workplaces percent change from baseline 14.00 0.03 28.19 residential percent change from baseline -10.00 0.02 6.10 percentchangehours 11.00 0.07 66.78 percentchangebusinesses 11.00 0.04 47.53 n grade total 5.00 -0.01 0.26 daily distance diff 9.00 0.00 0.01 n grade distance 15.00 -0.00 0.19 daily visitation diff -10.00 -0.00 0.00 n grade visitation -10.00 0.00 0.62 log encounters rate -8.00 0.02 2.60 n grade encounters -10.00 -0.02 1.75 The figures above are with $L=7$. In these tables, we see that removing time fixed effects, the covariance between \u0394log\u0394cases and the measurement variables is greatly reduced. There is not a super clear pattern about what lag has the highest covariance It is not the usual arithmetic mean, but whatever value makes the equality hold. Such an $\\overline{R}$ exists by the intermediate value theorem. \u21a9","title":"L = 14"},{"location":"extensions/","text":"Another Derivation \u00b6 An alternative (and easier) way to derive the same estimator will be described here. This approach will easily generalize to more complicated models, but let\u2019s begin with the simplest SIR model with testing. \\begin{align*} \\dot{S} & = -\\frac{S}{N} \\beta I \\\\ \\dot{I} & = \\frac{S}{N} \\beta I - \\gamma I \\\\ \\dot{C} & = \\tau I \\\\ \\dot{\\mathcal{R}} & = \\gamma I \\end{align*} Then note that \\ddot{C} = \\dot{\\tau} I + \\tau \\dot{I} and \\begin{align*} \\frac{\\ddot{C}}{\\dot{C}} = & \\frac{\\dot{\\tau}}{\\tau} + \\frac{\\dot{I}}{I} \\\\ \\frac{d}{dt} \\log(\\dot{C}) = & \\frac{\\dot{\\tau}}{\\tau} + \\frac{S}{N}\\beta - \\gamma \\\\ = & \\frac{\\dot{\\tau}}{\\tau} + \\gamma(R_t - 1) \\end{align*} which is the equation we have been using for estimation. Incorporating death \u00b6 If we add deaths to the model, \\begin{align*} \\dot{S} & = -\\frac{S}{N} \\beta I \\\\ \\dot{I} & = \\frac{S}{N} \\beta I - \\gamma I - p I\\\\ \\dot{C} & = \\tau I \\\\ \\dot{\\mathcal{R}} & = \\gamma I \\\\ \\dot{D} & = p I \\end{align*} then, \\begin{align*} \\frac{\\ddot{C}}{\\dot{C}} = & \\frac{\\dot{\\tau}}{\\tau} + \\frac{S}{N}\\beta - \\gamma - p \\\\ \\frac{\\ddot{D}}{\\dot{D}} = & \\frac{S}{N}\\beta - \\gamma - p \\\\ \\end{align*} Other observable states could similarly be added to the model. Time delays \u00b6 A drawback of the above approach is that it implies changes in $R_t$ show up in the derivatives of case and death numbers instantly. This is definitely not true. Instead consider a model where infections last $\\ell$ days. After $\\ell$ days, each infected person dies with probability $\\pi$ and recovers otherwise. Then we have \\begin{align*} \\dot{S}(t) & = -\\frac{S(t)}{N} \\beta I \\\\ \\dot{I}(t) & = \\frac{S(t)}{N} \\beta(t) I(t) - \\frac{S(t-\\ell)}{N} \\beta(t-\\ell) I(t-\\ell) \\\\ \\dot{C}(t) & = \\tau(t) I(t) \\\\ \\dot{\\mathcal{R}}(t) & = (1-\\pi) \\frac{S(t-\\ell)}{N} \\beta(t-\\ell) I(t-\\ell) \\\\ \\dot{D}(t) & = \\pi \\frac{S(t-\\ell)}{N} \\beta(t-\\ell) I(t-\\ell) \\end{align*} Rearranging gives \\frac{\\ddot{C}(t)}{\\dot{C}(t)} = \\frac{\\dot{\\tau}(t)}{\\tau(t)} + \\frac{S(t)}{N}\\beta(t) - \\frac{1}{\\pi} \\frac{\\dot{D}(t)}{\\dot{C}(t)} and \\dot{D}(t) = \\pi \\frac{S(t-\\ell)}{N} \\beta(t-\\ell) \\frac{\\dot{C}(t-\\ell)}{\\tau(t-\\ell)} Note These last two equations also hold in the model without time delay by setting $\\ell=0$ and $\\pi = \\frac{p}{p+\\gamma}$ Note Random durations can be accomodated by replacing the shift by $\\ell$ with a convolution.","title":"Extensions"},{"location":"extensions/#another-derivation","text":"An alternative (and easier) way to derive the same estimator will be described here. This approach will easily generalize to more complicated models, but let\u2019s begin with the simplest SIR model with testing. \\begin{align*} \\dot{S} & = -\\frac{S}{N} \\beta I \\\\ \\dot{I} & = \\frac{S}{N} \\beta I - \\gamma I \\\\ \\dot{C} & = \\tau I \\\\ \\dot{\\mathcal{R}} & = \\gamma I \\end{align*} Then note that \\ddot{C} = \\dot{\\tau} I + \\tau \\dot{I} and \\begin{align*} \\frac{\\ddot{C}}{\\dot{C}} = & \\frac{\\dot{\\tau}}{\\tau} + \\frac{\\dot{I}}{I} \\\\ \\frac{d}{dt} \\log(\\dot{C}) = & \\frac{\\dot{\\tau}}{\\tau} + \\frac{S}{N}\\beta - \\gamma \\\\ = & \\frac{\\dot{\\tau}}{\\tau} + \\gamma(R_t - 1) \\end{align*} which is the equation we have been using for estimation.","title":"Another Derivation"},{"location":"extensions/#incorporating-death","text":"If we add deaths to the model, \\begin{align*} \\dot{S} & = -\\frac{S}{N} \\beta I \\\\ \\dot{I} & = \\frac{S}{N} \\beta I - \\gamma I - p I\\\\ \\dot{C} & = \\tau I \\\\ \\dot{\\mathcal{R}} & = \\gamma I \\\\ \\dot{D} & = p I \\end{align*} then, \\begin{align*} \\frac{\\ddot{C}}{\\dot{C}} = & \\frac{\\dot{\\tau}}{\\tau} + \\frac{S}{N}\\beta - \\gamma - p \\\\ \\frac{\\ddot{D}}{\\dot{D}} = & \\frac{S}{N}\\beta - \\gamma - p \\\\ \\end{align*} Other observable states could similarly be added to the model.","title":"Incorporating death"},{"location":"extensions/#time-delays","text":"A drawback of the above approach is that it implies changes in $R_t$ show up in the derivatives of case and death numbers instantly. This is definitely not true. Instead consider a model where infections last $\\ell$ days. After $\\ell$ days, each infected person dies with probability $\\pi$ and recovers otherwise. Then we have \\begin{align*} \\dot{S}(t) & = -\\frac{S(t)}{N} \\beta I \\\\ \\dot{I}(t) & = \\frac{S(t)}{N} \\beta(t) I(t) - \\frac{S(t-\\ell)}{N} \\beta(t-\\ell) I(t-\\ell) \\\\ \\dot{C}(t) & = \\tau(t) I(t) \\\\ \\dot{\\mathcal{R}}(t) & = (1-\\pi) \\frac{S(t-\\ell)}{N} \\beta(t-\\ell) I(t-\\ell) \\\\ \\dot{D}(t) & = \\pi \\frac{S(t-\\ell)}{N} \\beta(t-\\ell) I(t-\\ell) \\end{align*} Rearranging gives \\frac{\\ddot{C}(t)}{\\dot{C}(t)} = \\frac{\\dot{\\tau}(t)}{\\tau(t)} + \\frac{S(t)}{N}\\beta(t) - \\frac{1}{\\pi} \\frac{\\dot{D}(t)}{\\dot{C}(t)} and \\dot{D}(t) = \\pi \\frac{S(t-\\ell)}{N} \\beta(t-\\ell) \\frac{\\dot{C}(t-\\ell)}{\\tau(t-\\ell)} Note These last two equations also hold in the model without time delay by setting $\\ell=0$ and $\\pi = \\frac{p}{p+\\gamma}$ Note Random durations can be accomodated by replacing the shift by $\\ell$ with a convolution.","title":"Time delays"},{"location":"license/","text":"The notes and results are licensed under a Creative Commons Attribution-ShareAlike 4.0 International License and were written by Paul Schrimpf. BibTeX citation. The license for the package source code is here.","title":"License"},{"location":"rt_longdiff/","text":"Longer Differences and Smoothing \u00b6 One way to reduce $\\sigma_k/\\sigma_R$ is to reduce noise in new cases by taking a longer difference or smoothing case counts in some other way. How does this affect the estimation and interpretation of $R_t$? As in the first section, we start with the approximate recursive relation C(t) - C(t-1) \\equiv \\Delta C(t) \\approx \\frac{\\tau(t)}{\\tau(t-1)} e^{\\gamma (R_t - 1)} \\Delta C(t-1) If we instead look at a longer difference, \\begin{align*} C(t) - C(t-L) = & \\sum_{i=0}^{L-1} \\Delta C_{t-i} \\\\ \\approx & \\sum_{i=0}^{L-1} \\frac{\\tau(t-i)}{\\tau(t-i-1)} e^{\\gamma (R_{t-i} - 1)} \\Delta C_{t-i-1} \\\\ = & \\overline {T_{t,L} e^{\\gamma(R_{t,L} - 1)}} \\sum_{i=0}^{L-1}\\Delta C_{t-i-1} \\\\ = & \\overline {T_{t,L} e^{\\gamma(R_{t,L} - 1)}} \\left( C(t-1) - C(t-1-L) \\right) \\end{align*} where $\\overline {T_{t,L} e^{\\gamma(R_{t,L} - 1)}}$ is some intermediate value in between the minimum and maximum of the ${ \\frac{\\tau(t-i)}{\\tau(t-i-1)} e^{\\gamma (R_{t-i} - 1)} }_{i=0}^{L-1}$. If testing is constant over time, we can then obtain an interpretable $\\overline{R_{t,L}}$ by using $k_{t,L} =\\log(C(t)-C(t-L))$ and following the procedure above. If testing varies with time, it becomes hard to separate testing rate changes from $R_t$ after taking long differnces. Note The same analysis can be applied to other smoothing operations, i.e. using \\sum_{i=0}^L w_i \\Delta C_{t-i} in place of $C(t) - C(t-L)$. However, there\u2019s something strange about smoothing $C_t$, and then extracting a smoothed component of it using the Kalman filter. The inference afterwards is suspect; we would essentially be estimating a kernel regression of $C_t$ on time, and using the estimated regression as though it\u2019s known with certainty. When would long differences reduce variance? Well if $\\Delta C(t) = \\Delta C^\\ast(t) + \\epsilon_t$ with $\\epsilon_t$ indepenedent over time with mean $0$ and constant variance, then you would need $C^\\ast(t) - C^\\ast(t-L)$ to increase faster than linearly with $L$. This is true if $C^\\ast$ is growing exponentially. Alternatively, if $\\epsilon_t$ is not independent over time, but negatively correlated (as seems likely), then variance can decrease with $L$. For example, if $\\Delta C(t) = C^\\ast(t) - C^\\ast(t-\\delta)$ with $\\delta$ a random, independent increment with mean $1$, then variance will tend to decrease with $L$ regardless of $C^\\ast(t)$. Results \u00b6 # data prep using CovidData using CovidRt using TransformVariables, Parameters, Plots, StatsPlots, DataFrames, Dates, LinearAlgebra, Distributions, Random, LogDensityProblems, DynamicHMC, MCMCChains, JLD2, Latexify Plots.pyplot() df = CovidData.statedata(policies=:indicators, fillmissingmobility=true) pvars = [Symbol(\"Stay.at.home..shelter.in.place\"), #Symbol(\"State.of.emergency\"), Symbol(\"Date.closed.K.12.schools\"), Symbol(\"Closed.gyms\"), Symbol(\"Closed.movie.theaters\"), Symbol(\"Closed.day.cares\"), Symbol(\"Date.banned.visitors.to.nursing.homes\"), Symbol(\"Closed.non.essential.businesses\"), Symbol(\"Closed.restaurants.except.take.out\")] mvars = [:retail_and_recreation_percent_change_from_baseline, :grocery_and_pharmacy_percent_change_from_baseline, :parks_percent_change_from_baseline , :transit_stations_percent_change_from_baseline, :workplaces_percent_change_from_baseline, :residential_percent_change_from_baseline, :percentchangebusinesses] df[!,:logpopdens] = log.(df[!,Symbol(\"Population.density.per.square.miles\")]) df[!,:weekend] = dayofweek.(df[!,:date]) .>= 6 x0vars=[:constant, :logpopdens, Symbol(\"Percent.Unemployed..2018.\"), Symbol(\"Percent.living.under.the.federal.poverty.line..2018.\"), Symbol(\"Percent.at.risk.for.serious.illness.due.to.COVID\")] sdf = filter(x->x.fips<60, df) sdf = sort(sdf, (:state, :date)) sdf[!,mvars] ./= 100 sdf[!,:constant] .= 1 xvars = vcat(pvars,mvars, x0vars); Here, we will allow the initial and time varying mean of $R_{s,t}$ to depend on covariates. \\begin{align*} \\tilde{R}_{s,0} & \\sim N(X_{0,s} \\alpha_0, \\sigma^2_{R,0}) \\\\ \\tilde{R}_{s,t} & = \\rho \\tilde{R}_{s,t} + u_{s,t} \\;,\\; u_{s,t} \\sim N(0, \\sigma^2_R) \\\\ R_{s,t} & = X_{s,t} \\alpha + \\tilde{R}_{s,t} \\\\ \\Delta \\log(k)_{s,t} & = \\gamma (R_{s,t} - 1) + \\epsilon_{s,t} - \\epsilon_{s,t-1} \\;, \\; \\epsilon_{s,t} \\sim N(0, \\sigma^2_k) \\end{align*} We present estimates of $R_t$ with \\Delta C(t) = C(t) - C(t-L_1) and \\Delta log (\\Delta C(t)) = log (\\Delta C(t)) - log (\\Delta C(t - L_2)) for a variety of values of $L_1$ and $L_2$ reestimate=false rlo=-1 #1 - eps(Float64) rhi=1.2 #1+ eps(Float64) K = length(xvars) priors = (\u03b3 = truncated(Normal(1/7,1/7), 1/28, 1/1), \u03c3R0 = truncated(Normal(1, 3), 0, Inf), \u03b10 = MvNormal(zeros(length(x0vars)), sqrt(10)), #truncated(Normal(1, 3), 0, Inf), \u03c3R = truncated(Normal(0.25,1),0,Inf), \u03c3k = truncated(Normal(0.1, 5), 0, Inf), \u03c1 = Uniform(rlo, rhi), \u03b1 = MvNormal(zeros(K), sqrt(10)) ) states_to_plot = [\"New York\", \"New Jersey\",\"Massachusetts\",\"California\", \"Georgia\",\"Illinois\",\"Michigan\", \"Ohio\",\"Wisconsin\",\"Washington\"] warmup = default_warmup_stages(local_optimization=nothing, stepsize_search=nothing, init_steps=100, middle_steps=100, terminating_steps=2*100, doubling_stages=2, M=Symmetric) for L1 in [1, 3, 7] for L2 in [1, 3, 7] mdl = CovidRt.RtModel(sdf, Symbol(\"cases.nyt\"), xvars, x0vars, priors; L1=L1, L2=L2, time0=r->(r[Symbol(\"cases.nyt\")].>=5)) estfile = \"rt$(L1)_$(L2).jld2\" if !isfile(estfile) || reestimate post = CovidRt.mcmc(mdl; iterations=2000, warmup=warmup) @save estfile post end @load estfile post cc = CovidRt.MCMCChain(post, xvars, x0vars) println(\"## L\u2081 = $(L1), L\u2082 = $(L2)\") println() #display(plot(cc)) println(latexify(DataFrame(describe(cc)[1]), env=:mdtable, latex=false, fmt=x->round(x, sigdigits=3))) println(latexify(DataFrame(describe(cc)[2]), env=:mdtable, latex=false, fmt=x->round(x, sigdigits=3))) states = mdl.id S = length(states_to_plot) figs = fill(plot(), S) for (i,st) in enumerate(states_to_plot) s = findfirst(states.==st) figr = CovidRt.plotpostr(mdl.t[s],mdl.dlogk[s],post, mdl.X[s], mdl.X0[s]) l = @layout [a{.1h}; grid(1,1)] figs[i] = plot(plot(annotation=(0.5,0.5, st*\", L\u2081=$(L1) L\u2082=$(L2)\"), framestyle = :none), plot(figr, ylim=(-1,15)), layout=l) display(figs[i]) end end end L\u2081 = 1, L\u2082 = 1 \u00b6 parameters mean std naive_se mcse ess r_hat \u03b3 0.239 0.0357 0.000797 0.00171 392.0 1.0 \u03c3R0 8.32 1.31 0.0292 0.0504 680.0 1.0 \u03b10(constant) 0.113 3.1 0.0693 0.0656 2710.0 1.0 \u03b10(logpopdens) -2.12 1.51 0.0339 0.0292 2220.0 1.0 \u03b10(Percent Unemployed 2018 ) -3.44 2.07 0.0463 0.0384 2510.0 1.0 \u03b10(Percent living under the federal poverty line 2018 ) 0.73 1.07 0.024 0.0234 2880.0 1.0 \u03b10(Percent at risk for serious illness due to COVID) 0.144 0.388 0.00867 0.00782 2300.0 1.0 \u03c3R 3.71 0.527 0.0118 0.0213 550.0 1.0 \u03c3k 0.0262 0.0198 0.000442 0.000352 2210.0 1.0 \u03c1 -0.475 0.0165 0.000369 0.000338 2960.0 1.0 \u03b1(Stay at home shelter in place) -0.251 0.167 0.00373 0.00388 2360.0 1.0 \u03b1(Date closed K 12 schools) -0.0818 0.244 0.00545 0.00497 2060.0 1.0 \u03b1(Closed gyms) -0.209 0.308 0.00688 0.00585 2650.0 1.0 \u03b1(Closed movie theaters) 0.114 0.312 0.00697 0.00537 2530.0 1.0 \u03b1(Closed day cares) 0.0187 0.15 0.00335 0.00311 2150.0 1.0 \u03b1(Date banned visitors to nursing homes) -0.0227 0.12 0.00269 0.00216 2960.0 1.0 \u03b1(Closed non essential businesses) -0.132 0.163 0.00364 0.00341 2850.0 1.0 \u03b1(Closed restaurants except take out) 0.124 0.259 0.0058 0.00456 2420.0 1.0 \u03b1(retail and recreation percent change from baseline) -0.828 0.909 0.0203 0.0136 2080.0 1.0 \u03b1(grocery and pharmacy percent change from baseline) 0.89 0.696 0.0156 0.0127 2400.0 1.0 \u03b1(parks percent change from baseline) 0.232 0.184 0.00412 0.00331 2520.0 1.0 \u03b1(transit stations percent change from baseline) -0.0128 0.759 0.017 0.0119 2340.0 1.0 \u03b1(workplaces percent change from baseline) -1.82 1.22 0.0274 0.0245 2320.0 1.0 \u03b1(residential percent change from baseline) 2.05 2.23 0.0498 0.041 2300.0 1.0 \u03b1(percentchangebusinesses) 3.62 1.01 0.0227 0.0237 1940.0 1.0 \u03b1(constant) -0.235 0.728 0.0163 0.0149 2600.0 1.0 \u03b1(logpopdens) 0.0761 0.0468 0.00105 0.000724 2660.0 1.0 \u03b1(Percent Unemployed 2018 ) 0.126 0.0884 0.00198 0.0016 2930.0 1.0 \u03b1(Percent living under the federal poverty line 2018 ) -0.0405 0.0385 0.000861 0.000637 2450.0 1.0 \u03b1(Percent at risk for serious illness due to COVID) 0.0426 0.0214 0.000478 0.000407 2420.0 1.0 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.182 0.214 0.233 0.259 0.323 \u03c3R0 5.9 7.42 8.28 9.18 11.0 \u03b10(constant) -6.16 -1.91 0.128 2.17 6.24 \u03b10(logpopdens) -5.11 -3.09 -2.15 -1.14 0.913 \u03b10(Percent Unemployed 2018 ) -7.45 -4.89 -3.42 -2.05 0.725 \u03b10(Percent living under the federal poverty line 2018 ) -1.34 0.0173 0.778 1.41 2.81 \u03b10(Percent at risk for serious illness due to COVID) -0.592 -0.108 0.148 0.407 0.924 \u03c3R 2.67 3.35 3.71 4.05 4.75 \u03c3k 0.00123 0.0105 0.0217 0.0379 0.0743 \u03c1 -0.507 -0.486 -0.475 -0.464 -0.444 \u03b1(Stay at home shelter in place) -0.604 -0.36 -0.247 -0.139 0.075 \u03b1(Date closed K 12 schools) -0.572 -0.24 -0.0844 0.0819 0.385 \u03b1(Closed gyms) -0.847 -0.41 -0.203 -0.0025 0.393 \u03b1(Closed movie theaters) -0.494 -0.0936 0.117 0.313 0.743 \u03b1(Closed day cares) -0.278 -0.0776 0.0183 0.115 0.32 \u03b1(Date banned visitors to nursing homes) -0.259 -0.102 -0.0228 0.0558 0.217 \u03b1(Closed non essential businesses) -0.458 -0.244 -0.132 -0.0219 0.183 \u03b1(Closed restaurants except take out) -0.37 -0.0541 0.119 0.294 0.653 \u03b1(retail and recreation percent change from baseline) -2.65 -1.44 -0.822 -0.231 0.95 \u03b1(grocery and pharmacy percent change from baseline) -0.413 0.396 0.875 1.35 2.25 \u03b1(parks percent change from baseline) -0.125 0.105 0.234 0.353 0.6 \u03b1(transit stations percent change from baseline) -1.5 -0.496 -0.0322 0.482 1.51 \u03b1(workplaces percent change from baseline) -4.29 -2.6 -1.8 -0.959 0.527 \u03b1(residential percent change from baseline) -2.35 0.585 2.04 3.5 6.44 \u03b1(percentchangebusinesses) 1.71 2.92 3.58 4.29 5.71 \u03b1(constant) -1.7 -0.714 -0.215 0.259 1.15 \u03b1(logpopdens) -0.00923 0.0433 0.0737 0.107 0.172 \u03b1(Percent Unemployed 2018 ) -0.0407 0.0682 0.123 0.18 0.303 \u03b1(Percent living under the federal poverty line 2018 ) -0.121 -0.0657 -0.0396 -0.014 0.0318 \u03b1(Percent at risk for serious illness due to COVID) 0.00154 0.028 0.0423 0.0566 0.0878 L\u2081 = 1, L\u2082 = 3 \u00b6 parameters mean std naive_se mcse ess r_hat \u03b3 0.0486 0.00898 0.000201 0.000486 453.0 1.0 \u03c3R0 8.31 1.52 0.0339 0.0496 814.0 1.0 \u03b10(constant) 0.318 3.12 0.0697 0.141 853.0 1.0 \u03b10(logpopdens) 1.09 2.25 0.0503 0.0897 646.0 1.0 \u03b10(Percent Unemployed 2018 ) 2.12 2.72 0.0609 0.103 649.0 1.0 \u03b10(Percent living under the federal poverty line 2018 ) -0.382 1.86 0.0417 0.0718 735.0 1.0 \u03b10(Percent at risk for serious illness due to COVID) 0.341 0.678 0.0152 0.0333 512.0 1.0 \u03c3R 1.0 0.787 0.0176 0.0307 735.0 1.0 \u03c3k 0.243 0.00917 0.000205 0.000368 630.0 1.0 \u03c1 0.374 0.12 0.00269 0.00501 638.0 1.0 \u03b1(Stay at home shelter in place) -1.78 0.568 0.0127 0.0364 264.0 1.0 \u03b1(Date closed K 12 schools) 0.0879 0.634 0.0142 0.0235 866.0 1.0 \u03b1(Closed gyms) -1.03 0.874 0.0196 0.0336 482.0 1.0 \u03b1(Closed movie theaters) 0.219 0.89 0.0199 0.0321 553.0 1.0 \u03b1(Closed day cares) -0.0219 0.408 0.00913 0.0113 1030.0 1.0 \u03b1(Date banned visitors to nursing homes) -0.167 0.348 0.00778 0.0144 695.0 1.0 \u03b1(Closed non essential businesses) -0.729 0.506 0.0113 0.022 437.0 1.0 \u03b1(Closed restaurants except take out) 0.343 0.729 0.0163 0.0286 707.0 1.0 \u03b1(retail and recreation percent change from baseline) -0.112 1.92 0.043 0.0532 884.0 1.0 \u03b1(grocery and pharmacy percent change from baseline) 1.66 1.62 0.0363 0.0664 888.0 1.01 \u03b1(parks percent change from baseline) 0.128 0.483 0.0108 0.0152 682.0 1.0 \u03b1(transit stations percent change from baseline) 2.63 1.86 0.0415 0.0834 403.0 1.0 \u03b1(workplaces percent change from baseline) -4.1 1.99 0.0446 0.0719 699.0 1.0 \u03b1(residential percent change from baseline) 4.86 2.9 0.0649 0.123 614.0 1.0 \u03b1(percentchangebusinesses) 6.48 1.99 0.0444 0.109 527.0 1.0 \u03b1(constant) -0.0214 1.69 0.0378 0.0512 914.0 1.0 \u03b1(logpopdens) 0.379 0.137 0.00306 0.00498 761.0 1.0 \u03b1(Percent Unemployed 2018 ) 0.64 0.264 0.00591 0.0131 512.0 1.0 \u03b1(Percent living under the federal poverty line 2018 ) -0.25 0.113 0.00252 0.00509 625.0 1.0 \u03b1(Percent at risk for serious illness due to COVID) 0.119 0.0563 0.00126 0.00192 813.0 1.0 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0364 0.0417 0.0469 0.0537 0.071 \u03c3R0 5.59 7.23 8.23 9.35 11.5 \u03b10(constant) -5.84 -1.81 0.406 2.48 6.26 \u03b10(logpopdens) -3.23 -0.449 0.994 2.5 5.58 \u03b10(Percent Unemployed 2018 ) -3.34 0.356 2.15 3.95 7.32 \u03b10(Percent living under the federal poverty line 2018 ) -3.6 -1.68 -0.513 0.771 3.61 \u03b10(Percent at risk for serious illness due to COVID) -0.92 -0.102 0.354 0.751 1.72 \u03c3R 0.0363 0.343 0.807 1.51 2.83 \u03c3k 0.218 0.24 0.245 0.248 0.253 \u03c1 0.152 0.284 0.373 0.464 0.609 \u03b1(Stay at home shelter in place) -3.06 -2.12 -1.73 -1.37 -0.773 \u03b1(Date closed K 12 schools) -1.2 -0.331 0.0943 0.515 1.35 \u03b1(Closed gyms) -2.84 -1.62 -1.01 -0.406 0.591 \u03b1(Closed movie theaters) -1.48 -0.401 0.204 0.811 2.09 \u03b1(Closed day cares) -0.793 -0.299 -0.0275 0.255 0.824 \u03b1(Date banned visitors to nursing homes) -0.863 -0.405 -0.163 0.0635 0.493 \u03b1(Closed non essential businesses) -1.74 -1.08 -0.719 -0.395 0.297 \u03b1(Closed restaurants except take out) -1.13 -0.155 0.346 0.846 1.74 \u03b1(retail and recreation percent change from baseline) -3.86 -1.33 -0.12 1.12 3.73 \u03b1(grocery and pharmacy percent change from baseline) -1.52 0.62 1.62 2.78 4.96 \u03b1(parks percent change from baseline) -0.849 -0.186 0.124 0.439 1.1 \u03b1(transit stations percent change from baseline) -0.882 1.41 2.58 3.85 6.54 \u03b1(workplaces percent change from baseline) -8.02 -5.46 -4.09 -2.75 -0.433 \u03b1(residential percent change from baseline) -0.71 2.89 4.83 6.77 10.6 \u03b1(percentchangebusinesses) 2.78 5.13 6.4 7.81 10.6 \u03b1(constant) -3.24 -1.16 -0.0416 1.1 3.32 \u03b1(logpopdens) 0.118 0.282 0.375 0.473 0.66 \u03b1(Percent Unemployed 2018 ) 0.148 0.457 0.622 0.818 1.19 \u03b1(Percent living under the federal poverty line 2018 ) -0.479 -0.323 -0.245 -0.17 -0.0511 \u03b1(Percent at risk for serious illness due to COVID) 0.0131 0.0816 0.119 0.156 0.23 L\u2081 = 1, L\u2082 = 7 \u00b6 parameters mean std naive_se mcse ess r_hat \u03b3 0.0376 0.0017 3.79e-5 0.000119 150.0 1.0 \u03c3R0 4.06 0.499 0.0112 0.0455 114.0 1.0 \u03b10(constant) 0.0666 1.15 0.0257 0.23 8.3 1.21 \u03b10(logpopdens) -0.000728 0.63 0.0141 0.0962 10.6 1.14 \u03b10(Percent Unemployed 2018 ) 0.473 0.836 0.0187 0.137 22.9 1.02 \u03b10(Percent living under the federal poverty line 2018 ) -0.285 0.416 0.0093 0.0636 43.0 1.0 \u03b10(Percent at risk for serious illness due to COVID) 0.277 0.138 0.00308 0.0187 42.5 1.03 \u03c3R 0.966 0.0988 0.00221 0.0105 58.1 1.01 \u03c3k 0.101 0.00174 3.89e-5 9.73e-5 366.0 1.0 \u03c1 0.909 0.0108 0.000242 0.00107 56.8 1.01 \u03b1(Stay at home shelter in place) -1.65 0.427 0.00955 0.07 13.6 1.07 \u03b1(Date closed K 12 schools) 1.11 0.574 0.0128 0.0776 17.0 1.18 \u03b1(Closed gyms) 0.0444 0.736 0.0165 0.105 20.0 1.14 \u03b1(Closed movie theaters) -0.89 0.721 0.0161 0.0991 25.7 1.06 \u03b1(Closed day cares) -0.0539 0.468 0.0105 0.076 14.4 1.15 \u03b1(Date banned visitors to nursing homes) -0.553 0.452 0.0101 0.0607 69.1 1.0 \u03b1(Closed non essential businesses) -0.57 0.477 0.0107 0.0673 27.4 1.0 \u03b1(Closed restaurants except take out) 0.386 0.559 0.0125 0.0758 20.8 1.05 \u03b1(retail and recreation percent change from baseline) -2.23 1.51 0.0338 0.23 15.8 1.09 \u03b1(grocery and pharmacy percent change from baseline) -1.36 1.19 0.0267 0.236 9.5 1.16 \u03b1(parks percent change from baseline) 0.269 0.328 0.00734 0.0473 19.2 1.06 \u03b1(transit stations percent change from baseline) 0.982 1.04 0.0234 0.206 8.25 1.24 \u03b1(workplaces percent change from baseline) -0.467 1.5 0.0335 0.303 12.2 1.11 \u03b1(residential percent change from baseline) 1.66 1.14 0.0255 0.196 18.6 1.01 \u03b1(percentchangebusinesses) 1.59 0.935 0.0209 0.185 8.39 1.17 \u03b1(constant) 1.72 2.23 0.0499 0.461 8.03 1.63 \u03b1(logpopdens) 0.461 0.196 0.00439 0.0276 23.5 1.04 \u03b1(Percent Unemployed 2018 ) 0.163 0.335 0.00749 0.0422 73.9 1.0 \u03b1(Percent living under the federal poverty line 2018 ) -0.0466 0.152 0.00341 0.017 86.5 1.03 \u03b1(Percent at risk for serious illness due to COVID) -0.0393 0.0822 0.00184 0.0155 8.04 1.49 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0358 0.0363 0.0371 0.0384 0.0421 \u03c3R0 3.1 3.72 4.06 4.37 5.08 \u03b10(constant) -1.79 -0.782 -0.0349 0.723 2.66 \u03b10(logpopdens) -1.31 -0.393 0.0157 0.405 1.26 \u03b10(Percent Unemployed 2018 ) -1.27 -0.061 0.472 1.02 2.2 \u03b10(Percent living under the federal poverty line 2018 ) -1.02 -0.583 -0.299 -0.022 0.612 \u03b10(Percent at risk for serious illness due to COVID) -0.00983 0.187 0.277 0.377 0.541 \u03c3R 0.774 0.896 0.967 1.03 1.16 \u03c3k 0.098 0.1 0.101 0.102 0.105 \u03c1 0.884 0.903 0.91 0.917 0.928 \u03b1(Stay at home shelter in place) -2.4 -1.98 -1.66 -1.33 -0.842 \u03b1(Date closed K 12 schools) -0.0586 0.743 1.12 1.47 2.25 \u03b1(Closed gyms) -1.24 -0.49 0.0234 0.538 1.62 \u03b1(Closed movie theaters) -2.48 -1.29 -0.884 -0.428 0.468 \u03b1(Closed day cares) -0.999 -0.342 -0.0439 0.268 0.835 \u03b1(Date banned visitors to nursing homes) -1.54 -0.862 -0.547 -0.24 0.259 \u03b1(Closed non essential businesses) -1.44 -0.919 -0.577 -0.223 0.311 \u03b1(Closed restaurants except take out) -0.786 0.0367 0.376 0.769 1.45 \u03b1(retail and recreation percent change from baseline) -5.66 -3.11 -2.03 -1.15 0.295 \u03b1(grocery and pharmacy percent change from baseline) -3.92 -1.99 -1.17 -0.577 0.719 \u03b1(parks percent change from baseline) -0.353 0.0219 0.282 0.509 0.883 \u03b1(transit stations percent change from baseline) -0.957 0.256 0.993 1.59 3.14 \u03b1(workplaces percent change from baseline) -3.27 -1.72 -0.313 0.717 2.24 \u03b1(residential percent change from baseline) -0.81 0.945 1.83 2.44 3.66 \u03b1(percentchangebusinesses) 0.0313 0.741 1.74 2.32 3.13 \u03b1(constant) -2.75 0.00553 2.2 3.52 4.98 \u03b1(logpopdens) 0.113 0.318 0.457 0.602 0.835 \u03b1(Percent Unemployed 2018 ) -0.61 -0.0321 0.192 0.396 0.746 \u03b1(Percent living under the federal poverty line 2018 ) -0.323 -0.151 -0.0469 0.0561 0.266 \u03b1(Percent at risk for serious illness due to COVID) -0.177 -0.0958 -0.0514 0.0176 0.13 L\u2081 = 3, L\u2082 = 1 \u00b6 parameters mean std naive_se mcse ess r_hat \u03b3 0.0749 0.0147 0.000328 0.000426 721.0 1.0 \u03c3R0 10.1 1.81 0.0404 0.0452 891.0 1.0 \u03b10(constant) 0.192 3.17 0.0709 0.0734 2150.0 1.0 \u03b10(logpopdens) 1.02 2.96 0.0661 0.0712 2220.0 1.0 \u03b10(Percent Unemployed 2018 ) 0.777 3.11 0.0695 0.0701 2300.0 1.0 \u03b10(Percent living under the federal poverty line 2018 ) 0.744 2.77 0.0619 0.0792 2020.0 1.0 \u03b10(Percent at risk for serious illness due to COVID) 1.62 1.47 0.0328 0.0527 900.0 1.0 \u03c3R 1.39 0.772 0.0173 0.0229 1280.0 1.0 \u03c3k 0.189 0.0191 0.000428 0.00059 1020.0 1.0 \u03c1 0.0952 0.038 0.00085 0.00108 1290.0 1.0 \u03b1(Stay at home shelter in place) -1.06 0.333 0.00745 0.00883 1210.0 1.0 \u03b1(Date closed K 12 schools) 0.303 0.389 0.00869 0.00864 2330.0 1.0 \u03b1(Closed gyms) -0.453 0.518 0.0116 0.0108 2110.0 1.0 \u03b1(Closed movie theaters) 0.0294 0.532 0.0119 0.00911 2190.0 1.0 \u03b1(Closed day cares) -0.0225 0.247 0.00552 0.00508 2700.0 1.0 \u03b1(Date banned visitors to nursing homes) -0.12 0.197 0.00441 0.00461 2070.0 1.0 \u03b1(Closed non essential businesses) -0.568 0.306 0.00684 0.0067 2070.0 1.0 \u03b1(Closed restaurants except take out) 0.0813 0.434 0.0097 0.00796 2950.0 1.0 \u03b1(retail and recreation percent change from baseline) -0.19 1.31 0.0292 0.022 2300.0 1.0 \u03b1(grocery and pharmacy percent change from baseline) 1.92 1.06 0.0237 0.0253 2130.0 1.0 \u03b1(parks percent change from baseline) 0.0128 0.274 0.00613 0.00538 2650.0 1.0 \u03b1(transit stations percent change from baseline) 2.12 1.17 0.0262 0.0278 2180.0 1.0 \u03b1(workplaces percent change from baseline) -1.22 1.61 0.036 0.0329 2170.0 1.0 \u03b1(residential percent change from baseline) 6.75 2.5 0.0558 0.038 2600.0 1.0 \u03b1(percentchangebusinesses) 3.01 1.31 0.0294 0.0256 2100.0 1.0 \u03b1(constant) -0.0793 1.08 0.0242 0.0235 2360.0 1.0 \u03b1(logpopdens) 0.251 0.0857 0.00192 0.00263 1300.0 1.0 \u03b1(Percent Unemployed 2018 ) 0.413 0.153 0.00342 0.00326 2060.0 1.0 \u03b1(Percent living under the federal poverty line 2018 ) -0.175 0.0685 0.00153 0.0019 1590.0 1.0 \u03b1(Percent at risk for serious illness due to COVID) 0.0787 0.0342 0.000764 0.000853 1940.0 1.0 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0505 0.0642 0.0733 0.0838 0.107 \u03c3R0 6.91 8.86 10.1 11.3 14.0 \u03b10(constant) -6.37 -1.82 0.211 2.21 6.37 \u03b10(logpopdens) -5.04 -0.921 1.07 3.03 6.48 \u03b10(Percent Unemployed 2018 ) -5.07 -1.26 0.739 2.86 6.93 \u03b10(Percent living under the federal poverty line 2018 ) -4.46 -1.19 0.767 2.65 6.29 \u03b10(Percent at risk for serious illness due to COVID) -0.899 0.672 1.46 2.4 5.19 \u03c3R 0.062 0.789 1.41 1.95 2.85 \u03c3k 0.142 0.179 0.195 0.204 0.212 \u03c1 0.0284 0.0696 0.0922 0.12 0.177 \u03b1(Stay at home shelter in place) -1.82 -1.26 -1.03 -0.831 -0.482 \u03b1(Date closed K 12 schools) -0.408 0.0441 0.277 0.556 1.1 \u03b1(Closed gyms) -1.5 -0.784 -0.426 -0.106 0.537 \u03b1(Closed movie theaters) -0.997 -0.325 0.0246 0.367 1.05 \u03b1(Closed day cares) -0.528 -0.185 -0.0191 0.137 0.466 \u03b1(Date banned visitors to nursing homes) -0.537 -0.247 -0.116 0.0104 0.266 \u03b1(Closed non essential businesses) -1.25 -0.743 -0.545 -0.357 -0.00389 \u03b1(Closed restaurants except take out) -0.793 -0.19 0.0846 0.359 0.918 \u03b1(retail and recreation percent change from baseline) -2.82 -1.1 -0.193 0.7 2.24 \u03b1(grocery and pharmacy percent change from baseline) -0.0693 1.21 1.89 2.58 4.1 \u03b1(parks percent change from baseline) -0.525 -0.157 0.00405 0.193 0.583 \u03b1(transit stations percent change from baseline) -0.000774 1.3 2.1 2.88 4.56 \u03b1(workplaces percent change from baseline) -4.49 -2.24 -1.14 -0.0858 1.76 \u03b1(residential percent change from baseline) 1.67 5.17 6.75 8.37 11.6 \u03b1(percentchangebusinesses) 0.653 2.07 2.96 3.89 5.71 \u03b1(constant) -2.22 -0.768 -0.0516 0.599 1.93 \u03b1(logpopdens) 0.106 0.191 0.243 0.303 0.435 \u03b1(Percent Unemployed 2018 ) 0.14 0.298 0.406 0.512 0.74 \u03b1(Percent living under the federal poverty line 2018 ) -0.322 -0.22 -0.17 -0.127 -0.0546 \u03b1(Percent at risk for serious illness due to COVID) 0.0166 0.0555 0.0763 0.1 0.147 L\u2081 = 3, L\u2082 = 3 \u00b6 parameters mean std naive_se mcse ess r_hat \u03b3 0.0467 0.00712 0.000159 0.000317 452.0 1.0 \u03c3R0 8.24 1.26 0.0281 0.0462 631.0 1.0 \u03b10(constant) 0.682 3.07 0.0687 0.0688 1190.0 1.0 \u03b10(logpopdens) -0.561 1.27 0.0283 0.0381 789.0 1.0 \u03b10(Percent Unemployed 2018 ) 1.97 1.95 0.0436 0.0602 857.0 1.0 \u03b10(Percent living under the federal poverty line 2018 ) -0.856 0.964 0.0216 0.0253 1140.0 1.0 \u03b10(Percent at risk for serious illness due to COVID) 0.279 0.341 0.00764 0.00794 1130.0 1.0 \u03c3R 3.28 0.454 0.0102 0.0209 415.0 1.0 \u03c3k 0.00423 0.00338 7.57e-5 0.000104 851.0 1.0 \u03c1 0.597 0.0152 0.000339 0.000341 2030.0 1.0 \u03b1(Stay at home shelter in place) -1.7 0.472 0.0106 0.0248 383.0 1.0 \u03b1(Date closed K 12 schools) -0.221 0.49 0.011 0.00954 1210.0 1.0 \u03b1(Closed gyms) -0.958 0.731 0.0163 0.0253 790.0 1.0 \u03b1(Closed movie theaters) -0.075 0.776 0.0174 0.0316 823.0 1.0 \u03b1(Closed day cares) -0.322 0.446 0.00998 0.0125 798.0 1.0 \u03b1(Date banned visitors to nursing homes) -0.373 0.371 0.00829 0.018 505.0 1.0 \u03b1(Closed non essential businesses) -0.383 0.456 0.0102 0.0107 1210.0 1.0 \u03b1(Closed restaurants except take out) 0.323 0.578 0.0129 0.0182 1090.0 1.0 \u03b1(retail and recreation percent change from baseline) -0.731 1.63 0.0365 0.0434 1470.0 1.0 \u03b1(grocery and pharmacy percent change from baseline) 1.73 1.38 0.0309 0.0305 1510.0 1.0 \u03b1(parks percent change from baseline) -0.183 0.311 0.00695 0.00876 1180.0 1.0 \u03b1(transit stations percent change from baseline) 2.64 1.55 0.0348 0.0555 1100.0 1.0 \u03b1(workplaces percent change from baseline) 1.57 1.54 0.0345 0.0581 1170.0 1.0 \u03b1(residential percent change from baseline) 4.34 2.46 0.0551 0.109 872.0 1.0 \u03b1(percentchangebusinesses) -0.0896 1.19 0.0266 0.04 939.0 1.0 \u03b1(constant) 1.29 1.71 0.0383 0.0405 1140.0 1.0 \u03b1(logpopdens) 0.371 0.151 0.00338 0.00442 1030.0 1.0 \u03b1(Percent Unemployed 2018 ) 0.452 0.265 0.00592 0.00678 1140.0 1.0 \u03b1(Percent living under the federal poverty line 2018 ) -0.208 0.115 0.00257 0.00274 1110.0 1.0 \u03b1(Percent at risk for serious illness due to COVID) 0.0867 0.0566 0.00127 0.0017 954.0 1.0 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0371 0.0414 0.0453 0.0507 0.0644 \u03c3R0 5.91 7.38 8.23 9.07 10.8 \u03b10(constant) -5.32 -1.45 0.783 2.79 6.51 \u03b10(logpopdens) -3.04 -1.37 -0.569 0.243 2.07 \u03b10(Percent Unemployed 2018 ) -1.72 0.604 1.96 3.27 5.83 \u03b10(Percent living under the federal poverty line 2018 ) -2.78 -1.49 -0.83 -0.178 1.06 \u03b10(Percent at risk for serious illness due to COVID) -0.377 0.0473 0.28 0.5 0.957 \u03c3R 2.32 2.96 3.31 3.62 4.05 \u03c3k 0.000105 0.00147 0.00348 0.0062 0.0122 \u03c1 0.567 0.587 0.597 0.607 0.626 \u03b1(Stay at home shelter in place) -2.72 -2.0 -1.67 -1.37 -0.877 \u03b1(Date closed K 12 schools) -1.2 -0.544 -0.205 0.114 0.728 \u03b1(Closed gyms) -2.31 -1.44 -0.955 -0.476 0.498 \u03b1(Closed movie theaters) -1.66 -0.567 -0.0393 0.445 1.38 \u03b1(Closed day cares) -1.21 -0.602 -0.309 -0.0271 0.544 \u03b1(Date banned visitors to nursing homes) -1.15 -0.608 -0.344 -0.13 0.315 \u03b1(Closed non essential businesses) -1.29 -0.679 -0.378 -0.0838 0.475 \u03b1(Closed restaurants except take out) -0.82 -0.0493 0.316 0.702 1.48 \u03b1(retail and recreation percent change from baseline) -4.12 -1.74 -0.728 0.341 2.37 \u03b1(grocery and pharmacy percent change from baseline) -0.949 0.792 1.68 2.66 4.59 \u03b1(parks percent change from baseline) -0.814 -0.386 -0.179 0.0266 0.415 \u03b1(transit stations percent change from baseline) -0.312 1.61 2.63 3.7 5.77 \u03b1(workplaces percent change from baseline) -1.38 0.522 1.57 2.6 4.61 \u03b1(residential percent change from baseline) -0.514 2.7 4.38 6.03 9.2 \u03b1(percentchangebusinesses) -2.4 -0.922 -0.104 0.727 2.26 \u03b1(constant) -2.07 0.142 1.26 2.41 4.57 \u03b1(logpopdens) 0.0994 0.266 0.36 0.469 0.682 \u03b1(Percent Unemployed 2018 ) -0.0351 0.268 0.438 0.631 1.0 \u03b1(Percent living under the federal poverty line 2018 ) -0.44 -0.282 -0.201 -0.13 0.00571 \u03b1(Percent at risk for serious illness due to COVID) -0.0164 0.0488 0.0853 0.123 0.203 L\u2081 = 3, L\u2082 = 7 \u00b6 parameters mean std naive_se mcse ess r_hat \u03b3 0.038 0.00243 5.44e-5 0.000236 55.9 1.04 \u03c3R0 4.16 0.488 0.0109 0.0499 50.8 1.04 \u03b10(constant) -0.957 1.83 0.0409 0.377 8.03 1.26 \u03b10(logpopdens) -0.457 0.62 0.0139 0.0953 15.8 1.13 \u03b10(Percent Unemployed 2018 ) 0.697 1.16 0.0258 0.243 8.21 1.18 \u03b10(Percent living under the federal poverty line 2018 ) -0.0466 0.471 0.0105 0.0884 9.43 1.15 \u03b10(Percent at risk for serious illness due to COVID) 0.19 0.135 0.00302 0.0186 16.0 1.16 \u03c3R 1.56 0.0921 0.00206 0.00849 114.0 1.01 \u03c3k 0.00257 0.00204 4.55e-5 0.000412 8.03 1.54 \u03c1 0.877 0.00989 0.000221 0.000799 157.0 1.0 \u03b1(Stay at home shelter in place) -0.602 0.291 0.0065 0.0336 57.0 1.02 \u03b1(Date closed K 12 schools) 0.721 0.286 0.00639 0.0346 50.7 1.02 \u03b1(Closed gyms) -0.679 0.502 0.0112 0.0685 24.4 1.03 \u03b1(Closed movie theaters) -0.119 0.539 0.012 0.0693 28.6 1.03 \u03b1(Closed day cares) 0.053 0.322 0.0072 0.0362 64.5 1.01 \u03b1(Date banned visitors to nursing homes) -0.133 0.292 0.00653 0.0279 98.1 1.0 \u03b1(Closed non essential businesses) 0.1 0.324 0.00724 0.0407 54.9 1.01 \u03b1(Closed restaurants except take out) 0.726 0.34 0.0076 0.0394 66.8 1.01 \u03b1(retail and recreation percent change from baseline) 3.32 0.896 0.02 0.163 8.34 1.33 \u03b1(grocery and pharmacy percent change from baseline) -0.613 0.83 0.0186 0.123 18.6 1.16 \u03b1(parks percent change from baseline) -0.358 0.16 0.00357 0.0192 44.2 1.04 \u03b1(transit stations percent change from baseline) -0.368 0.792 0.0177 0.135 25.1 1.02 \u03b1(workplaces percent change from baseline) -0.253 0.812 0.0182 0.104 31.6 1.06 \u03b1(residential percent change from baseline) -2.0 1.34 0.0299 0.216 13.5 1.22 \u03b1(percentchangebusinesses) 0.302 0.546 0.0122 0.103 11.8 1.05 \u03b1(constant) 1.06 1.33 0.0297 0.253 9.08 1.15 \u03b1(logpopdens) 0.557 0.219 0.00491 0.0238 71.0 1.01 \u03b1(Percent Unemployed 2018 ) -0.0654 0.423 0.00946 0.0669 13.0 1.2 \u03b1(Percent living under the federal poverty line 2018 ) -0.0965 0.172 0.00384 0.0252 15.5 1.11 \u03b1(Percent at risk for serious illness due to COVID) 0.0407 0.0589 0.00132 0.00834 14.4 1.11 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0358 0.0363 0.0372 0.0388 0.0443 \u03c3R0 3.24 3.84 4.15 4.46 5.17 \u03b10(constant) -5.19 -1.98 -0.571 0.366 1.7 \u03b10(logpopdens) -1.73 -0.851 -0.463 -0.0485 0.703 \u03b10(Percent Unemployed 2018 ) -1.83 0.118 0.84 1.44 2.72 \u03b10(Percent living under the federal poverty line 2018 ) -0.958 -0.374 -0.065 0.266 0.939 \u03b10(Percent at risk for serious illness due to COVID) -0.0632 0.094 0.188 0.283 0.469 \u03c3R 1.33 1.52 1.58 1.62 1.67 \u03c3k 0.000203 0.000795 0.00205 0.00402 0.00721 \u03c1 0.857 0.87 0.877 0.883 0.896 \u03b1(Stay at home shelter in place) -1.2 -0.802 -0.592 -0.397 -0.0837 \u03b1(Date closed K 12 schools) 0.175 0.517 0.709 0.926 1.27 \u03b1(Closed gyms) -1.71 -1.02 -0.678 -0.312 0.219 \u03b1(Closed movie theaters) -1.22 -0.491 -0.0963 0.281 0.94 \u03b1(Closed day cares) -0.523 -0.172 0.0376 0.261 0.747 \u03b1(Date banned visitors to nursing homes) -0.713 -0.328 -0.139 0.0713 0.423 \u03b1(Closed non essential businesses) -0.543 -0.102 0.0933 0.324 0.715 \u03b1(Closed restaurants except take out) 0.0734 0.487 0.738 0.981 1.33 \u03b1(retail and recreation percent change from baseline) 1.54 2.71 3.43 4.02 4.86 \u03b1(grocery and pharmacy percent change from baseline) -2.28 -1.2 -0.645 -0.0559 1.01 \u03b1(parks percent change from baseline) -0.682 -0.469 -0.353 -0.246 -0.0472 \u03b1(transit stations percent change from baseline) -2.25 -0.871 -0.186 0.196 0.857 \u03b1(workplaces percent change from baseline) -2.06 -0.775 -0.186 0.333 1.16 \u03b1(residential percent change from baseline) -4.47 -2.96 -2.03 -1.05 0.696 \u03b1(percentchangebusinesses) -0.666 -0.112 0.301 0.683 1.34 \u03b1(constant) -1.22 0.162 0.981 1.87 4.0 \u03b1(logpopdens) 0.124 0.406 0.549 0.703 0.987 \u03b1(Percent Unemployed 2018 ) -0.966 -0.324 -0.0593 0.209 0.731 \u03b1(Percent living under the federal poverty line 2018 ) -0.43 -0.214 -0.0941 0.00663 0.272 \u03b1(Percent at risk for serious illness due to COVID) -0.0967 0.00641 0.0421 0.0812 0.149 L\u2081 = 7, L\u2082 = 1 \u00b6 parameters mean std naive_se mcse ess r_hat \u03b3 0.0394 0.00367 8.2e-5 0.000382 39.5 1.1 \u03c3R0 6.84 1.39 0.0311 0.153 42.3 1.02 \u03b10(constant) 2.64 3.36 0.0752 0.696 9.98 1.33 \u03b10(logpopdens) 0.201 1.08 0.024 0.146 43.3 1.0 \u03b10(Percent Unemployed 2018 ) 0.272 1.54 0.0343 0.252 14.5 1.23 \u03b10(Percent living under the federal poverty line 2018 ) -0.0227 0.759 0.017 0.115 18.5 1.09 \u03b10(Percent at risk for serious illness due to COVID) 0.127 0.302 0.00675 0.0449 40.8 1.03 \u03c3R 1.58 0.407 0.0091 0.0522 35.3 1.03 \u03c3k 0.0963 0.00655 0.000147 0.000867 29.2 1.07 \u03c1 0.7 0.128 0.00285 0.0188 22.0 1.09 \u03b1(Stay at home shelter in place) -1.97 0.396 0.00886 0.0517 24.6 1.05 \u03b1(Date closed K 12 schools) 0.451 0.605 0.0135 0.0749 32.2 1.05 \u03b1(Closed gyms) -0.707 0.654 0.0146 0.0902 32.8 1.02 \u03b1(Closed movie theaters) -0.0205 0.691 0.0155 0.0842 44.7 1.0 \u03b1(Closed day cares) -0.242 0.326 0.0073 0.0313 69.0 1.0 \u03b1(Date banned visitors to nursing homes) -0.695 0.344 0.00768 0.0389 27.4 1.08 \u03b1(Closed non essential businesses) -0.899 0.441 0.00986 0.0535 67.4 1.01 \u03b1(Closed restaurants except take out) 0.461 0.576 0.0129 0.0496 93.7 1.02 \u03b1(retail and recreation percent change from baseline) 0.222 1.66 0.037 0.313 11.0 1.09 \u03b1(grocery and pharmacy percent change from baseline) -0.899 1.29 0.0289 0.227 13.5 1.13 \u03b1(parks percent change from baseline) 0.0558 0.355 0.00794 0.0415 41.4 1.02 \u03b1(transit stations percent change from baseline) 2.36 1.16 0.0259 0.135 73.2 1.01 \u03b1(workplaces percent change from baseline) -1.1 1.6 0.0359 0.282 8.98 1.24 \u03b1(residential percent change from baseline) 5.38 2.38 0.0532 0.383 9.65 1.35 \u03b1(percentchangebusinesses) 0.684 1.4 0.0312 0.218 19.3 1.08 \u03b1(constant) -0.0262 1.4 0.0313 0.243 17.1 1.0 \u03b1(logpopdens) 0.474 0.121 0.0027 0.00905 176.0 1.02 \u03b1(Percent Unemployed 2018 ) 0.361 0.249 0.00556 0.0231 54.7 1.03 \u03b1(Percent living under the federal poverty line 2018 ) -0.145 0.106 0.00237 0.0118 38.2 1.02 \u03b1(Percent at risk for serious illness due to COVID) 0.072 0.0566 0.00127 0.009 20.6 1.0 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0358 0.0369 0.0383 0.0408 0.0501 \u03c3R0 4.38 5.84 6.77 7.68 9.85 \u03b10(constant) -4.76 0.732 3.48 5.04 7.35 \u03b10(logpopdens) -1.88 -0.458 0.228 0.862 2.48 \u03b10(Percent Unemployed 2018 ) -2.91 -0.737 0.32 1.43 3.04 \u03b10(Percent living under the federal poverty line 2018 ) -1.38 -0.545 -0.112 0.428 1.62 \u03b10(Percent at risk for serious illness due to COVID) -0.542 -0.0261 0.139 0.287 0.795 \u03c3R 0.951 1.28 1.52 1.8 2.47 \u03c3k 0.0763 0.0942 0.0977 0.1 0.105 \u03c1 0.37 0.637 0.73 0.799 0.861 \u03b1(Stay at home shelter in place) -2.72 -2.23 -1.97 -1.71 -1.21 \u03b1(Date closed K 12 schools) -0.631 0.0401 0.406 0.872 1.68 \u03b1(Closed gyms) -2.01 -1.15 -0.688 -0.25 0.538 \u03b1(Closed movie theaters) -1.42 -0.451 -0.0115 0.436 1.27 \u03b1(Closed day cares) -0.867 -0.474 -0.244 -0.0262 0.412 \u03b1(Date banned visitors to nursing homes) -1.38 -0.924 -0.687 -0.462 -0.0157 \u03b1(Closed non essential businesses) -1.69 -1.18 -0.909 -0.624 0.029 \u03b1(Closed restaurants except take out) -0.588 0.0512 0.43 0.821 1.69 \u03b1(retail and recreation percent change from baseline) -3.26 -0.885 0.431 1.33 3.35 \u03b1(grocery and pharmacy percent change from baseline) -3.01 -1.89 -1.01 0.0283 1.79 \u03b1(parks percent change from baseline) -0.643 -0.2 0.0536 0.323 0.71 \u03b1(transit stations percent change from baseline) 0.126 1.63 2.36 3.15 4.71 \u03b1(workplaces percent change from baseline) -4.47 -2.26 -0.956 0.01 1.84 \u03b1(residential percent change from baseline) 1.64 3.65 5.09 6.9 11.3 \u03b1(percentchangebusinesses) -1.69 -0.385 0.589 1.57 3.83 \u03b1(constant) -2.91 -0.798 0.0916 0.875 2.6 \u03b1(logpopdens) 0.235 0.398 0.474 0.55 0.711 \u03b1(Percent Unemployed 2018 ) -0.2 0.202 0.378 0.522 0.828 \u03b1(Percent living under the federal poverty line 2018 ) -0.35 -0.215 -0.145 -0.076 0.0696 \u03b1(Percent at risk for serious illness due to COVID) -0.0435 0.0346 0.0723 0.113 0.177 L\u2081 = 7, L\u2082 = 3 \u00b6 parameters mean std naive_se mcse ess r_hat \u03b3 0.0379 0.00233 5.2e-5 0.000166 196.0 1.01 \u03c3R0 4.97 0.537 0.012 0.0418 153.0 1.0 \u03b10(constant) 0.423 1.93 0.0433 0.338 13.0 1.02 \u03b10(logpopdens) -0.222 0.651 0.0146 0.0973 31.5 1.03 \u03b10(Percent Unemployed 2018 ) 0.149 0.98 0.0219 0.159 38.0 1.01 \u03b10(Percent living under the federal poverty line 2018 ) -0.169 0.49 0.011 0.0537 62.9 1.01 \u03b10(Percent at risk for serious illness due to COVID) 0.224 0.168 0.00376 0.0203 47.0 1.0 \u03c3R 1.73 0.0998 0.00223 0.00738 182.0 1.01 \u03c3k 0.00216 0.00159 3.56e-5 0.000133 90.8 1.03 \u03c1 0.837 0.0117 0.000263 0.000746 249.0 1.01 \u03b1(Stay at home shelter in place) -0.895 0.353 0.00789 0.0495 44.1 1.0 \u03b1(Date closed K 12 schools) -0.0798 0.325 0.00727 0.0298 120.0 1.01 \u03b1(Closed gyms) -0.586 0.528 0.0118 0.0511 101.0 1.0 \u03b1(Closed movie theaters) -0.122 0.545 0.0122 0.0633 80.6 1.0 \u03b1(Closed day cares) -0.31 0.423 0.00946 0.0602 21.2 1.01 \u03b1(Date banned visitors to nursing homes) -0.501 0.294 0.00657 0.0244 151.0 1.01 \u03b1(Closed non essential businesses) 0.025 0.357 0.00799 0.0418 60.0 1.0 \u03b1(Closed restaurants except take out) 0.767 0.447 0.01 0.0597 41.2 1.02 \u03b1(retail and recreation percent change from baseline) 0.897 0.947 0.0212 0.17 11.4 1.1 \u03b1(grocery and pharmacy percent change from baseline) -0.878 0.794 0.0178 0.137 23.1 1.01 \u03b1(parks percent change from baseline) -0.0684 0.178 0.00399 0.0254 11.9 1.22 \u03b1(transit stations percent change from baseline) 0.978 0.936 0.0209 0.111 25.1 1.11 \u03b1(workplaces percent change from baseline) 2.08 1.01 0.0226 0.177 8.26 1.43 \u03b1(residential percent change from baseline) 3.06 1.72 0.0385 0.316 8.03 1.42 \u03b1(percentchangebusinesses) -0.0657 0.632 0.0141 0.0758 57.9 1.03 \u03b1(constant) 2.29 1.99 0.0444 0.379 9.61 1.32 \u03b1(logpopdens) 0.504 0.183 0.00409 0.0185 84.7 1.06 \u03b1(Percent Unemployed 2018 ) 0.00689 0.3 0.0067 0.0331 66.0 1.02 \u03b1(Percent living under the federal poverty line 2018 ) -0.0776 0.125 0.00279 0.011 104.0 1.0 \u03b1(Percent at risk for serious illness due to COVID) 0.0233 0.0648 0.00145 0.0102 12.7 1.18 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0358 0.0363 0.0371 0.0386 0.0446 \u03c3R0 3.95 4.62 4.96 5.31 6.12 \u03b10(constant) -3.71 -0.792 0.618 1.86 3.57 \u03b10(logpopdens) -1.34 -0.71 -0.25 0.207 1.11 \u03b10(Percent Unemployed 2018 ) -1.72 -0.604 0.151 0.885 2.02 \u03b10(Percent living under the federal poverty line 2018 ) -1.07 -0.497 -0.177 0.151 0.763 \u03b10(Percent at risk for serious illness due to COVID) -0.136 0.118 0.221 0.342 0.528 \u03c3R 1.46 1.69 1.76 1.8 1.85 \u03c3k 0.000117 0.000812 0.00187 0.00317 0.00583 \u03c1 0.814 0.829 0.837 0.845 0.862 \u03b1(Stay at home shelter in place) -1.7 -1.12 -0.891 -0.669 -0.196 \u03b1(Date closed K 12 schools) -0.734 -0.293 -0.0633 0.144 0.519 \u03b1(Closed gyms) -1.63 -0.941 -0.61 -0.211 0.472 \u03b1(Closed movie theaters) -1.09 -0.477 -0.13 0.225 0.992 \u03b1(Closed day cares) -1.21 -0.563 -0.317 -0.0113 0.565 \u03b1(Date banned visitors to nursing homes) -1.06 -0.7 -0.495 -0.295 0.0612 \u03b1(Closed non essential businesses) -0.687 -0.211 0.0368 0.256 0.699 \u03b1(Closed restaurants except take out) -0.148 0.489 0.769 1.06 1.62 \u03b1(retail and recreation percent change from baseline) -1.11 0.312 0.838 1.6 2.63 \u03b1(grocery and pharmacy percent change from baseline) -2.34 -1.46 -0.886 -0.35 0.612 \u03b1(parks percent change from baseline) -0.416 -0.192 -0.0696 0.0577 0.302 \u03b1(transit stations percent change from baseline) -0.961 0.389 0.936 1.59 2.94 \u03b1(workplaces percent change from baseline) 0.163 1.34 2.08 2.85 3.97 \u03b1(residential percent change from baseline) -0.698 2.01 3.25 4.19 6.17 \u03b1(percentchangebusinesses) -1.16 -0.518 -0.093 0.353 1.25 \u03b1(constant) -1.77 1.13 2.56 3.73 5.82 \u03b1(logpopdens) 0.153 0.38 0.504 0.624 0.87 \u03b1(Percent Unemployed 2018 ) -0.588 -0.209 0.0175 0.22 0.552 \u03b1(Percent living under the federal poverty line 2018 ) -0.322 -0.157 -0.0755 0.0064 0.173 \u03b1(Percent at risk for serious illness due to COVID) -0.09 -0.0215 0.019 0.0665 0.15 L\u2081 = 7, L\u2082 = 7 \u00b6 parameters mean std naive_se mcse ess r_hat \u03b3 0.0375 0.00187 4.18e-5 0.000195 84.3 1.03 \u03c3R0 3.14 0.341 0.00763 0.0411 28.0 1.04 \u03b10(constant) 1.16 0.839 0.0188 0.18 8.04 1.59 \u03b10(logpopdens) -0.471 0.35 0.00782 0.0447 55.7 1.01 \u03b10(Percent Unemployed 2018 ) 0.785 0.488 0.0109 0.0912 11.3 1.21 \u03b10(Percent living under the federal poverty line 2018 ) -0.264 0.278 0.00622 0.0422 13.1 1.2 \u03b10(Percent at risk for serious illness due to COVID) 0.216 0.0936 0.00209 0.013 19.8 1.12 \u03c3R 0.936 0.0458 0.00103 0.00494 60.8 1.04 \u03c3k 0.000728 0.00048 1.07e-5 9.65e-5 8.65 1.08 \u03c1 0.936 0.00643 0.000144 0.000381 242.0 1.0 \u03b1(Stay at home shelter in place) -0.264 0.195 0.00436 0.0336 18.3 1.01 \u03b1(Date closed K 12 schools) 0.339 0.209 0.00468 0.0342 15.6 1.22 \u03b1(Closed gyms) -0.0412 0.34 0.00761 0.0657 8.52 1.3 \u03b1(Closed movie theaters) 0.23 0.39 0.00873 0.0741 8.03 1.51 \u03b1(Closed day cares) 0.218 0.306 0.00683 0.0559 18.2 1.0 \u03b1(Date banned visitors to nursing homes) -0.644 0.247 0.00552 0.0362 22.2 1.14 \u03b1(Closed non essential businesses) 0.00545 0.224 0.005 0.0348 27.2 1.01 \u03b1(Closed restaurants except take out) 0.497 0.199 0.00445 0.0276 37.9 1.06 \u03b1(retail and recreation percent change from baseline) 1.68 0.495 0.0111 0.0903 15.5 1.01 \u03b1(grocery and pharmacy percent change from baseline) -1.4 0.425 0.00951 0.0808 10.7 1.05 \u03b1(parks percent change from baseline) -0.0749 0.109 0.00243 0.0188 12.7 1.04 \u03b1(transit stations percent change from baseline) 0.912 0.494 0.011 0.0871 13.7 1.11 \u03b1(workplaces percent change from baseline) 0.333 0.796 0.0178 0.173 8.03 1.5 \u03b1(residential percent change from baseline) 1.04 1.33 0.0297 0.299 8.03 1.7 \u03b1(percentchangebusinesses) -0.158 0.397 0.00889 0.0824 11.6 1.0 \u03b1(constant) 2.25 1.93 0.0432 0.44 8.03 2.38 \u03b1(logpopdens) 0.771 0.243 0.00544 0.0332 40.3 1.0 \u03b1(Percent Unemployed 2018 ) -0.648 0.418 0.00934 0.0772 13.5 1.02 \u03b1(Percent living under the federal poverty line 2018 ) 0.121 0.155 0.00347 0.0192 46.8 1.02 \u03b1(Percent at risk for serious illness due to COVID) -0.0734 0.0648 0.00145 0.0105 9.42 1.18 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0358 0.0362 0.0369 0.038 0.0428 \u03c3R0 2.51 2.91 3.14 3.36 3.9 \u03b10(constant) -0.641 0.573 1.25 1.79 2.54 \u03b10(logpopdens) -1.09 -0.714 -0.514 -0.253 0.287 \u03b10(Percent Unemployed 2018 ) -0.245 0.518 0.862 1.12 1.59 \u03b10(Percent living under the federal poverty line 2018 ) -0.826 -0.431 -0.259 -0.0933 0.301 \u03b10(Percent at risk for serious illness due to COVID) 0.0402 0.156 0.214 0.279 0.395 \u03c3R 0.817 0.915 0.945 0.967 0.998 \u03c3k 0.000147 0.000378 0.000634 0.001 0.00172 \u03c1 0.924 0.932 0.936 0.941 0.948 \u03b1(Stay at home shelter in place) -0.681 -0.385 -0.252 -0.133 0.101 \u03b1(Date closed K 12 schools) -0.00467 0.179 0.324 0.473 0.803 \u03b1(Closed gyms) -0.785 -0.304 0.0118 0.209 0.536 \u03b1(Closed movie theaters) -0.497 -0.0643 0.188 0.533 1.01 \u03b1(Closed day cares) -0.404 0.00634 0.225 0.42 0.762 \u03b1(Date banned visitors to nursing homes) -1.17 -0.794 -0.64 -0.487 -0.146 \u03b1(Closed non essential businesses) -0.444 -0.142 0.0153 0.165 0.426 \u03b1(Closed restaurants except take out) 0.115 0.36 0.496 0.624 0.915 \u03b1(retail and recreation percent change from baseline) 0.704 1.39 1.63 1.98 2.75 \u03b1(grocery and pharmacy percent change from baseline) -2.28 -1.68 -1.37 -1.1 -0.645 \u03b1(parks percent change from baseline) -0.302 -0.151 -0.0647 0.00749 0.11 \u03b1(transit stations percent change from baseline) 0.0133 0.541 0.932 1.27 1.8 \u03b1(workplaces percent change from baseline) -1.13 -0.21 0.477 0.874 1.65 \u03b1(residential percent change from baseline) -1.65 0.103 1.66 1.98 2.62 \u03b1(percentchangebusinesses) -0.843 -0.436 -0.173 0.139 0.567 \u03b1(constant) -1.09 1.04 2.19 3.73 5.28 \u03b1(logpopdens) 0.268 0.617 0.772 0.936 1.23 \u03b1(Percent Unemployed 2018 ) -1.47 -0.957 -0.604 -0.344 0.0735 \u03b1(Percent living under the federal poverty line 2018 ) -0.173 0.0112 0.119 0.221 0.44 \u03b1(Percent at risk for serious illness due to COVID) -0.192 -0.123 -0.0722 -0.0259 0.0535","title":"Long-differening"},{"location":"rt_longdiff/#longer-differences-and-smoothing","text":"One way to reduce $\\sigma_k/\\sigma_R$ is to reduce noise in new cases by taking a longer difference or smoothing case counts in some other way. How does this affect the estimation and interpretation of $R_t$? As in the first section, we start with the approximate recursive relation C(t) - C(t-1) \\equiv \\Delta C(t) \\approx \\frac{\\tau(t)}{\\tau(t-1)} e^{\\gamma (R_t - 1)} \\Delta C(t-1) If we instead look at a longer difference, \\begin{align*} C(t) - C(t-L) = & \\sum_{i=0}^{L-1} \\Delta C_{t-i} \\\\ \\approx & \\sum_{i=0}^{L-1} \\frac{\\tau(t-i)}{\\tau(t-i-1)} e^{\\gamma (R_{t-i} - 1)} \\Delta C_{t-i-1} \\\\ = & \\overline {T_{t,L} e^{\\gamma(R_{t,L} - 1)}} \\sum_{i=0}^{L-1}\\Delta C_{t-i-1} \\\\ = & \\overline {T_{t,L} e^{\\gamma(R_{t,L} - 1)}} \\left( C(t-1) - C(t-1-L) \\right) \\end{align*} where $\\overline {T_{t,L} e^{\\gamma(R_{t,L} - 1)}}$ is some intermediate value in between the minimum and maximum of the ${ \\frac{\\tau(t-i)}{\\tau(t-i-1)} e^{\\gamma (R_{t-i} - 1)} }_{i=0}^{L-1}$. If testing is constant over time, we can then obtain an interpretable $\\overline{R_{t,L}}$ by using $k_{t,L} =\\log(C(t)-C(t-L))$ and following the procedure above. If testing varies with time, it becomes hard to separate testing rate changes from $R_t$ after taking long differnces. Note The same analysis can be applied to other smoothing operations, i.e. using \\sum_{i=0}^L w_i \\Delta C_{t-i} in place of $C(t) - C(t-L)$. However, there\u2019s something strange about smoothing $C_t$, and then extracting a smoothed component of it using the Kalman filter. The inference afterwards is suspect; we would essentially be estimating a kernel regression of $C_t$ on time, and using the estimated regression as though it\u2019s known with certainty. When would long differences reduce variance? Well if $\\Delta C(t) = \\Delta C^\\ast(t) + \\epsilon_t$ with $\\epsilon_t$ indepenedent over time with mean $0$ and constant variance, then you would need $C^\\ast(t) - C^\\ast(t-L)$ to increase faster than linearly with $L$. This is true if $C^\\ast$ is growing exponentially. Alternatively, if $\\epsilon_t$ is not independent over time, but negatively correlated (as seems likely), then variance can decrease with $L$. For example, if $\\Delta C(t) = C^\\ast(t) - C^\\ast(t-\\delta)$ with $\\delta$ a random, independent increment with mean $1$, then variance will tend to decrease with $L$ regardless of $C^\\ast(t)$.","title":"Longer Differences and Smoothing"},{"location":"rt_longdiff/#results","text":"# data prep using CovidData using CovidRt using TransformVariables, Parameters, Plots, StatsPlots, DataFrames, Dates, LinearAlgebra, Distributions, Random, LogDensityProblems, DynamicHMC, MCMCChains, JLD2, Latexify Plots.pyplot() df = CovidData.statedata(policies=:indicators, fillmissingmobility=true) pvars = [Symbol(\"Stay.at.home..shelter.in.place\"), #Symbol(\"State.of.emergency\"), Symbol(\"Date.closed.K.12.schools\"), Symbol(\"Closed.gyms\"), Symbol(\"Closed.movie.theaters\"), Symbol(\"Closed.day.cares\"), Symbol(\"Date.banned.visitors.to.nursing.homes\"), Symbol(\"Closed.non.essential.businesses\"), Symbol(\"Closed.restaurants.except.take.out\")] mvars = [:retail_and_recreation_percent_change_from_baseline, :grocery_and_pharmacy_percent_change_from_baseline, :parks_percent_change_from_baseline , :transit_stations_percent_change_from_baseline, :workplaces_percent_change_from_baseline, :residential_percent_change_from_baseline, :percentchangebusinesses] df[!,:logpopdens] = log.(df[!,Symbol(\"Population.density.per.square.miles\")]) df[!,:weekend] = dayofweek.(df[!,:date]) .>= 6 x0vars=[:constant, :logpopdens, Symbol(\"Percent.Unemployed..2018.\"), Symbol(\"Percent.living.under.the.federal.poverty.line..2018.\"), Symbol(\"Percent.at.risk.for.serious.illness.due.to.COVID\")] sdf = filter(x->x.fips<60, df) sdf = sort(sdf, (:state, :date)) sdf[!,mvars] ./= 100 sdf[!,:constant] .= 1 xvars = vcat(pvars,mvars, x0vars); Here, we will allow the initial and time varying mean of $R_{s,t}$ to depend on covariates. \\begin{align*} \\tilde{R}_{s,0} & \\sim N(X_{0,s} \\alpha_0, \\sigma^2_{R,0}) \\\\ \\tilde{R}_{s,t} & = \\rho \\tilde{R}_{s,t} + u_{s,t} \\;,\\; u_{s,t} \\sim N(0, \\sigma^2_R) \\\\ R_{s,t} & = X_{s,t} \\alpha + \\tilde{R}_{s,t} \\\\ \\Delta \\log(k)_{s,t} & = \\gamma (R_{s,t} - 1) + \\epsilon_{s,t} - \\epsilon_{s,t-1} \\;, \\; \\epsilon_{s,t} \\sim N(0, \\sigma^2_k) \\end{align*} We present estimates of $R_t$ with \\Delta C(t) = C(t) - C(t-L_1) and \\Delta log (\\Delta C(t)) = log (\\Delta C(t)) - log (\\Delta C(t - L_2)) for a variety of values of $L_1$ and $L_2$ reestimate=false rlo=-1 #1 - eps(Float64) rhi=1.2 #1+ eps(Float64) K = length(xvars) priors = (\u03b3 = truncated(Normal(1/7,1/7), 1/28, 1/1), \u03c3R0 = truncated(Normal(1, 3), 0, Inf), \u03b10 = MvNormal(zeros(length(x0vars)), sqrt(10)), #truncated(Normal(1, 3), 0, Inf), \u03c3R = truncated(Normal(0.25,1),0,Inf), \u03c3k = truncated(Normal(0.1, 5), 0, Inf), \u03c1 = Uniform(rlo, rhi), \u03b1 = MvNormal(zeros(K), sqrt(10)) ) states_to_plot = [\"New York\", \"New Jersey\",\"Massachusetts\",\"California\", \"Georgia\",\"Illinois\",\"Michigan\", \"Ohio\",\"Wisconsin\",\"Washington\"] warmup = default_warmup_stages(local_optimization=nothing, stepsize_search=nothing, init_steps=100, middle_steps=100, terminating_steps=2*100, doubling_stages=2, M=Symmetric) for L1 in [1, 3, 7] for L2 in [1, 3, 7] mdl = CovidRt.RtModel(sdf, Symbol(\"cases.nyt\"), xvars, x0vars, priors; L1=L1, L2=L2, time0=r->(r[Symbol(\"cases.nyt\")].>=5)) estfile = \"rt$(L1)_$(L2).jld2\" if !isfile(estfile) || reestimate post = CovidRt.mcmc(mdl; iterations=2000, warmup=warmup) @save estfile post end @load estfile post cc = CovidRt.MCMCChain(post, xvars, x0vars) println(\"## L\u2081 = $(L1), L\u2082 = $(L2)\") println() #display(plot(cc)) println(latexify(DataFrame(describe(cc)[1]), env=:mdtable, latex=false, fmt=x->round(x, sigdigits=3))) println(latexify(DataFrame(describe(cc)[2]), env=:mdtable, latex=false, fmt=x->round(x, sigdigits=3))) states = mdl.id S = length(states_to_plot) figs = fill(plot(), S) for (i,st) in enumerate(states_to_plot) s = findfirst(states.==st) figr = CovidRt.plotpostr(mdl.t[s],mdl.dlogk[s],post, mdl.X[s], mdl.X0[s]) l = @layout [a{.1h}; grid(1,1)] figs[i] = plot(plot(annotation=(0.5,0.5, st*\", L\u2081=$(L1) L\u2082=$(L2)\"), framestyle = :none), plot(figr, ylim=(-1,15)), layout=l) display(figs[i]) end end end","title":"Results"},{"location":"rt_longdiff/#l1-1-l2-1","text":"parameters mean std naive_se mcse ess r_hat \u03b3 0.239 0.0357 0.000797 0.00171 392.0 1.0 \u03c3R0 8.32 1.31 0.0292 0.0504 680.0 1.0 \u03b10(constant) 0.113 3.1 0.0693 0.0656 2710.0 1.0 \u03b10(logpopdens) -2.12 1.51 0.0339 0.0292 2220.0 1.0 \u03b10(Percent Unemployed 2018 ) -3.44 2.07 0.0463 0.0384 2510.0 1.0 \u03b10(Percent living under the federal poverty line 2018 ) 0.73 1.07 0.024 0.0234 2880.0 1.0 \u03b10(Percent at risk for serious illness due to COVID) 0.144 0.388 0.00867 0.00782 2300.0 1.0 \u03c3R 3.71 0.527 0.0118 0.0213 550.0 1.0 \u03c3k 0.0262 0.0198 0.000442 0.000352 2210.0 1.0 \u03c1 -0.475 0.0165 0.000369 0.000338 2960.0 1.0 \u03b1(Stay at home shelter in place) -0.251 0.167 0.00373 0.00388 2360.0 1.0 \u03b1(Date closed K 12 schools) -0.0818 0.244 0.00545 0.00497 2060.0 1.0 \u03b1(Closed gyms) -0.209 0.308 0.00688 0.00585 2650.0 1.0 \u03b1(Closed movie theaters) 0.114 0.312 0.00697 0.00537 2530.0 1.0 \u03b1(Closed day cares) 0.0187 0.15 0.00335 0.00311 2150.0 1.0 \u03b1(Date banned visitors to nursing homes) -0.0227 0.12 0.00269 0.00216 2960.0 1.0 \u03b1(Closed non essential businesses) -0.132 0.163 0.00364 0.00341 2850.0 1.0 \u03b1(Closed restaurants except take out) 0.124 0.259 0.0058 0.00456 2420.0 1.0 \u03b1(retail and recreation percent change from baseline) -0.828 0.909 0.0203 0.0136 2080.0 1.0 \u03b1(grocery and pharmacy percent change from baseline) 0.89 0.696 0.0156 0.0127 2400.0 1.0 \u03b1(parks percent change from baseline) 0.232 0.184 0.00412 0.00331 2520.0 1.0 \u03b1(transit stations percent change from baseline) -0.0128 0.759 0.017 0.0119 2340.0 1.0 \u03b1(workplaces percent change from baseline) -1.82 1.22 0.0274 0.0245 2320.0 1.0 \u03b1(residential percent change from baseline) 2.05 2.23 0.0498 0.041 2300.0 1.0 \u03b1(percentchangebusinesses) 3.62 1.01 0.0227 0.0237 1940.0 1.0 \u03b1(constant) -0.235 0.728 0.0163 0.0149 2600.0 1.0 \u03b1(logpopdens) 0.0761 0.0468 0.00105 0.000724 2660.0 1.0 \u03b1(Percent Unemployed 2018 ) 0.126 0.0884 0.00198 0.0016 2930.0 1.0 \u03b1(Percent living under the federal poverty line 2018 ) -0.0405 0.0385 0.000861 0.000637 2450.0 1.0 \u03b1(Percent at risk for serious illness due to COVID) 0.0426 0.0214 0.000478 0.000407 2420.0 1.0 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.182 0.214 0.233 0.259 0.323 \u03c3R0 5.9 7.42 8.28 9.18 11.0 \u03b10(constant) -6.16 -1.91 0.128 2.17 6.24 \u03b10(logpopdens) -5.11 -3.09 -2.15 -1.14 0.913 \u03b10(Percent Unemployed 2018 ) -7.45 -4.89 -3.42 -2.05 0.725 \u03b10(Percent living under the federal poverty line 2018 ) -1.34 0.0173 0.778 1.41 2.81 \u03b10(Percent at risk for serious illness due to COVID) -0.592 -0.108 0.148 0.407 0.924 \u03c3R 2.67 3.35 3.71 4.05 4.75 \u03c3k 0.00123 0.0105 0.0217 0.0379 0.0743 \u03c1 -0.507 -0.486 -0.475 -0.464 -0.444 \u03b1(Stay at home shelter in place) -0.604 -0.36 -0.247 -0.139 0.075 \u03b1(Date closed K 12 schools) -0.572 -0.24 -0.0844 0.0819 0.385 \u03b1(Closed gyms) -0.847 -0.41 -0.203 -0.0025 0.393 \u03b1(Closed movie theaters) -0.494 -0.0936 0.117 0.313 0.743 \u03b1(Closed day cares) -0.278 -0.0776 0.0183 0.115 0.32 \u03b1(Date banned visitors to nursing homes) -0.259 -0.102 -0.0228 0.0558 0.217 \u03b1(Closed non essential businesses) -0.458 -0.244 -0.132 -0.0219 0.183 \u03b1(Closed restaurants except take out) -0.37 -0.0541 0.119 0.294 0.653 \u03b1(retail and recreation percent change from baseline) -2.65 -1.44 -0.822 -0.231 0.95 \u03b1(grocery and pharmacy percent change from baseline) -0.413 0.396 0.875 1.35 2.25 \u03b1(parks percent change from baseline) -0.125 0.105 0.234 0.353 0.6 \u03b1(transit stations percent change from baseline) -1.5 -0.496 -0.0322 0.482 1.51 \u03b1(workplaces percent change from baseline) -4.29 -2.6 -1.8 -0.959 0.527 \u03b1(residential percent change from baseline) -2.35 0.585 2.04 3.5 6.44 \u03b1(percentchangebusinesses) 1.71 2.92 3.58 4.29 5.71 \u03b1(constant) -1.7 -0.714 -0.215 0.259 1.15 \u03b1(logpopdens) -0.00923 0.0433 0.0737 0.107 0.172 \u03b1(Percent Unemployed 2018 ) -0.0407 0.0682 0.123 0.18 0.303 \u03b1(Percent living under the federal poverty line 2018 ) -0.121 -0.0657 -0.0396 -0.014 0.0318 \u03b1(Percent at risk for serious illness due to COVID) 0.00154 0.028 0.0423 0.0566 0.0878","title":"L\u2081 = 1, L\u2082 = 1"},{"location":"rt_longdiff/#l1-1-l2-3","text":"parameters mean std naive_se mcse ess r_hat \u03b3 0.0486 0.00898 0.000201 0.000486 453.0 1.0 \u03c3R0 8.31 1.52 0.0339 0.0496 814.0 1.0 \u03b10(constant) 0.318 3.12 0.0697 0.141 853.0 1.0 \u03b10(logpopdens) 1.09 2.25 0.0503 0.0897 646.0 1.0 \u03b10(Percent Unemployed 2018 ) 2.12 2.72 0.0609 0.103 649.0 1.0 \u03b10(Percent living under the federal poverty line 2018 ) -0.382 1.86 0.0417 0.0718 735.0 1.0 \u03b10(Percent at risk for serious illness due to COVID) 0.341 0.678 0.0152 0.0333 512.0 1.0 \u03c3R 1.0 0.787 0.0176 0.0307 735.0 1.0 \u03c3k 0.243 0.00917 0.000205 0.000368 630.0 1.0 \u03c1 0.374 0.12 0.00269 0.00501 638.0 1.0 \u03b1(Stay at home shelter in place) -1.78 0.568 0.0127 0.0364 264.0 1.0 \u03b1(Date closed K 12 schools) 0.0879 0.634 0.0142 0.0235 866.0 1.0 \u03b1(Closed gyms) -1.03 0.874 0.0196 0.0336 482.0 1.0 \u03b1(Closed movie theaters) 0.219 0.89 0.0199 0.0321 553.0 1.0 \u03b1(Closed day cares) -0.0219 0.408 0.00913 0.0113 1030.0 1.0 \u03b1(Date banned visitors to nursing homes) -0.167 0.348 0.00778 0.0144 695.0 1.0 \u03b1(Closed non essential businesses) -0.729 0.506 0.0113 0.022 437.0 1.0 \u03b1(Closed restaurants except take out) 0.343 0.729 0.0163 0.0286 707.0 1.0 \u03b1(retail and recreation percent change from baseline) -0.112 1.92 0.043 0.0532 884.0 1.0 \u03b1(grocery and pharmacy percent change from baseline) 1.66 1.62 0.0363 0.0664 888.0 1.01 \u03b1(parks percent change from baseline) 0.128 0.483 0.0108 0.0152 682.0 1.0 \u03b1(transit stations percent change from baseline) 2.63 1.86 0.0415 0.0834 403.0 1.0 \u03b1(workplaces percent change from baseline) -4.1 1.99 0.0446 0.0719 699.0 1.0 \u03b1(residential percent change from baseline) 4.86 2.9 0.0649 0.123 614.0 1.0 \u03b1(percentchangebusinesses) 6.48 1.99 0.0444 0.109 527.0 1.0 \u03b1(constant) -0.0214 1.69 0.0378 0.0512 914.0 1.0 \u03b1(logpopdens) 0.379 0.137 0.00306 0.00498 761.0 1.0 \u03b1(Percent Unemployed 2018 ) 0.64 0.264 0.00591 0.0131 512.0 1.0 \u03b1(Percent living under the federal poverty line 2018 ) -0.25 0.113 0.00252 0.00509 625.0 1.0 \u03b1(Percent at risk for serious illness due to COVID) 0.119 0.0563 0.00126 0.00192 813.0 1.0 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0364 0.0417 0.0469 0.0537 0.071 \u03c3R0 5.59 7.23 8.23 9.35 11.5 \u03b10(constant) -5.84 -1.81 0.406 2.48 6.26 \u03b10(logpopdens) -3.23 -0.449 0.994 2.5 5.58 \u03b10(Percent Unemployed 2018 ) -3.34 0.356 2.15 3.95 7.32 \u03b10(Percent living under the federal poverty line 2018 ) -3.6 -1.68 -0.513 0.771 3.61 \u03b10(Percent at risk for serious illness due to COVID) -0.92 -0.102 0.354 0.751 1.72 \u03c3R 0.0363 0.343 0.807 1.51 2.83 \u03c3k 0.218 0.24 0.245 0.248 0.253 \u03c1 0.152 0.284 0.373 0.464 0.609 \u03b1(Stay at home shelter in place) -3.06 -2.12 -1.73 -1.37 -0.773 \u03b1(Date closed K 12 schools) -1.2 -0.331 0.0943 0.515 1.35 \u03b1(Closed gyms) -2.84 -1.62 -1.01 -0.406 0.591 \u03b1(Closed movie theaters) -1.48 -0.401 0.204 0.811 2.09 \u03b1(Closed day cares) -0.793 -0.299 -0.0275 0.255 0.824 \u03b1(Date banned visitors to nursing homes) -0.863 -0.405 -0.163 0.0635 0.493 \u03b1(Closed non essential businesses) -1.74 -1.08 -0.719 -0.395 0.297 \u03b1(Closed restaurants except take out) -1.13 -0.155 0.346 0.846 1.74 \u03b1(retail and recreation percent change from baseline) -3.86 -1.33 -0.12 1.12 3.73 \u03b1(grocery and pharmacy percent change from baseline) -1.52 0.62 1.62 2.78 4.96 \u03b1(parks percent change from baseline) -0.849 -0.186 0.124 0.439 1.1 \u03b1(transit stations percent change from baseline) -0.882 1.41 2.58 3.85 6.54 \u03b1(workplaces percent change from baseline) -8.02 -5.46 -4.09 -2.75 -0.433 \u03b1(residential percent change from baseline) -0.71 2.89 4.83 6.77 10.6 \u03b1(percentchangebusinesses) 2.78 5.13 6.4 7.81 10.6 \u03b1(constant) -3.24 -1.16 -0.0416 1.1 3.32 \u03b1(logpopdens) 0.118 0.282 0.375 0.473 0.66 \u03b1(Percent Unemployed 2018 ) 0.148 0.457 0.622 0.818 1.19 \u03b1(Percent living under the federal poverty line 2018 ) -0.479 -0.323 -0.245 -0.17 -0.0511 \u03b1(Percent at risk for serious illness due to COVID) 0.0131 0.0816 0.119 0.156 0.23","title":"L\u2081 = 1, L\u2082 = 3"},{"location":"rt_longdiff/#l1-1-l2-7","text":"parameters mean std naive_se mcse ess r_hat \u03b3 0.0376 0.0017 3.79e-5 0.000119 150.0 1.0 \u03c3R0 4.06 0.499 0.0112 0.0455 114.0 1.0 \u03b10(constant) 0.0666 1.15 0.0257 0.23 8.3 1.21 \u03b10(logpopdens) -0.000728 0.63 0.0141 0.0962 10.6 1.14 \u03b10(Percent Unemployed 2018 ) 0.473 0.836 0.0187 0.137 22.9 1.02 \u03b10(Percent living under the federal poverty line 2018 ) -0.285 0.416 0.0093 0.0636 43.0 1.0 \u03b10(Percent at risk for serious illness due to COVID) 0.277 0.138 0.00308 0.0187 42.5 1.03 \u03c3R 0.966 0.0988 0.00221 0.0105 58.1 1.01 \u03c3k 0.101 0.00174 3.89e-5 9.73e-5 366.0 1.0 \u03c1 0.909 0.0108 0.000242 0.00107 56.8 1.01 \u03b1(Stay at home shelter in place) -1.65 0.427 0.00955 0.07 13.6 1.07 \u03b1(Date closed K 12 schools) 1.11 0.574 0.0128 0.0776 17.0 1.18 \u03b1(Closed gyms) 0.0444 0.736 0.0165 0.105 20.0 1.14 \u03b1(Closed movie theaters) -0.89 0.721 0.0161 0.0991 25.7 1.06 \u03b1(Closed day cares) -0.0539 0.468 0.0105 0.076 14.4 1.15 \u03b1(Date banned visitors to nursing homes) -0.553 0.452 0.0101 0.0607 69.1 1.0 \u03b1(Closed non essential businesses) -0.57 0.477 0.0107 0.0673 27.4 1.0 \u03b1(Closed restaurants except take out) 0.386 0.559 0.0125 0.0758 20.8 1.05 \u03b1(retail and recreation percent change from baseline) -2.23 1.51 0.0338 0.23 15.8 1.09 \u03b1(grocery and pharmacy percent change from baseline) -1.36 1.19 0.0267 0.236 9.5 1.16 \u03b1(parks percent change from baseline) 0.269 0.328 0.00734 0.0473 19.2 1.06 \u03b1(transit stations percent change from baseline) 0.982 1.04 0.0234 0.206 8.25 1.24 \u03b1(workplaces percent change from baseline) -0.467 1.5 0.0335 0.303 12.2 1.11 \u03b1(residential percent change from baseline) 1.66 1.14 0.0255 0.196 18.6 1.01 \u03b1(percentchangebusinesses) 1.59 0.935 0.0209 0.185 8.39 1.17 \u03b1(constant) 1.72 2.23 0.0499 0.461 8.03 1.63 \u03b1(logpopdens) 0.461 0.196 0.00439 0.0276 23.5 1.04 \u03b1(Percent Unemployed 2018 ) 0.163 0.335 0.00749 0.0422 73.9 1.0 \u03b1(Percent living under the federal poverty line 2018 ) -0.0466 0.152 0.00341 0.017 86.5 1.03 \u03b1(Percent at risk for serious illness due to COVID) -0.0393 0.0822 0.00184 0.0155 8.04 1.49 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0358 0.0363 0.0371 0.0384 0.0421 \u03c3R0 3.1 3.72 4.06 4.37 5.08 \u03b10(constant) -1.79 -0.782 -0.0349 0.723 2.66 \u03b10(logpopdens) -1.31 -0.393 0.0157 0.405 1.26 \u03b10(Percent Unemployed 2018 ) -1.27 -0.061 0.472 1.02 2.2 \u03b10(Percent living under the federal poverty line 2018 ) -1.02 -0.583 -0.299 -0.022 0.612 \u03b10(Percent at risk for serious illness due to COVID) -0.00983 0.187 0.277 0.377 0.541 \u03c3R 0.774 0.896 0.967 1.03 1.16 \u03c3k 0.098 0.1 0.101 0.102 0.105 \u03c1 0.884 0.903 0.91 0.917 0.928 \u03b1(Stay at home shelter in place) -2.4 -1.98 -1.66 -1.33 -0.842 \u03b1(Date closed K 12 schools) -0.0586 0.743 1.12 1.47 2.25 \u03b1(Closed gyms) -1.24 -0.49 0.0234 0.538 1.62 \u03b1(Closed movie theaters) -2.48 -1.29 -0.884 -0.428 0.468 \u03b1(Closed day cares) -0.999 -0.342 -0.0439 0.268 0.835 \u03b1(Date banned visitors to nursing homes) -1.54 -0.862 -0.547 -0.24 0.259 \u03b1(Closed non essential businesses) -1.44 -0.919 -0.577 -0.223 0.311 \u03b1(Closed restaurants except take out) -0.786 0.0367 0.376 0.769 1.45 \u03b1(retail and recreation percent change from baseline) -5.66 -3.11 -2.03 -1.15 0.295 \u03b1(grocery and pharmacy percent change from baseline) -3.92 -1.99 -1.17 -0.577 0.719 \u03b1(parks percent change from baseline) -0.353 0.0219 0.282 0.509 0.883 \u03b1(transit stations percent change from baseline) -0.957 0.256 0.993 1.59 3.14 \u03b1(workplaces percent change from baseline) -3.27 -1.72 -0.313 0.717 2.24 \u03b1(residential percent change from baseline) -0.81 0.945 1.83 2.44 3.66 \u03b1(percentchangebusinesses) 0.0313 0.741 1.74 2.32 3.13 \u03b1(constant) -2.75 0.00553 2.2 3.52 4.98 \u03b1(logpopdens) 0.113 0.318 0.457 0.602 0.835 \u03b1(Percent Unemployed 2018 ) -0.61 -0.0321 0.192 0.396 0.746 \u03b1(Percent living under the federal poverty line 2018 ) -0.323 -0.151 -0.0469 0.0561 0.266 \u03b1(Percent at risk for serious illness due to COVID) -0.177 -0.0958 -0.0514 0.0176 0.13","title":"L\u2081 = 1, L\u2082 = 7"},{"location":"rt_longdiff/#l1-3-l2-1","text":"parameters mean std naive_se mcse ess r_hat \u03b3 0.0749 0.0147 0.000328 0.000426 721.0 1.0 \u03c3R0 10.1 1.81 0.0404 0.0452 891.0 1.0 \u03b10(constant) 0.192 3.17 0.0709 0.0734 2150.0 1.0 \u03b10(logpopdens) 1.02 2.96 0.0661 0.0712 2220.0 1.0 \u03b10(Percent Unemployed 2018 ) 0.777 3.11 0.0695 0.0701 2300.0 1.0 \u03b10(Percent living under the federal poverty line 2018 ) 0.744 2.77 0.0619 0.0792 2020.0 1.0 \u03b10(Percent at risk for serious illness due to COVID) 1.62 1.47 0.0328 0.0527 900.0 1.0 \u03c3R 1.39 0.772 0.0173 0.0229 1280.0 1.0 \u03c3k 0.189 0.0191 0.000428 0.00059 1020.0 1.0 \u03c1 0.0952 0.038 0.00085 0.00108 1290.0 1.0 \u03b1(Stay at home shelter in place) -1.06 0.333 0.00745 0.00883 1210.0 1.0 \u03b1(Date closed K 12 schools) 0.303 0.389 0.00869 0.00864 2330.0 1.0 \u03b1(Closed gyms) -0.453 0.518 0.0116 0.0108 2110.0 1.0 \u03b1(Closed movie theaters) 0.0294 0.532 0.0119 0.00911 2190.0 1.0 \u03b1(Closed day cares) -0.0225 0.247 0.00552 0.00508 2700.0 1.0 \u03b1(Date banned visitors to nursing homes) -0.12 0.197 0.00441 0.00461 2070.0 1.0 \u03b1(Closed non essential businesses) -0.568 0.306 0.00684 0.0067 2070.0 1.0 \u03b1(Closed restaurants except take out) 0.0813 0.434 0.0097 0.00796 2950.0 1.0 \u03b1(retail and recreation percent change from baseline) -0.19 1.31 0.0292 0.022 2300.0 1.0 \u03b1(grocery and pharmacy percent change from baseline) 1.92 1.06 0.0237 0.0253 2130.0 1.0 \u03b1(parks percent change from baseline) 0.0128 0.274 0.00613 0.00538 2650.0 1.0 \u03b1(transit stations percent change from baseline) 2.12 1.17 0.0262 0.0278 2180.0 1.0 \u03b1(workplaces percent change from baseline) -1.22 1.61 0.036 0.0329 2170.0 1.0 \u03b1(residential percent change from baseline) 6.75 2.5 0.0558 0.038 2600.0 1.0 \u03b1(percentchangebusinesses) 3.01 1.31 0.0294 0.0256 2100.0 1.0 \u03b1(constant) -0.0793 1.08 0.0242 0.0235 2360.0 1.0 \u03b1(logpopdens) 0.251 0.0857 0.00192 0.00263 1300.0 1.0 \u03b1(Percent Unemployed 2018 ) 0.413 0.153 0.00342 0.00326 2060.0 1.0 \u03b1(Percent living under the federal poverty line 2018 ) -0.175 0.0685 0.00153 0.0019 1590.0 1.0 \u03b1(Percent at risk for serious illness due to COVID) 0.0787 0.0342 0.000764 0.000853 1940.0 1.0 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0505 0.0642 0.0733 0.0838 0.107 \u03c3R0 6.91 8.86 10.1 11.3 14.0 \u03b10(constant) -6.37 -1.82 0.211 2.21 6.37 \u03b10(logpopdens) -5.04 -0.921 1.07 3.03 6.48 \u03b10(Percent Unemployed 2018 ) -5.07 -1.26 0.739 2.86 6.93 \u03b10(Percent living under the federal poverty line 2018 ) -4.46 -1.19 0.767 2.65 6.29 \u03b10(Percent at risk for serious illness due to COVID) -0.899 0.672 1.46 2.4 5.19 \u03c3R 0.062 0.789 1.41 1.95 2.85 \u03c3k 0.142 0.179 0.195 0.204 0.212 \u03c1 0.0284 0.0696 0.0922 0.12 0.177 \u03b1(Stay at home shelter in place) -1.82 -1.26 -1.03 -0.831 -0.482 \u03b1(Date closed K 12 schools) -0.408 0.0441 0.277 0.556 1.1 \u03b1(Closed gyms) -1.5 -0.784 -0.426 -0.106 0.537 \u03b1(Closed movie theaters) -0.997 -0.325 0.0246 0.367 1.05 \u03b1(Closed day cares) -0.528 -0.185 -0.0191 0.137 0.466 \u03b1(Date banned visitors to nursing homes) -0.537 -0.247 -0.116 0.0104 0.266 \u03b1(Closed non essential businesses) -1.25 -0.743 -0.545 -0.357 -0.00389 \u03b1(Closed restaurants except take out) -0.793 -0.19 0.0846 0.359 0.918 \u03b1(retail and recreation percent change from baseline) -2.82 -1.1 -0.193 0.7 2.24 \u03b1(grocery and pharmacy percent change from baseline) -0.0693 1.21 1.89 2.58 4.1 \u03b1(parks percent change from baseline) -0.525 -0.157 0.00405 0.193 0.583 \u03b1(transit stations percent change from baseline) -0.000774 1.3 2.1 2.88 4.56 \u03b1(workplaces percent change from baseline) -4.49 -2.24 -1.14 -0.0858 1.76 \u03b1(residential percent change from baseline) 1.67 5.17 6.75 8.37 11.6 \u03b1(percentchangebusinesses) 0.653 2.07 2.96 3.89 5.71 \u03b1(constant) -2.22 -0.768 -0.0516 0.599 1.93 \u03b1(logpopdens) 0.106 0.191 0.243 0.303 0.435 \u03b1(Percent Unemployed 2018 ) 0.14 0.298 0.406 0.512 0.74 \u03b1(Percent living under the federal poverty line 2018 ) -0.322 -0.22 -0.17 -0.127 -0.0546 \u03b1(Percent at risk for serious illness due to COVID) 0.0166 0.0555 0.0763 0.1 0.147","title":"L\u2081 = 3, L\u2082 = 1"},{"location":"rt_longdiff/#l1-3-l2-3","text":"parameters mean std naive_se mcse ess r_hat \u03b3 0.0467 0.00712 0.000159 0.000317 452.0 1.0 \u03c3R0 8.24 1.26 0.0281 0.0462 631.0 1.0 \u03b10(constant) 0.682 3.07 0.0687 0.0688 1190.0 1.0 \u03b10(logpopdens) -0.561 1.27 0.0283 0.0381 789.0 1.0 \u03b10(Percent Unemployed 2018 ) 1.97 1.95 0.0436 0.0602 857.0 1.0 \u03b10(Percent living under the federal poverty line 2018 ) -0.856 0.964 0.0216 0.0253 1140.0 1.0 \u03b10(Percent at risk for serious illness due to COVID) 0.279 0.341 0.00764 0.00794 1130.0 1.0 \u03c3R 3.28 0.454 0.0102 0.0209 415.0 1.0 \u03c3k 0.00423 0.00338 7.57e-5 0.000104 851.0 1.0 \u03c1 0.597 0.0152 0.000339 0.000341 2030.0 1.0 \u03b1(Stay at home shelter in place) -1.7 0.472 0.0106 0.0248 383.0 1.0 \u03b1(Date closed K 12 schools) -0.221 0.49 0.011 0.00954 1210.0 1.0 \u03b1(Closed gyms) -0.958 0.731 0.0163 0.0253 790.0 1.0 \u03b1(Closed movie theaters) -0.075 0.776 0.0174 0.0316 823.0 1.0 \u03b1(Closed day cares) -0.322 0.446 0.00998 0.0125 798.0 1.0 \u03b1(Date banned visitors to nursing homes) -0.373 0.371 0.00829 0.018 505.0 1.0 \u03b1(Closed non essential businesses) -0.383 0.456 0.0102 0.0107 1210.0 1.0 \u03b1(Closed restaurants except take out) 0.323 0.578 0.0129 0.0182 1090.0 1.0 \u03b1(retail and recreation percent change from baseline) -0.731 1.63 0.0365 0.0434 1470.0 1.0 \u03b1(grocery and pharmacy percent change from baseline) 1.73 1.38 0.0309 0.0305 1510.0 1.0 \u03b1(parks percent change from baseline) -0.183 0.311 0.00695 0.00876 1180.0 1.0 \u03b1(transit stations percent change from baseline) 2.64 1.55 0.0348 0.0555 1100.0 1.0 \u03b1(workplaces percent change from baseline) 1.57 1.54 0.0345 0.0581 1170.0 1.0 \u03b1(residential percent change from baseline) 4.34 2.46 0.0551 0.109 872.0 1.0 \u03b1(percentchangebusinesses) -0.0896 1.19 0.0266 0.04 939.0 1.0 \u03b1(constant) 1.29 1.71 0.0383 0.0405 1140.0 1.0 \u03b1(logpopdens) 0.371 0.151 0.00338 0.00442 1030.0 1.0 \u03b1(Percent Unemployed 2018 ) 0.452 0.265 0.00592 0.00678 1140.0 1.0 \u03b1(Percent living under the federal poverty line 2018 ) -0.208 0.115 0.00257 0.00274 1110.0 1.0 \u03b1(Percent at risk for serious illness due to COVID) 0.0867 0.0566 0.00127 0.0017 954.0 1.0 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0371 0.0414 0.0453 0.0507 0.0644 \u03c3R0 5.91 7.38 8.23 9.07 10.8 \u03b10(constant) -5.32 -1.45 0.783 2.79 6.51 \u03b10(logpopdens) -3.04 -1.37 -0.569 0.243 2.07 \u03b10(Percent Unemployed 2018 ) -1.72 0.604 1.96 3.27 5.83 \u03b10(Percent living under the federal poverty line 2018 ) -2.78 -1.49 -0.83 -0.178 1.06 \u03b10(Percent at risk for serious illness due to COVID) -0.377 0.0473 0.28 0.5 0.957 \u03c3R 2.32 2.96 3.31 3.62 4.05 \u03c3k 0.000105 0.00147 0.00348 0.0062 0.0122 \u03c1 0.567 0.587 0.597 0.607 0.626 \u03b1(Stay at home shelter in place) -2.72 -2.0 -1.67 -1.37 -0.877 \u03b1(Date closed K 12 schools) -1.2 -0.544 -0.205 0.114 0.728 \u03b1(Closed gyms) -2.31 -1.44 -0.955 -0.476 0.498 \u03b1(Closed movie theaters) -1.66 -0.567 -0.0393 0.445 1.38 \u03b1(Closed day cares) -1.21 -0.602 -0.309 -0.0271 0.544 \u03b1(Date banned visitors to nursing homes) -1.15 -0.608 -0.344 -0.13 0.315 \u03b1(Closed non essential businesses) -1.29 -0.679 -0.378 -0.0838 0.475 \u03b1(Closed restaurants except take out) -0.82 -0.0493 0.316 0.702 1.48 \u03b1(retail and recreation percent change from baseline) -4.12 -1.74 -0.728 0.341 2.37 \u03b1(grocery and pharmacy percent change from baseline) -0.949 0.792 1.68 2.66 4.59 \u03b1(parks percent change from baseline) -0.814 -0.386 -0.179 0.0266 0.415 \u03b1(transit stations percent change from baseline) -0.312 1.61 2.63 3.7 5.77 \u03b1(workplaces percent change from baseline) -1.38 0.522 1.57 2.6 4.61 \u03b1(residential percent change from baseline) -0.514 2.7 4.38 6.03 9.2 \u03b1(percentchangebusinesses) -2.4 -0.922 -0.104 0.727 2.26 \u03b1(constant) -2.07 0.142 1.26 2.41 4.57 \u03b1(logpopdens) 0.0994 0.266 0.36 0.469 0.682 \u03b1(Percent Unemployed 2018 ) -0.0351 0.268 0.438 0.631 1.0 \u03b1(Percent living under the federal poverty line 2018 ) -0.44 -0.282 -0.201 -0.13 0.00571 \u03b1(Percent at risk for serious illness due to COVID) -0.0164 0.0488 0.0853 0.123 0.203","title":"L\u2081 = 3, L\u2082 = 3"},{"location":"rt_longdiff/#l1-3-l2-7","text":"parameters mean std naive_se mcse ess r_hat \u03b3 0.038 0.00243 5.44e-5 0.000236 55.9 1.04 \u03c3R0 4.16 0.488 0.0109 0.0499 50.8 1.04 \u03b10(constant) -0.957 1.83 0.0409 0.377 8.03 1.26 \u03b10(logpopdens) -0.457 0.62 0.0139 0.0953 15.8 1.13 \u03b10(Percent Unemployed 2018 ) 0.697 1.16 0.0258 0.243 8.21 1.18 \u03b10(Percent living under the federal poverty line 2018 ) -0.0466 0.471 0.0105 0.0884 9.43 1.15 \u03b10(Percent at risk for serious illness due to COVID) 0.19 0.135 0.00302 0.0186 16.0 1.16 \u03c3R 1.56 0.0921 0.00206 0.00849 114.0 1.01 \u03c3k 0.00257 0.00204 4.55e-5 0.000412 8.03 1.54 \u03c1 0.877 0.00989 0.000221 0.000799 157.0 1.0 \u03b1(Stay at home shelter in place) -0.602 0.291 0.0065 0.0336 57.0 1.02 \u03b1(Date closed K 12 schools) 0.721 0.286 0.00639 0.0346 50.7 1.02 \u03b1(Closed gyms) -0.679 0.502 0.0112 0.0685 24.4 1.03 \u03b1(Closed movie theaters) -0.119 0.539 0.012 0.0693 28.6 1.03 \u03b1(Closed day cares) 0.053 0.322 0.0072 0.0362 64.5 1.01 \u03b1(Date banned visitors to nursing homes) -0.133 0.292 0.00653 0.0279 98.1 1.0 \u03b1(Closed non essential businesses) 0.1 0.324 0.00724 0.0407 54.9 1.01 \u03b1(Closed restaurants except take out) 0.726 0.34 0.0076 0.0394 66.8 1.01 \u03b1(retail and recreation percent change from baseline) 3.32 0.896 0.02 0.163 8.34 1.33 \u03b1(grocery and pharmacy percent change from baseline) -0.613 0.83 0.0186 0.123 18.6 1.16 \u03b1(parks percent change from baseline) -0.358 0.16 0.00357 0.0192 44.2 1.04 \u03b1(transit stations percent change from baseline) -0.368 0.792 0.0177 0.135 25.1 1.02 \u03b1(workplaces percent change from baseline) -0.253 0.812 0.0182 0.104 31.6 1.06 \u03b1(residential percent change from baseline) -2.0 1.34 0.0299 0.216 13.5 1.22 \u03b1(percentchangebusinesses) 0.302 0.546 0.0122 0.103 11.8 1.05 \u03b1(constant) 1.06 1.33 0.0297 0.253 9.08 1.15 \u03b1(logpopdens) 0.557 0.219 0.00491 0.0238 71.0 1.01 \u03b1(Percent Unemployed 2018 ) -0.0654 0.423 0.00946 0.0669 13.0 1.2 \u03b1(Percent living under the federal poverty line 2018 ) -0.0965 0.172 0.00384 0.0252 15.5 1.11 \u03b1(Percent at risk for serious illness due to COVID) 0.0407 0.0589 0.00132 0.00834 14.4 1.11 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0358 0.0363 0.0372 0.0388 0.0443 \u03c3R0 3.24 3.84 4.15 4.46 5.17 \u03b10(constant) -5.19 -1.98 -0.571 0.366 1.7 \u03b10(logpopdens) -1.73 -0.851 -0.463 -0.0485 0.703 \u03b10(Percent Unemployed 2018 ) -1.83 0.118 0.84 1.44 2.72 \u03b10(Percent living under the federal poverty line 2018 ) -0.958 -0.374 -0.065 0.266 0.939 \u03b10(Percent at risk for serious illness due to COVID) -0.0632 0.094 0.188 0.283 0.469 \u03c3R 1.33 1.52 1.58 1.62 1.67 \u03c3k 0.000203 0.000795 0.00205 0.00402 0.00721 \u03c1 0.857 0.87 0.877 0.883 0.896 \u03b1(Stay at home shelter in place) -1.2 -0.802 -0.592 -0.397 -0.0837 \u03b1(Date closed K 12 schools) 0.175 0.517 0.709 0.926 1.27 \u03b1(Closed gyms) -1.71 -1.02 -0.678 -0.312 0.219 \u03b1(Closed movie theaters) -1.22 -0.491 -0.0963 0.281 0.94 \u03b1(Closed day cares) -0.523 -0.172 0.0376 0.261 0.747 \u03b1(Date banned visitors to nursing homes) -0.713 -0.328 -0.139 0.0713 0.423 \u03b1(Closed non essential businesses) -0.543 -0.102 0.0933 0.324 0.715 \u03b1(Closed restaurants except take out) 0.0734 0.487 0.738 0.981 1.33 \u03b1(retail and recreation percent change from baseline) 1.54 2.71 3.43 4.02 4.86 \u03b1(grocery and pharmacy percent change from baseline) -2.28 -1.2 -0.645 -0.0559 1.01 \u03b1(parks percent change from baseline) -0.682 -0.469 -0.353 -0.246 -0.0472 \u03b1(transit stations percent change from baseline) -2.25 -0.871 -0.186 0.196 0.857 \u03b1(workplaces percent change from baseline) -2.06 -0.775 -0.186 0.333 1.16 \u03b1(residential percent change from baseline) -4.47 -2.96 -2.03 -1.05 0.696 \u03b1(percentchangebusinesses) -0.666 -0.112 0.301 0.683 1.34 \u03b1(constant) -1.22 0.162 0.981 1.87 4.0 \u03b1(logpopdens) 0.124 0.406 0.549 0.703 0.987 \u03b1(Percent Unemployed 2018 ) -0.966 -0.324 -0.0593 0.209 0.731 \u03b1(Percent living under the federal poverty line 2018 ) -0.43 -0.214 -0.0941 0.00663 0.272 \u03b1(Percent at risk for serious illness due to COVID) -0.0967 0.00641 0.0421 0.0812 0.149","title":"L\u2081 = 3, L\u2082 = 7"},{"location":"rt_longdiff/#l1-7-l2-1","text":"parameters mean std naive_se mcse ess r_hat \u03b3 0.0394 0.00367 8.2e-5 0.000382 39.5 1.1 \u03c3R0 6.84 1.39 0.0311 0.153 42.3 1.02 \u03b10(constant) 2.64 3.36 0.0752 0.696 9.98 1.33 \u03b10(logpopdens) 0.201 1.08 0.024 0.146 43.3 1.0 \u03b10(Percent Unemployed 2018 ) 0.272 1.54 0.0343 0.252 14.5 1.23 \u03b10(Percent living under the federal poverty line 2018 ) -0.0227 0.759 0.017 0.115 18.5 1.09 \u03b10(Percent at risk for serious illness due to COVID) 0.127 0.302 0.00675 0.0449 40.8 1.03 \u03c3R 1.58 0.407 0.0091 0.0522 35.3 1.03 \u03c3k 0.0963 0.00655 0.000147 0.000867 29.2 1.07 \u03c1 0.7 0.128 0.00285 0.0188 22.0 1.09 \u03b1(Stay at home shelter in place) -1.97 0.396 0.00886 0.0517 24.6 1.05 \u03b1(Date closed K 12 schools) 0.451 0.605 0.0135 0.0749 32.2 1.05 \u03b1(Closed gyms) -0.707 0.654 0.0146 0.0902 32.8 1.02 \u03b1(Closed movie theaters) -0.0205 0.691 0.0155 0.0842 44.7 1.0 \u03b1(Closed day cares) -0.242 0.326 0.0073 0.0313 69.0 1.0 \u03b1(Date banned visitors to nursing homes) -0.695 0.344 0.00768 0.0389 27.4 1.08 \u03b1(Closed non essential businesses) -0.899 0.441 0.00986 0.0535 67.4 1.01 \u03b1(Closed restaurants except take out) 0.461 0.576 0.0129 0.0496 93.7 1.02 \u03b1(retail and recreation percent change from baseline) 0.222 1.66 0.037 0.313 11.0 1.09 \u03b1(grocery and pharmacy percent change from baseline) -0.899 1.29 0.0289 0.227 13.5 1.13 \u03b1(parks percent change from baseline) 0.0558 0.355 0.00794 0.0415 41.4 1.02 \u03b1(transit stations percent change from baseline) 2.36 1.16 0.0259 0.135 73.2 1.01 \u03b1(workplaces percent change from baseline) -1.1 1.6 0.0359 0.282 8.98 1.24 \u03b1(residential percent change from baseline) 5.38 2.38 0.0532 0.383 9.65 1.35 \u03b1(percentchangebusinesses) 0.684 1.4 0.0312 0.218 19.3 1.08 \u03b1(constant) -0.0262 1.4 0.0313 0.243 17.1 1.0 \u03b1(logpopdens) 0.474 0.121 0.0027 0.00905 176.0 1.02 \u03b1(Percent Unemployed 2018 ) 0.361 0.249 0.00556 0.0231 54.7 1.03 \u03b1(Percent living under the federal poverty line 2018 ) -0.145 0.106 0.00237 0.0118 38.2 1.02 \u03b1(Percent at risk for serious illness due to COVID) 0.072 0.0566 0.00127 0.009 20.6 1.0 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0358 0.0369 0.0383 0.0408 0.0501 \u03c3R0 4.38 5.84 6.77 7.68 9.85 \u03b10(constant) -4.76 0.732 3.48 5.04 7.35 \u03b10(logpopdens) -1.88 -0.458 0.228 0.862 2.48 \u03b10(Percent Unemployed 2018 ) -2.91 -0.737 0.32 1.43 3.04 \u03b10(Percent living under the federal poverty line 2018 ) -1.38 -0.545 -0.112 0.428 1.62 \u03b10(Percent at risk for serious illness due to COVID) -0.542 -0.0261 0.139 0.287 0.795 \u03c3R 0.951 1.28 1.52 1.8 2.47 \u03c3k 0.0763 0.0942 0.0977 0.1 0.105 \u03c1 0.37 0.637 0.73 0.799 0.861 \u03b1(Stay at home shelter in place) -2.72 -2.23 -1.97 -1.71 -1.21 \u03b1(Date closed K 12 schools) -0.631 0.0401 0.406 0.872 1.68 \u03b1(Closed gyms) -2.01 -1.15 -0.688 -0.25 0.538 \u03b1(Closed movie theaters) -1.42 -0.451 -0.0115 0.436 1.27 \u03b1(Closed day cares) -0.867 -0.474 -0.244 -0.0262 0.412 \u03b1(Date banned visitors to nursing homes) -1.38 -0.924 -0.687 -0.462 -0.0157 \u03b1(Closed non essential businesses) -1.69 -1.18 -0.909 -0.624 0.029 \u03b1(Closed restaurants except take out) -0.588 0.0512 0.43 0.821 1.69 \u03b1(retail and recreation percent change from baseline) -3.26 -0.885 0.431 1.33 3.35 \u03b1(grocery and pharmacy percent change from baseline) -3.01 -1.89 -1.01 0.0283 1.79 \u03b1(parks percent change from baseline) -0.643 -0.2 0.0536 0.323 0.71 \u03b1(transit stations percent change from baseline) 0.126 1.63 2.36 3.15 4.71 \u03b1(workplaces percent change from baseline) -4.47 -2.26 -0.956 0.01 1.84 \u03b1(residential percent change from baseline) 1.64 3.65 5.09 6.9 11.3 \u03b1(percentchangebusinesses) -1.69 -0.385 0.589 1.57 3.83 \u03b1(constant) -2.91 -0.798 0.0916 0.875 2.6 \u03b1(logpopdens) 0.235 0.398 0.474 0.55 0.711 \u03b1(Percent Unemployed 2018 ) -0.2 0.202 0.378 0.522 0.828 \u03b1(Percent living under the federal poverty line 2018 ) -0.35 -0.215 -0.145 -0.076 0.0696 \u03b1(Percent at risk for serious illness due to COVID) -0.0435 0.0346 0.0723 0.113 0.177","title":"L\u2081 = 7, L\u2082 = 1"},{"location":"rt_longdiff/#l1-7-l2-3","text":"parameters mean std naive_se mcse ess r_hat \u03b3 0.0379 0.00233 5.2e-5 0.000166 196.0 1.01 \u03c3R0 4.97 0.537 0.012 0.0418 153.0 1.0 \u03b10(constant) 0.423 1.93 0.0433 0.338 13.0 1.02 \u03b10(logpopdens) -0.222 0.651 0.0146 0.0973 31.5 1.03 \u03b10(Percent Unemployed 2018 ) 0.149 0.98 0.0219 0.159 38.0 1.01 \u03b10(Percent living under the federal poverty line 2018 ) -0.169 0.49 0.011 0.0537 62.9 1.01 \u03b10(Percent at risk for serious illness due to COVID) 0.224 0.168 0.00376 0.0203 47.0 1.0 \u03c3R 1.73 0.0998 0.00223 0.00738 182.0 1.01 \u03c3k 0.00216 0.00159 3.56e-5 0.000133 90.8 1.03 \u03c1 0.837 0.0117 0.000263 0.000746 249.0 1.01 \u03b1(Stay at home shelter in place) -0.895 0.353 0.00789 0.0495 44.1 1.0 \u03b1(Date closed K 12 schools) -0.0798 0.325 0.00727 0.0298 120.0 1.01 \u03b1(Closed gyms) -0.586 0.528 0.0118 0.0511 101.0 1.0 \u03b1(Closed movie theaters) -0.122 0.545 0.0122 0.0633 80.6 1.0 \u03b1(Closed day cares) -0.31 0.423 0.00946 0.0602 21.2 1.01 \u03b1(Date banned visitors to nursing homes) -0.501 0.294 0.00657 0.0244 151.0 1.01 \u03b1(Closed non essential businesses) 0.025 0.357 0.00799 0.0418 60.0 1.0 \u03b1(Closed restaurants except take out) 0.767 0.447 0.01 0.0597 41.2 1.02 \u03b1(retail and recreation percent change from baseline) 0.897 0.947 0.0212 0.17 11.4 1.1 \u03b1(grocery and pharmacy percent change from baseline) -0.878 0.794 0.0178 0.137 23.1 1.01 \u03b1(parks percent change from baseline) -0.0684 0.178 0.00399 0.0254 11.9 1.22 \u03b1(transit stations percent change from baseline) 0.978 0.936 0.0209 0.111 25.1 1.11 \u03b1(workplaces percent change from baseline) 2.08 1.01 0.0226 0.177 8.26 1.43 \u03b1(residential percent change from baseline) 3.06 1.72 0.0385 0.316 8.03 1.42 \u03b1(percentchangebusinesses) -0.0657 0.632 0.0141 0.0758 57.9 1.03 \u03b1(constant) 2.29 1.99 0.0444 0.379 9.61 1.32 \u03b1(logpopdens) 0.504 0.183 0.00409 0.0185 84.7 1.06 \u03b1(Percent Unemployed 2018 ) 0.00689 0.3 0.0067 0.0331 66.0 1.02 \u03b1(Percent living under the federal poverty line 2018 ) -0.0776 0.125 0.00279 0.011 104.0 1.0 \u03b1(Percent at risk for serious illness due to COVID) 0.0233 0.0648 0.00145 0.0102 12.7 1.18 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0358 0.0363 0.0371 0.0386 0.0446 \u03c3R0 3.95 4.62 4.96 5.31 6.12 \u03b10(constant) -3.71 -0.792 0.618 1.86 3.57 \u03b10(logpopdens) -1.34 -0.71 -0.25 0.207 1.11 \u03b10(Percent Unemployed 2018 ) -1.72 -0.604 0.151 0.885 2.02 \u03b10(Percent living under the federal poverty line 2018 ) -1.07 -0.497 -0.177 0.151 0.763 \u03b10(Percent at risk for serious illness due to COVID) -0.136 0.118 0.221 0.342 0.528 \u03c3R 1.46 1.69 1.76 1.8 1.85 \u03c3k 0.000117 0.000812 0.00187 0.00317 0.00583 \u03c1 0.814 0.829 0.837 0.845 0.862 \u03b1(Stay at home shelter in place) -1.7 -1.12 -0.891 -0.669 -0.196 \u03b1(Date closed K 12 schools) -0.734 -0.293 -0.0633 0.144 0.519 \u03b1(Closed gyms) -1.63 -0.941 -0.61 -0.211 0.472 \u03b1(Closed movie theaters) -1.09 -0.477 -0.13 0.225 0.992 \u03b1(Closed day cares) -1.21 -0.563 -0.317 -0.0113 0.565 \u03b1(Date banned visitors to nursing homes) -1.06 -0.7 -0.495 -0.295 0.0612 \u03b1(Closed non essential businesses) -0.687 -0.211 0.0368 0.256 0.699 \u03b1(Closed restaurants except take out) -0.148 0.489 0.769 1.06 1.62 \u03b1(retail and recreation percent change from baseline) -1.11 0.312 0.838 1.6 2.63 \u03b1(grocery and pharmacy percent change from baseline) -2.34 -1.46 -0.886 -0.35 0.612 \u03b1(parks percent change from baseline) -0.416 -0.192 -0.0696 0.0577 0.302 \u03b1(transit stations percent change from baseline) -0.961 0.389 0.936 1.59 2.94 \u03b1(workplaces percent change from baseline) 0.163 1.34 2.08 2.85 3.97 \u03b1(residential percent change from baseline) -0.698 2.01 3.25 4.19 6.17 \u03b1(percentchangebusinesses) -1.16 -0.518 -0.093 0.353 1.25 \u03b1(constant) -1.77 1.13 2.56 3.73 5.82 \u03b1(logpopdens) 0.153 0.38 0.504 0.624 0.87 \u03b1(Percent Unemployed 2018 ) -0.588 -0.209 0.0175 0.22 0.552 \u03b1(Percent living under the federal poverty line 2018 ) -0.322 -0.157 -0.0755 0.0064 0.173 \u03b1(Percent at risk for serious illness due to COVID) -0.09 -0.0215 0.019 0.0665 0.15","title":"L\u2081 = 7, L\u2082 = 3"},{"location":"rt_longdiff/#l1-7-l2-7","text":"parameters mean std naive_se mcse ess r_hat \u03b3 0.0375 0.00187 4.18e-5 0.000195 84.3 1.03 \u03c3R0 3.14 0.341 0.00763 0.0411 28.0 1.04 \u03b10(constant) 1.16 0.839 0.0188 0.18 8.04 1.59 \u03b10(logpopdens) -0.471 0.35 0.00782 0.0447 55.7 1.01 \u03b10(Percent Unemployed 2018 ) 0.785 0.488 0.0109 0.0912 11.3 1.21 \u03b10(Percent living under the federal poverty line 2018 ) -0.264 0.278 0.00622 0.0422 13.1 1.2 \u03b10(Percent at risk for serious illness due to COVID) 0.216 0.0936 0.00209 0.013 19.8 1.12 \u03c3R 0.936 0.0458 0.00103 0.00494 60.8 1.04 \u03c3k 0.000728 0.00048 1.07e-5 9.65e-5 8.65 1.08 \u03c1 0.936 0.00643 0.000144 0.000381 242.0 1.0 \u03b1(Stay at home shelter in place) -0.264 0.195 0.00436 0.0336 18.3 1.01 \u03b1(Date closed K 12 schools) 0.339 0.209 0.00468 0.0342 15.6 1.22 \u03b1(Closed gyms) -0.0412 0.34 0.00761 0.0657 8.52 1.3 \u03b1(Closed movie theaters) 0.23 0.39 0.00873 0.0741 8.03 1.51 \u03b1(Closed day cares) 0.218 0.306 0.00683 0.0559 18.2 1.0 \u03b1(Date banned visitors to nursing homes) -0.644 0.247 0.00552 0.0362 22.2 1.14 \u03b1(Closed non essential businesses) 0.00545 0.224 0.005 0.0348 27.2 1.01 \u03b1(Closed restaurants except take out) 0.497 0.199 0.00445 0.0276 37.9 1.06 \u03b1(retail and recreation percent change from baseline) 1.68 0.495 0.0111 0.0903 15.5 1.01 \u03b1(grocery and pharmacy percent change from baseline) -1.4 0.425 0.00951 0.0808 10.7 1.05 \u03b1(parks percent change from baseline) -0.0749 0.109 0.00243 0.0188 12.7 1.04 \u03b1(transit stations percent change from baseline) 0.912 0.494 0.011 0.0871 13.7 1.11 \u03b1(workplaces percent change from baseline) 0.333 0.796 0.0178 0.173 8.03 1.5 \u03b1(residential percent change from baseline) 1.04 1.33 0.0297 0.299 8.03 1.7 \u03b1(percentchangebusinesses) -0.158 0.397 0.00889 0.0824 11.6 1.0 \u03b1(constant) 2.25 1.93 0.0432 0.44 8.03 2.38 \u03b1(logpopdens) 0.771 0.243 0.00544 0.0332 40.3 1.0 \u03b1(Percent Unemployed 2018 ) -0.648 0.418 0.00934 0.0772 13.5 1.02 \u03b1(Percent living under the federal poverty line 2018 ) 0.121 0.155 0.00347 0.0192 46.8 1.02 \u03b1(Percent at risk for serious illness due to COVID) -0.0734 0.0648 0.00145 0.0105 9.42 1.18 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0358 0.0362 0.0369 0.038 0.0428 \u03c3R0 2.51 2.91 3.14 3.36 3.9 \u03b10(constant) -0.641 0.573 1.25 1.79 2.54 \u03b10(logpopdens) -1.09 -0.714 -0.514 -0.253 0.287 \u03b10(Percent Unemployed 2018 ) -0.245 0.518 0.862 1.12 1.59 \u03b10(Percent living under the federal poverty line 2018 ) -0.826 -0.431 -0.259 -0.0933 0.301 \u03b10(Percent at risk for serious illness due to COVID) 0.0402 0.156 0.214 0.279 0.395 \u03c3R 0.817 0.915 0.945 0.967 0.998 \u03c3k 0.000147 0.000378 0.000634 0.001 0.00172 \u03c1 0.924 0.932 0.936 0.941 0.948 \u03b1(Stay at home shelter in place) -0.681 -0.385 -0.252 -0.133 0.101 \u03b1(Date closed K 12 schools) -0.00467 0.179 0.324 0.473 0.803 \u03b1(Closed gyms) -0.785 -0.304 0.0118 0.209 0.536 \u03b1(Closed movie theaters) -0.497 -0.0643 0.188 0.533 1.01 \u03b1(Closed day cares) -0.404 0.00634 0.225 0.42 0.762 \u03b1(Date banned visitors to nursing homes) -1.17 -0.794 -0.64 -0.487 -0.146 \u03b1(Closed non essential businesses) -0.444 -0.142 0.0153 0.165 0.426 \u03b1(Closed restaurants except take out) 0.115 0.36 0.496 0.624 0.915 \u03b1(retail and recreation percent change from baseline) 0.704 1.39 1.63 1.98 2.75 \u03b1(grocery and pharmacy percent change from baseline) -2.28 -1.68 -1.37 -1.1 -0.645 \u03b1(parks percent change from baseline) -0.302 -0.151 -0.0647 0.00749 0.11 \u03b1(transit stations percent change from baseline) 0.0133 0.541 0.932 1.27 1.8 \u03b1(workplaces percent change from baseline) -1.13 -0.21 0.477 0.874 1.65 \u03b1(residential percent change from baseline) -1.65 0.103 1.66 1.98 2.62 \u03b1(percentchangebusinesses) -0.843 -0.436 -0.173 0.139 0.567 \u03b1(constant) -1.09 1.04 2.19 3.73 5.28 \u03b1(logpopdens) 0.268 0.617 0.772 0.936 1.23 \u03b1(Percent Unemployed 2018 ) -1.47 -0.957 -0.604 -0.344 0.0735 \u03b1(Percent living under the federal poverty line 2018 ) -0.173 0.0112 0.119 0.221 0.44 \u03b1(Percent at risk for serious illness due to COVID) -0.192 -0.123 -0.0722 -0.0259 0.0535","title":"L\u2081 = 7, L\u2082 = 7"},{"location":"rt_onlym/","text":"Results \u00b6 ## data prep using CovidData using CovidRt using TransformVariables, Parameters, Plots, StatsPlots, DataFrames, Dates, LinearAlgebra, Distributions, Random, LogDensityProblems, DynamicHMC, MCMCChains, JLD2, Latexify Plots.pyplot() df = CovidData.statedata(policies=:indicators, fillmissingmobility=true) df[!,:log_encounters_rate] = log.(1 .+ df[!,:encounters_rate]) pvars = [Symbol(\"Stay.at.home..shelter.in.place\"), #Symbol(\"State.of.emergency\"), Symbol(\"Date.closed.K.12.schools\"), Symbol(\"Closed.gyms\"), Symbol(\"Closed.movie.theaters\"), Symbol(\"Closed.day.cares\"), Symbol(\"Date.banned.visitors.to.nursing.homes\"), Symbol(\"Closed.non.essential.businesses\"), Symbol(\"Closed.restaurants.except.take.out\")] mvars = [:retail_and_recreation_percent_change_from_baseline, :grocery_and_pharmacy_percent_change_from_baseline, :parks_percent_change_from_baseline , :transit_stations_percent_change_from_baseline, :workplaces_percent_change_from_baseline, :residential_percent_change_from_baseline, :percentchangehours, :percentchangebusinesses, :daily_distance_diff, :daily_visitation_diff, :log_encounters_rate] df[!,:logpopdens] = log.(df[!,Symbol(\"Population.density.per.square.miles\")]) df[!,:weekend] = dayofweek.(df[!,:date]) .>= 6 x0vars=[:constant, :logpopdens, Symbol(\"Percent.Unemployed..2018.\"), Symbol(\"Percent.living.under.the.federal.poverty.line..2018.\"), Symbol(\"Percent.at.risk.for.serious.illness.due.to.COVID\")] sdf = filter(x->x.fips<60, df) sdf = sort(sdf, (:state, :date)) sdf[!,mvars] ./= 100 sdf[!,:constant] .= 1 xvars = vcat(x0vars, mvars); Here, we will allow the initial and time varying mean of $R_{s,t}$ to depend on covariates. \\begin{align*} \\tilde{R}_{s,0} & \\sim N(X_{0,s} \\alpha_0, \\sigma^2_{R,0}) \\\\ \\tilde{R}_{s,t} & = \\rho \\tilde{R}_{s,t} + u_{s,t} \\;,\\; u_{s,t} \\sim N(0, \\sigma^2_R) \\\\ R_{s,t} & = X_{s,t} \\alpha + \\tilde{R}_{s,t} \\\\ \\Delta \\log(k)_{s,t} & = \\gamma (R_{s,t} - 1) + \\epsilon_{s,t} - \\epsilon_{s,t-1} \\;, \\; \\epsilon_{s,t} \\sim N(0, \\sigma^2_k) \\end{align*} We present estimates of $R_t$ with \\Delta C(t) = C(t) - C(t-L_1) and \\Delta log (\\Delta C(t)) = log (\\Delta C(t)) - log (\\Delta C(t - L_2)) for a variety of values of $L_1$ and $L_2$ reestimate=true rlo=1 - eps(Float64) rhi=1+ eps(Float64) K = length(xvars) priors = (\u03b3 = truncated(Normal(1/7,1/7), 1/28, 1/1), \u03c3R0 = truncated(Normal(1, 3), 0, Inf), \u03b10 = MvNormal(zeros(length(x0vars)), sqrt(10)), #truncated(Normal(1, 3), 0, Inf), \u03c3R = truncated(Normal(0.25,1),0,Inf), \u03c3k = truncated(Normal(0.1, 5), 0, Inf), \u03c1 = Uniform(rlo, rhi), \u03b1 = MvNormal(zeros(K), sqrt(10)) ) states_to_plot = [\"New York\", \"New Jersey\",\"Massachusetts\",\"California\", \"Georgia\",\"Illinois\",\"Michigan\", \"Ohio\",\"Wisconsin\",\"Washington\"] warmup = default_warmup_stages(local_optimization=FindLocalOptimum(1e-4, 100), stepsize_search=nothing, init_steps=100, middle_steps=100, terminating_steps=2*100, doubling_stages=4, M=Symmetric) for L1 in [7] for L2 in [7] mdl = CovidRt.RtModel(sdf, Symbol(\"cases.nyt\"), xvars, x0vars, priors; L1=L1, L2=L2, time0=r->(r[Symbol(\"cases.nyt\")].>=5)) estfile = \"rt_onlym_$(L1)_$(L2).jld2\" if !isfile(estfile) || reestimate post = CovidRt.mcmc(mdl; iterations=2000, warmup=warmup) @save estfile post end @load estfile post cc = CovidRt.MCMCChain(post, xvars, x0vars) println(\"## L\u2081 = $(L1), L\u2082 = $(L2)\") println() #display(plot(cc)) println(latexify(DataFrame(describe(cc)[1]), env=:mdtable, latex=false, fmt=x->round(x, sigdigits=3))) println(latexify(DataFrame(describe(cc)[2]), env=:mdtable, latex=false, fmt=x->round(x, sigdigits=3))) states = mdl.id S = length(states_to_plot) figs = fill(plot(), S) for (i,st) in enumerate(states_to_plot) s = findfirst(states.==st) figr = CovidRt.plotpostr(mdl.t[s],mdl.dlogk[s],post, mdl.X[s], mdl.X0[s]) l = @layout [a{.1h}; grid(1,1)] figs[i] = plot(plot(annotation=(0.5,0.5, st*\", L\u2081=$(L1) L\u2082=$(L2)\"), framestyle = :none), plot(figr, ylim=(-1,15)), layout=l) display(figs[i]) end end end L\u2081 = 7, L\u2082 = 7 \u00b6 parameters mean std naive_se mcse ess r_hat \u03b3 0.039 0.00338 7.57e-5 0.000292 171.0 1.0 \u03c3R0 2.61 0.348 0.00778 0.0343 67.1 1.0 \u03b10(constant) 1.05 2.58 0.0576 0.345 55.1 1.0 \u03b10(logpopdens) -0.217 2.28 0.051 0.345 22.1 1.06 \u03b10(Percent Unemployed 2018 ) 0.187 2.28 0.051 0.238 83.1 1.0 \u03b10(Percent living under the federal poverty line 2018 ) -0.108 1.87 0.0417 0.243 71.5 1.0 \u03b10(Percent at risk for serious illness due to COVID) -0.139 2.27 0.0507 0.23 86.1 1.0 \u03c3R 0.786 0.0587 0.00131 0.00542 156.0 1.0 \u03c3k 0.000758 0.000633 1.42e-5 6.67e-5 80.3 1.03 \u03c1 1.0 1.48e-16 3.93e-18 5.7e-18 56.8 0.999 \u03b1(constant) 1.11 2.27 0.0508 0.218 77.9 1.05 \u03b1(logpopdens) 0.62 2.31 0.0516 0.358 18.9 1.07 \u03b1(Percent Unemployed 2018 ) 0.112 2.25 0.0502 0.235 81.3 1.0 \u03b1(Percent living under the federal poverty line 2018 ) -0.0819 1.86 0.0417 0.245 69.1 1.0 \u03b1(Percent at risk for serious illness due to COVID) 0.291 2.27 0.0508 0.232 84.2 1.0 \u03b1(retail and recreation percent change from baseline) 0.443 0.611 0.0137 0.0632 95.2 1.0 \u03b1(grocery and pharmacy percent change from baseline) -0.848 0.402 0.009 0.0419 107.0 1.0 \u03b1(parks percent change from baseline) 0.00586 0.0716 0.0016 0.00674 98.0 1.0 \u03b1(transit stations percent change from baseline) 0.145 0.531 0.0119 0.0589 77.4 1.0 \u03b1(workplaces percent change from baseline) -0.0129 0.655 0.0146 0.0841 72.5 1.0 \u03b1(residential percent change from baseline) -0.609 1.07 0.0239 0.133 75.6 1.0 \u03b1(percentchangehours) -0.367 0.523 0.0117 0.062 85.0 1.02 \u03b1(percentchangebusinesses) 1.34 0.683 0.0153 0.0906 54.5 1.0 \u03b1(daily distance diff) -0.466 3.04 0.0679 0.444 28.2 1.02 \u03b1(daily visitation diff) 0.0958 3.39 0.0758 0.433 69.4 1.0 \u03b1(log encounters rate) 1.81 2.95 0.066 0.335 65.8 1.03 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0358 0.0367 0.0379 0.04 0.0475 \u03c3R0 1.95 2.39 2.61 2.82 3.34 \u03b10(constant) -3.53 -0.481 0.778 2.58 6.72 \u03b10(logpopdens) -4.36 -1.82 -0.412 1.29 4.65 \u03b10(Percent Unemployed 2018 ) -4.38 -1.36 0.0871 1.76 4.55 \u03b10(Percent living under the federal poverty line 2018 ) -4.2 -1.22 -0.0256 1.28 3.11 \u03b10(Percent at risk for serious illness due to COVID) -4.33 -1.81 -0.0158 1.4 4.23 \u03c3R 0.634 0.759 0.801 0.827 0.856 \u03c3k 8.08e-6 0.00022 0.000623 0.00115 0.00221 \u03c1 1.0 1.0 1.0 1.0 1.0 \u03b1(constant) -3.74 -0.145 1.2 2.47 5.49 \u03b1(logpopdens) -4.14 -0.981 0.762 2.28 4.83 \u03b1(Percent Unemployed 2018 ) -4.27 -1.44 0.186 1.66 4.4 \u03b1(Percent living under the federal poverty line 2018 ) -3.23 -1.45 -0.187 1.02 3.99 \u03b1(Percent at risk for serious illness due to COVID) -4.12 -1.25 0.183 1.98 4.5 \u03b1(retail and recreation percent change from baseline) -0.815 0.0455 0.435 0.82 1.64 \u03b1(grocery and pharmacy percent change from baseline) -1.7 -1.1 -0.862 -0.561 -0.0653 \u03b1(parks percent change from baseline) -0.133 -0.0434 0.00755 0.0511 0.152 \u03b1(transit stations percent change from baseline) -0.949 -0.189 0.155 0.514 1.14 \u03b1(workplaces percent change from baseline) -1.29 -0.467 -0.0332 0.435 1.33 \u03b1(residential percent change from baseline) -2.72 -1.27 -0.644 0.0627 1.54 \u03b1(percentchangehours) -1.39 -0.748 -0.352 -0.000109 0.676 \u03b1(percentchangebusinesses) -0.159 0.907 1.37 1.81 2.62 \u03b1(daily distance diff) -6.4 -2.28 -0.764 1.56 5.87 \u03b1(daily visitation diff) -5.58 -2.43 0.156 2.39 7.95 \u03b1(log encounters rate) -4.08 -0.11 2.23 3.83 7.25 Lagging mobility measures \u00b6 There is expected to be some delay between infection transmission and reporting. The Midas network has compiled various published estimates of the duration of stages of corona virus infections. The incubation period (time between a person becomes infected and becomes symptomatic) is generally believed to be around 5 days. There are fewer estimates of the time between symptom onset and reporting. The few available estimates are from Italy and China. Points estimates range from 5-7 days, but confidence intervals span 1-20 days. Infections that are reported on day $t$ likely occurred between day $t-5$ and $t-20$. There are two important implications. The first is simply a matter of interpretation. Our $R_t$ estimates are the effective reproductive number of cases reported on day $t$, which is the effective reproductive number of infections that began 5-20 days ago. The second implication is that $R_t$ should be related to mobility measurements and policy conditions on days $t-5$ to $t-20$. One option would be to include many different lags of these variables in the model. However, this will greatly reduce statistical power and increase computation time. Instead, we will construct lagged, weighted rolling averages for use in the model. Specifically, we will use \\tilde{m}_t = \\sum_{\\ell=(L_1+L_2)/2+5}^{20} m_{t-\\ell} P(\\ell \\text{ days between infection and reporting}) with the assumption that the number of days between infection and reporting is $N(7,3)$ truncated to $[0,20]$. d = truncated(Normal(7, 3), 5, 20) \u2113 = collect(5:20) p = pdf.(d, \u2113) p ./= sum(p) plot(\u2113, d, title=\"Weights for covariates\", xlab=\"lag\", ylab=\"weight\") mlvars = [Symbol(string(v)*\"_lagged\") for v in mvars] xvars = vcat(x0vars, mlvars); reestimate=true rlo=1 - eps(Float64) rhi=1+ eps(Float64) K = length(xvars) priors = (\u03b3 = truncated(Normal(1/7,1/7), 1/28, 1/1), \u03c3R0 = truncated(Normal(1, 3), 0, Inf), \u03b10 = MvNormal(zeros(length(x0vars)), sqrt(10)), #truncated(Normal(1, 3), 0, Inf), \u03c3R = truncated(Normal(0.25,1),0,Inf), \u03c3k = truncated(Normal(0.1, 5), 0, Inf), \u03c1 = Uniform(rlo, rhi), \u03b1 = MvNormal(zeros(K), sqrt(10)) ) states_to_plot = [\"New York\", \"New Jersey\",\"Massachusetts\",\"California\", \"Georgia\",\"Illinois\",\"Michigan\", \"Ohio\",\"Wisconsin\",\"Washington\"] warmup = default_warmup_stages(local_optimization=FindLocalOptimum(1e-4, 100), stepsize_search=nothing, init_steps=100, middle_steps=100, terminating_steps=2*100, doubling_stages=4, M=Symmetric) for L1 in [7] for L2 in [7] w = vcat(reverse(p), zeros(minimum(\u2113)-1 + 2*((L1+L2)\u00f72) + 1 + maximum(\u2113))) sort!(sdf, (:state, :date)) for v in mvars newv = Symbol(string(v)*\"_lagged\") sdf[!,newv] = copy(sdf[!,v]) for gdf in groupby(sdf, :state) gdf[:, newv] .= CovidRt.smooth(gdf[:,v], w=w) end end mdl = CovidRt.RtModel(sdf, Symbol(\"cases.nyt\"), xvars, x0vars, priors; L1=L1, L2=L2, time0=r->(r[Symbol(\"cases.nyt\")].>=5)) estfile = \"rt_mlag_$(L1)_$(L2).jld2\" if !isfile(estfile) || reestimate post = CovidRt.mcmc(mdl; iterations=2000, warmup=warmup) @save estfile post end @load estfile post cc = CovidRt.MCMCChain(post, xvars, x0vars) println(\"## L\u2081 = $(L1), L\u2082 = $(L2)\") println() #display(plot(cc)) println(latexify(DataFrame(describe(cc)[1]), env=:mdtable, latex=false, fmt=x->round(x, sigdigits=3))) println(latexify(DataFrame(describe(cc)[2]), env=:mdtable, latex=false, fmt=x->round(x, sigdigits=3))) states = mdl.id S = length(states_to_plot) figs = fill(plot(), S) for (i,st) in enumerate(states_to_plot) s = findfirst(states.==st) figr = CovidRt.plotpostr(mdl.t[s],mdl.dlogk[s],post, mdl.X[s], mdl.X0[s]) l = @layout [a{.1h}; grid(1,1)] figs[i] = plot(plot(annotation=(0.5,0.5, st*\", L\u2081=$(L1) L\u2082=$(L2)\"), framestyle = :none), plot(figr, ylim=(-1,15)), layout=l) display(figs[i]) end end end L\u2081 = 7, L\u2082 = 7 \u00b6 parameters mean std naive_se mcse ess r_hat \u03b3 0.041 0.00509 0.000114 0.000362 212.0 1.0 \u03c3R0 2.41 0.365 0.00817 0.0292 201.0 1.0 \u03b10(constant) 1.18 2.77 0.062 0.146 255.0 1.01 \u03b10(logpopdens) -0.0986 2.16 0.0484 0.154 239.0 1.0 \u03b10(Percent Unemployed 2018 ) 0.297 2.17 0.0486 0.177 138.0 1.02 \u03b10(Percent living under the federal poverty line 2018 ) 0.107 2.09 0.0467 0.154 160.0 1.01 \u03b10(Percent at risk for serious illness due to COVID) -0.0743 2.11 0.0472 0.129 289.0 1.0 \u03c3R 0.725 0.0787 0.00176 0.00616 193.0 1.0 \u03c3k 0.00101 0.00079 1.77e-5 4.62e-5 276.0 1.0 \u03c1 1.0 1.45e-16 4.2e-18 0.0 284.0 0.999 \u03b1(constant) 0.877 2.75 0.0614 0.209 207.0 1.01 \u03b1(logpopdens) 0.302 2.16 0.0484 0.154 244.0 1.0 \u03b1(Percent Unemployed 2018 ) 0.0861 2.21 0.0493 0.195 128.0 1.02 \u03b1(Percent living under the federal poverty line 2018 ) -0.314 2.1 0.0469 0.156 157.0 1.01 \u03b1(Percent at risk for serious illness due to COVID) 0.228 2.11 0.0471 0.13 286.0 1.0 \u03b1(retail and recreation percent change from baseline lagged) 2.48 1.85 0.0414 0.15 152.0 1.0 \u03b1(grocery and pharmacy percent change from baseline lagged) -2.53 1.07 0.024 0.0841 221.0 1.0 \u03b1(parks percent change from baseline lagged) 0.0191 0.373 0.00833 0.0272 167.0 1.0 \u03b1(transit stations percent change from baseline lagged) 2.78 1.75 0.0392 0.137 222.0 1.0 \u03b1(workplaces percent change from baseline lagged) 2.58 1.68 0.0375 0.122 167.0 1.0 \u03b1(residential percent change from baseline lagged) -1.82 2.55 0.057 0.17 226.0 0.999 \u03b1(percentchangehours lagged) 1.15 1.79 0.0401 0.146 150.0 1.01 \u03b1(percentchangebusinesses lagged) 2.0 1.87 0.0418 0.0993 272.0 1.0 \u03b1(daily distance diff lagged) -0.214 3.19 0.0712 0.25 200.0 1.0 \u03b1(daily visitation diff lagged) -0.00998 3.09 0.069 0.214 173.0 1.0 \u03b1(log encounters rate lagged) 1.2 3.23 0.0723 0.244 194.0 1.01 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0358 0.0373 0.0394 0.0432 0.055 \u03c3R0 1.69 2.16 2.39 2.65 3.12 \u03b10(constant) -4.46 -0.608 1.14 2.87 6.7 \u03b10(logpopdens) -4.31 -1.52 -0.0922 1.4 4.04 \u03b10(Percent Unemployed 2018 ) -3.97 -1.2 0.265 1.87 4.35 \u03b10(Percent living under the federal poverty line 2018 ) -3.85 -1.36 0.182 1.68 3.76 \u03b10(Percent at risk for serious illness due to COVID) -4.23 -1.39 -0.00477 1.4 3.94 \u03c3R 0.532 0.679 0.744 0.785 0.828 \u03c3k 1.59e-5 0.00036 0.000851 0.00151 0.00279 \u03c1 1.0 1.0 1.0 1.0 1.0 \u03b1(constant) -4.43 -1.15 0.899 2.81 6.55 \u03b1(logpopdens) -3.72 -1.1 0.287 1.73 4.54 \u03b1(Percent Unemployed 2018 ) -3.93 -1.52 0.0288 1.61 4.36 \u03b1(Percent living under the federal poverty line 2018 ) -3.98 -1.87 -0.406 1.15 3.62 \u03b1(Percent at risk for serious illness due to COVID) -3.77 -1.23 0.165 1.53 4.31 \u03b1(retail and recreation percent change from baseline lagged) -1.35 1.24 2.54 3.85 5.75 \u03b1(grocery and pharmacy percent change from baseline lagged) -4.66 -3.24 -2.5 -1.83 -0.33 \u03b1(parks percent change from baseline lagged) -0.697 -0.216 0.0056 0.253 0.795 \u03b1(transit stations percent change from baseline lagged) -0.446 1.47 2.77 3.95 6.22 \u03b1(workplaces percent change from baseline lagged) -0.958 1.46 2.57 3.77 5.65 \u03b1(residential percent change from baseline lagged) -6.4 -3.65 -1.82 -0.154 3.35 \u03b1(percentchangehours lagged) -2.19 -0.0371 1.08 2.37 4.96 \u03b1(percentchangebusinesses lagged) -1.7 0.82 2.02 3.18 5.61 \u03b1(daily distance diff lagged) -6.63 -2.27 -0.193 2.02 5.95 \u03b1(daily visitation diff lagged) -5.88 -2.3 0.155 2.16 5.57 \u03b1(log encounters rate lagged) -5.77 -0.971 1.36 3.59 7.05","title":"Without policies"},{"location":"rt_onlym/#results","text":"## data prep using CovidData using CovidRt using TransformVariables, Parameters, Plots, StatsPlots, DataFrames, Dates, LinearAlgebra, Distributions, Random, LogDensityProblems, DynamicHMC, MCMCChains, JLD2, Latexify Plots.pyplot() df = CovidData.statedata(policies=:indicators, fillmissingmobility=true) df[!,:log_encounters_rate] = log.(1 .+ df[!,:encounters_rate]) pvars = [Symbol(\"Stay.at.home..shelter.in.place\"), #Symbol(\"State.of.emergency\"), Symbol(\"Date.closed.K.12.schools\"), Symbol(\"Closed.gyms\"), Symbol(\"Closed.movie.theaters\"), Symbol(\"Closed.day.cares\"), Symbol(\"Date.banned.visitors.to.nursing.homes\"), Symbol(\"Closed.non.essential.businesses\"), Symbol(\"Closed.restaurants.except.take.out\")] mvars = [:retail_and_recreation_percent_change_from_baseline, :grocery_and_pharmacy_percent_change_from_baseline, :parks_percent_change_from_baseline , :transit_stations_percent_change_from_baseline, :workplaces_percent_change_from_baseline, :residential_percent_change_from_baseline, :percentchangehours, :percentchangebusinesses, :daily_distance_diff, :daily_visitation_diff, :log_encounters_rate] df[!,:logpopdens] = log.(df[!,Symbol(\"Population.density.per.square.miles\")]) df[!,:weekend] = dayofweek.(df[!,:date]) .>= 6 x0vars=[:constant, :logpopdens, Symbol(\"Percent.Unemployed..2018.\"), Symbol(\"Percent.living.under.the.federal.poverty.line..2018.\"), Symbol(\"Percent.at.risk.for.serious.illness.due.to.COVID\")] sdf = filter(x->x.fips<60, df) sdf = sort(sdf, (:state, :date)) sdf[!,mvars] ./= 100 sdf[!,:constant] .= 1 xvars = vcat(x0vars, mvars); Here, we will allow the initial and time varying mean of $R_{s,t}$ to depend on covariates. \\begin{align*} \\tilde{R}_{s,0} & \\sim N(X_{0,s} \\alpha_0, \\sigma^2_{R,0}) \\\\ \\tilde{R}_{s,t} & = \\rho \\tilde{R}_{s,t} + u_{s,t} \\;,\\; u_{s,t} \\sim N(0, \\sigma^2_R) \\\\ R_{s,t} & = X_{s,t} \\alpha + \\tilde{R}_{s,t} \\\\ \\Delta \\log(k)_{s,t} & = \\gamma (R_{s,t} - 1) + \\epsilon_{s,t} - \\epsilon_{s,t-1} \\;, \\; \\epsilon_{s,t} \\sim N(0, \\sigma^2_k) \\end{align*} We present estimates of $R_t$ with \\Delta C(t) = C(t) - C(t-L_1) and \\Delta log (\\Delta C(t)) = log (\\Delta C(t)) - log (\\Delta C(t - L_2)) for a variety of values of $L_1$ and $L_2$ reestimate=true rlo=1 - eps(Float64) rhi=1+ eps(Float64) K = length(xvars) priors = (\u03b3 = truncated(Normal(1/7,1/7), 1/28, 1/1), \u03c3R0 = truncated(Normal(1, 3), 0, Inf), \u03b10 = MvNormal(zeros(length(x0vars)), sqrt(10)), #truncated(Normal(1, 3), 0, Inf), \u03c3R = truncated(Normal(0.25,1),0,Inf), \u03c3k = truncated(Normal(0.1, 5), 0, Inf), \u03c1 = Uniform(rlo, rhi), \u03b1 = MvNormal(zeros(K), sqrt(10)) ) states_to_plot = [\"New York\", \"New Jersey\",\"Massachusetts\",\"California\", \"Georgia\",\"Illinois\",\"Michigan\", \"Ohio\",\"Wisconsin\",\"Washington\"] warmup = default_warmup_stages(local_optimization=FindLocalOptimum(1e-4, 100), stepsize_search=nothing, init_steps=100, middle_steps=100, terminating_steps=2*100, doubling_stages=4, M=Symmetric) for L1 in [7] for L2 in [7] mdl = CovidRt.RtModel(sdf, Symbol(\"cases.nyt\"), xvars, x0vars, priors; L1=L1, L2=L2, time0=r->(r[Symbol(\"cases.nyt\")].>=5)) estfile = \"rt_onlym_$(L1)_$(L2).jld2\" if !isfile(estfile) || reestimate post = CovidRt.mcmc(mdl; iterations=2000, warmup=warmup) @save estfile post end @load estfile post cc = CovidRt.MCMCChain(post, xvars, x0vars) println(\"## L\u2081 = $(L1), L\u2082 = $(L2)\") println() #display(plot(cc)) println(latexify(DataFrame(describe(cc)[1]), env=:mdtable, latex=false, fmt=x->round(x, sigdigits=3))) println(latexify(DataFrame(describe(cc)[2]), env=:mdtable, latex=false, fmt=x->round(x, sigdigits=3))) states = mdl.id S = length(states_to_plot) figs = fill(plot(), S) for (i,st) in enumerate(states_to_plot) s = findfirst(states.==st) figr = CovidRt.plotpostr(mdl.t[s],mdl.dlogk[s],post, mdl.X[s], mdl.X0[s]) l = @layout [a{.1h}; grid(1,1)] figs[i] = plot(plot(annotation=(0.5,0.5, st*\", L\u2081=$(L1) L\u2082=$(L2)\"), framestyle = :none), plot(figr, ylim=(-1,15)), layout=l) display(figs[i]) end end end","title":"Results"},{"location":"rt_onlym/#l1-7-l2-7","text":"parameters mean std naive_se mcse ess r_hat \u03b3 0.039 0.00338 7.57e-5 0.000292 171.0 1.0 \u03c3R0 2.61 0.348 0.00778 0.0343 67.1 1.0 \u03b10(constant) 1.05 2.58 0.0576 0.345 55.1 1.0 \u03b10(logpopdens) -0.217 2.28 0.051 0.345 22.1 1.06 \u03b10(Percent Unemployed 2018 ) 0.187 2.28 0.051 0.238 83.1 1.0 \u03b10(Percent living under the federal poverty line 2018 ) -0.108 1.87 0.0417 0.243 71.5 1.0 \u03b10(Percent at risk for serious illness due to COVID) -0.139 2.27 0.0507 0.23 86.1 1.0 \u03c3R 0.786 0.0587 0.00131 0.00542 156.0 1.0 \u03c3k 0.000758 0.000633 1.42e-5 6.67e-5 80.3 1.03 \u03c1 1.0 1.48e-16 3.93e-18 5.7e-18 56.8 0.999 \u03b1(constant) 1.11 2.27 0.0508 0.218 77.9 1.05 \u03b1(logpopdens) 0.62 2.31 0.0516 0.358 18.9 1.07 \u03b1(Percent Unemployed 2018 ) 0.112 2.25 0.0502 0.235 81.3 1.0 \u03b1(Percent living under the federal poverty line 2018 ) -0.0819 1.86 0.0417 0.245 69.1 1.0 \u03b1(Percent at risk for serious illness due to COVID) 0.291 2.27 0.0508 0.232 84.2 1.0 \u03b1(retail and recreation percent change from baseline) 0.443 0.611 0.0137 0.0632 95.2 1.0 \u03b1(grocery and pharmacy percent change from baseline) -0.848 0.402 0.009 0.0419 107.0 1.0 \u03b1(parks percent change from baseline) 0.00586 0.0716 0.0016 0.00674 98.0 1.0 \u03b1(transit stations percent change from baseline) 0.145 0.531 0.0119 0.0589 77.4 1.0 \u03b1(workplaces percent change from baseline) -0.0129 0.655 0.0146 0.0841 72.5 1.0 \u03b1(residential percent change from baseline) -0.609 1.07 0.0239 0.133 75.6 1.0 \u03b1(percentchangehours) -0.367 0.523 0.0117 0.062 85.0 1.02 \u03b1(percentchangebusinesses) 1.34 0.683 0.0153 0.0906 54.5 1.0 \u03b1(daily distance diff) -0.466 3.04 0.0679 0.444 28.2 1.02 \u03b1(daily visitation diff) 0.0958 3.39 0.0758 0.433 69.4 1.0 \u03b1(log encounters rate) 1.81 2.95 0.066 0.335 65.8 1.03 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0358 0.0367 0.0379 0.04 0.0475 \u03c3R0 1.95 2.39 2.61 2.82 3.34 \u03b10(constant) -3.53 -0.481 0.778 2.58 6.72 \u03b10(logpopdens) -4.36 -1.82 -0.412 1.29 4.65 \u03b10(Percent Unemployed 2018 ) -4.38 -1.36 0.0871 1.76 4.55 \u03b10(Percent living under the federal poverty line 2018 ) -4.2 -1.22 -0.0256 1.28 3.11 \u03b10(Percent at risk for serious illness due to COVID) -4.33 -1.81 -0.0158 1.4 4.23 \u03c3R 0.634 0.759 0.801 0.827 0.856 \u03c3k 8.08e-6 0.00022 0.000623 0.00115 0.00221 \u03c1 1.0 1.0 1.0 1.0 1.0 \u03b1(constant) -3.74 -0.145 1.2 2.47 5.49 \u03b1(logpopdens) -4.14 -0.981 0.762 2.28 4.83 \u03b1(Percent Unemployed 2018 ) -4.27 -1.44 0.186 1.66 4.4 \u03b1(Percent living under the federal poverty line 2018 ) -3.23 -1.45 -0.187 1.02 3.99 \u03b1(Percent at risk for serious illness due to COVID) -4.12 -1.25 0.183 1.98 4.5 \u03b1(retail and recreation percent change from baseline) -0.815 0.0455 0.435 0.82 1.64 \u03b1(grocery and pharmacy percent change from baseline) -1.7 -1.1 -0.862 -0.561 -0.0653 \u03b1(parks percent change from baseline) -0.133 -0.0434 0.00755 0.0511 0.152 \u03b1(transit stations percent change from baseline) -0.949 -0.189 0.155 0.514 1.14 \u03b1(workplaces percent change from baseline) -1.29 -0.467 -0.0332 0.435 1.33 \u03b1(residential percent change from baseline) -2.72 -1.27 -0.644 0.0627 1.54 \u03b1(percentchangehours) -1.39 -0.748 -0.352 -0.000109 0.676 \u03b1(percentchangebusinesses) -0.159 0.907 1.37 1.81 2.62 \u03b1(daily distance diff) -6.4 -2.28 -0.764 1.56 5.87 \u03b1(daily visitation diff) -5.58 -2.43 0.156 2.39 7.95 \u03b1(log encounters rate) -4.08 -0.11 2.23 3.83 7.25","title":"L\u2081 = 7, L\u2082 = 7"},{"location":"rt_onlym/#lagging-mobility-measures","text":"There is expected to be some delay between infection transmission and reporting. The Midas network has compiled various published estimates of the duration of stages of corona virus infections. The incubation period (time between a person becomes infected and becomes symptomatic) is generally believed to be around 5 days. There are fewer estimates of the time between symptom onset and reporting. The few available estimates are from Italy and China. Points estimates range from 5-7 days, but confidence intervals span 1-20 days. Infections that are reported on day $t$ likely occurred between day $t-5$ and $t-20$. There are two important implications. The first is simply a matter of interpretation. Our $R_t$ estimates are the effective reproductive number of cases reported on day $t$, which is the effective reproductive number of infections that began 5-20 days ago. The second implication is that $R_t$ should be related to mobility measurements and policy conditions on days $t-5$ to $t-20$. One option would be to include many different lags of these variables in the model. However, this will greatly reduce statistical power and increase computation time. Instead, we will construct lagged, weighted rolling averages for use in the model. Specifically, we will use \\tilde{m}_t = \\sum_{\\ell=(L_1+L_2)/2+5}^{20} m_{t-\\ell} P(\\ell \\text{ days between infection and reporting}) with the assumption that the number of days between infection and reporting is $N(7,3)$ truncated to $[0,20]$. d = truncated(Normal(7, 3), 5, 20) \u2113 = collect(5:20) p = pdf.(d, \u2113) p ./= sum(p) plot(\u2113, d, title=\"Weights for covariates\", xlab=\"lag\", ylab=\"weight\") mlvars = [Symbol(string(v)*\"_lagged\") for v in mvars] xvars = vcat(x0vars, mlvars); reestimate=true rlo=1 - eps(Float64) rhi=1+ eps(Float64) K = length(xvars) priors = (\u03b3 = truncated(Normal(1/7,1/7), 1/28, 1/1), \u03c3R0 = truncated(Normal(1, 3), 0, Inf), \u03b10 = MvNormal(zeros(length(x0vars)), sqrt(10)), #truncated(Normal(1, 3), 0, Inf), \u03c3R = truncated(Normal(0.25,1),0,Inf), \u03c3k = truncated(Normal(0.1, 5), 0, Inf), \u03c1 = Uniform(rlo, rhi), \u03b1 = MvNormal(zeros(K), sqrt(10)) ) states_to_plot = [\"New York\", \"New Jersey\",\"Massachusetts\",\"California\", \"Georgia\",\"Illinois\",\"Michigan\", \"Ohio\",\"Wisconsin\",\"Washington\"] warmup = default_warmup_stages(local_optimization=FindLocalOptimum(1e-4, 100), stepsize_search=nothing, init_steps=100, middle_steps=100, terminating_steps=2*100, doubling_stages=4, M=Symmetric) for L1 in [7] for L2 in [7] w = vcat(reverse(p), zeros(minimum(\u2113)-1 + 2*((L1+L2)\u00f72) + 1 + maximum(\u2113))) sort!(sdf, (:state, :date)) for v in mvars newv = Symbol(string(v)*\"_lagged\") sdf[!,newv] = copy(sdf[!,v]) for gdf in groupby(sdf, :state) gdf[:, newv] .= CovidRt.smooth(gdf[:,v], w=w) end end mdl = CovidRt.RtModel(sdf, Symbol(\"cases.nyt\"), xvars, x0vars, priors; L1=L1, L2=L2, time0=r->(r[Symbol(\"cases.nyt\")].>=5)) estfile = \"rt_mlag_$(L1)_$(L2).jld2\" if !isfile(estfile) || reestimate post = CovidRt.mcmc(mdl; iterations=2000, warmup=warmup) @save estfile post end @load estfile post cc = CovidRt.MCMCChain(post, xvars, x0vars) println(\"## L\u2081 = $(L1), L\u2082 = $(L2)\") println() #display(plot(cc)) println(latexify(DataFrame(describe(cc)[1]), env=:mdtable, latex=false, fmt=x->round(x, sigdigits=3))) println(latexify(DataFrame(describe(cc)[2]), env=:mdtable, latex=false, fmt=x->round(x, sigdigits=3))) states = mdl.id S = length(states_to_plot) figs = fill(plot(), S) for (i,st) in enumerate(states_to_plot) s = findfirst(states.==st) figr = CovidRt.plotpostr(mdl.t[s],mdl.dlogk[s],post, mdl.X[s], mdl.X0[s]) l = @layout [a{.1h}; grid(1,1)] figs[i] = plot(plot(annotation=(0.5,0.5, st*\", L\u2081=$(L1) L\u2082=$(L2)\"), framestyle = :none), plot(figr, ylim=(-1,15)), layout=l) display(figs[i]) end end end","title":"Lagging mobility measures"},{"location":"rt_onlym/#l1-7-l2-7_1","text":"parameters mean std naive_se mcse ess r_hat \u03b3 0.041 0.00509 0.000114 0.000362 212.0 1.0 \u03c3R0 2.41 0.365 0.00817 0.0292 201.0 1.0 \u03b10(constant) 1.18 2.77 0.062 0.146 255.0 1.01 \u03b10(logpopdens) -0.0986 2.16 0.0484 0.154 239.0 1.0 \u03b10(Percent Unemployed 2018 ) 0.297 2.17 0.0486 0.177 138.0 1.02 \u03b10(Percent living under the federal poverty line 2018 ) 0.107 2.09 0.0467 0.154 160.0 1.01 \u03b10(Percent at risk for serious illness due to COVID) -0.0743 2.11 0.0472 0.129 289.0 1.0 \u03c3R 0.725 0.0787 0.00176 0.00616 193.0 1.0 \u03c3k 0.00101 0.00079 1.77e-5 4.62e-5 276.0 1.0 \u03c1 1.0 1.45e-16 4.2e-18 0.0 284.0 0.999 \u03b1(constant) 0.877 2.75 0.0614 0.209 207.0 1.01 \u03b1(logpopdens) 0.302 2.16 0.0484 0.154 244.0 1.0 \u03b1(Percent Unemployed 2018 ) 0.0861 2.21 0.0493 0.195 128.0 1.02 \u03b1(Percent living under the federal poverty line 2018 ) -0.314 2.1 0.0469 0.156 157.0 1.01 \u03b1(Percent at risk for serious illness due to COVID) 0.228 2.11 0.0471 0.13 286.0 1.0 \u03b1(retail and recreation percent change from baseline lagged) 2.48 1.85 0.0414 0.15 152.0 1.0 \u03b1(grocery and pharmacy percent change from baseline lagged) -2.53 1.07 0.024 0.0841 221.0 1.0 \u03b1(parks percent change from baseline lagged) 0.0191 0.373 0.00833 0.0272 167.0 1.0 \u03b1(transit stations percent change from baseline lagged) 2.78 1.75 0.0392 0.137 222.0 1.0 \u03b1(workplaces percent change from baseline lagged) 2.58 1.68 0.0375 0.122 167.0 1.0 \u03b1(residential percent change from baseline lagged) -1.82 2.55 0.057 0.17 226.0 0.999 \u03b1(percentchangehours lagged) 1.15 1.79 0.0401 0.146 150.0 1.01 \u03b1(percentchangebusinesses lagged) 2.0 1.87 0.0418 0.0993 272.0 1.0 \u03b1(daily distance diff lagged) -0.214 3.19 0.0712 0.25 200.0 1.0 \u03b1(daily visitation diff lagged) -0.00998 3.09 0.069 0.214 173.0 1.0 \u03b1(log encounters rate lagged) 1.2 3.23 0.0723 0.244 194.0 1.01 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0358 0.0373 0.0394 0.0432 0.055 \u03c3R0 1.69 2.16 2.39 2.65 3.12 \u03b10(constant) -4.46 -0.608 1.14 2.87 6.7 \u03b10(logpopdens) -4.31 -1.52 -0.0922 1.4 4.04 \u03b10(Percent Unemployed 2018 ) -3.97 -1.2 0.265 1.87 4.35 \u03b10(Percent living under the federal poverty line 2018 ) -3.85 -1.36 0.182 1.68 3.76 \u03b10(Percent at risk for serious illness due to COVID) -4.23 -1.39 -0.00477 1.4 3.94 \u03c3R 0.532 0.679 0.744 0.785 0.828 \u03c3k 1.59e-5 0.00036 0.000851 0.00151 0.00279 \u03c1 1.0 1.0 1.0 1.0 1.0 \u03b1(constant) -4.43 -1.15 0.899 2.81 6.55 \u03b1(logpopdens) -3.72 -1.1 0.287 1.73 4.54 \u03b1(Percent Unemployed 2018 ) -3.93 -1.52 0.0288 1.61 4.36 \u03b1(Percent living under the federal poverty line 2018 ) -3.98 -1.87 -0.406 1.15 3.62 \u03b1(Percent at risk for serious illness due to COVID) -3.77 -1.23 0.165 1.53 4.31 \u03b1(retail and recreation percent change from baseline lagged) -1.35 1.24 2.54 3.85 5.75 \u03b1(grocery and pharmacy percent change from baseline lagged) -4.66 -3.24 -2.5 -1.83 -0.33 \u03b1(parks percent change from baseline lagged) -0.697 -0.216 0.0056 0.253 0.795 \u03b1(transit stations percent change from baseline lagged) -0.446 1.47 2.77 3.95 6.22 \u03b1(workplaces percent change from baseline lagged) -0.958 1.46 2.57 3.77 5.65 \u03b1(residential percent change from baseline lagged) -6.4 -3.65 -1.82 -0.154 3.35 \u03b1(percentchangehours lagged) -2.19 -0.0371 1.08 2.37 4.96 \u03b1(percentchangebusinesses lagged) -1.7 0.82 2.02 3.18 5.61 \u03b1(daily distance diff lagged) -6.63 -2.27 -0.193 2.02 5.95 \u03b1(daily visitation diff lagged) -5.88 -2.3 0.155 2.16 5.57 \u03b1(log encounters rate lagged) -5.77 -0.971 1.36 3.59 7.05","title":"L\u2081 = 7, L\u2082 = 7"},{"location":"rt_onlyp/","text":"Results \u00b6 ## data prep using CovidData Error: importing CovidData into Main conflicts with an existing identifier using CovidRt Error: importing CovidRt into Main conflicts with an existing identifier using TransformVariables, Parameters, Plots, StatsPlots, DataFrames, Dates, LinearAlgebra, Distributions, Random, LogDensityProblems, DynamicHMC, MCMCChains, JLD2, Latexify Plots.pyplot() df = CovidData.statedata(policies=:indicators, fillmissingmobility=true) df[!,:log_encounters_rate] = log.(1 .+ df[!,:encounters_rate]) pvars = [Symbol(\"Stay.at.home..shelter.in.place\"), Symbol(\"State.of.emergency\"), Symbol(\"Date.closed.K.12.schools\"), Symbol(\"Closed.gyms\"), Symbol(\"Closed.movie.theaters\"), Symbol(\"Closed.day.cares\"), Symbol(\"Date.banned.visitors.to.nursing.homes\"), Symbol(\"Closed.non.essential.businesses\"), Symbol(\"Closed.restaurants.except.take.out\")] mvars = [:retail_and_recreation_percent_change_from_baseline, :grocery_and_pharmacy_percent_change_from_baseline, :parks_percent_change_from_baseline , :transit_stations_percent_change_from_baseline, :workplaces_percent_change_from_baseline, :residential_percent_change_from_baseline, :percentchangehours, :percentchangebusinesses, :daily_distance_diff, :daily_visitation_diff, :log_encounters_rate] df[!,:logpopdens] = log.(df[!,Symbol(\"Population.density.per.square.miles\")]) df[!,:weekend] = dayofweek.(df[!,:date]) .>= 6 x0vars=[:constant, :logpopdens, Symbol(\"Percent.Unemployed..2018.\"), Symbol(\"Percent.living.under.the.federal.poverty.line..2018.\"), Symbol(\"Percent.at.risk.for.serious.illness.due.to.COVID\")] sdf = filter(x->x.fips<60, df) sdf = sort(sdf, (:state, :date)) sdf[!,mvars] ./= 100 sdf[!,:constant] .= 1 2845-element Array{Int64,1}: 1 1 1 1 1 1 1 1 1 1 \u22ee 1 1 1 1 1 1 1 1 1 Here, we will allow the initial and time varying mean of $R_{s,t}$ to depend on covariates. We will include only the policy related covariates and the non time-varying ones. \\begin{align*} \\tilde{R}_{s,0} & \\sim N(X_{0,s} \\alpha_0, \\sigma^2_{R,0}) \\\\ \\tilde{R}_{s,t} & = \\rho \\tilde{R}_{s,t} + u_{s,t} \\;,\\; u_{s,t} \\sim N(0, \\sigma^2_R) \\\\ R_{s,t} & = X_{s,t} \\alpha + \\tilde{R}_{s,t} \\\\ \\Delta \\log(k)_{s,t} & = \\gamma (R_{s,t} - 1) + \\epsilon_{s,t} - \\epsilon_{s,t-1} \\;, \\; \\epsilon_{s,t} \\sim N(0, \\sigma^2_k) \\end{align*} In computing $\\Delta \\log \\Delta C$, we take backward differences of length 7, so (\\Delta \\log \\Delta C)[t] = \\log (C_t - C_{t-7}) - \\log(C_{t-7} - C_{t-14}) This means that our time $t$ outcome is reflects the average reproductive number from time $t-7$ to $t$. For $X_{s,t}$ we use the moving average of the policy indicator variables from time $t-7-L$ to $t-14-L$, and we try a few different values of $L$. reestimate=true xvarsets = [ vcat(x0vars, Symbol(\"Stay.at.home..shelter.in.place_lagged\"), Symbol(\"Date.closed.K.12.schools_lagged\"), Symbol(\"Closed.movie.theaters_lagged\"), Symbol(\"Closed.non.essential.businesses_lagged\"), Symbol(\"Closed.restaurants.except.take.out_lagged\")) , vcat(x0vars, Symbol(\"Stay.at.home..shelter.in.place_lagged\")) ] rlo=-1 rhi=1.1 states_to_plot = [\"New York\", \"New Jersey\",\"Massachusetts\",\"California\", \"Georgia\",\"Illinois\",\"Michigan\", \"Ohio\",\"Wisconsin\",\"Washington\"] warmup = default_warmup_stages(local_optimization=FindLocalOptimum(1e-4, 100), stepsize_search=nothing, init_steps=100, middle_steps=100, terminating_steps=2*100, doubling_stages=4, M=Symmetric) for L in [0, 7] for xvars in xvarsets K = length(xvars) priors = (\u03b3 = truncated(Normal(1/7,1/7), 1/28, 1/1), \u03c3R0 = truncated(Normal(1, 3), 0, Inf), \u03b10 = MvNormal(zeros(length(x0vars)), sqrt(10)), #truncated(Normal(1, 3), 0, Inf), \u03c3R = truncated(Normal(0.25,1),0,Inf), \u03c3k = truncated(Normal(0.1, 5), 0, Inf), \u03c1 = Uniform(rlo, rhi), \u03b1 = MvNormal(zeros(K), sqrt(10)) ) estfile = \"rt_onlyp_$(L)_x$(K).jld2\" w = vcat(ones(7), zeros(1+2*L+7)) sort!(sdf, (:state, :date)) for v in pvars newv = Symbol(string(v)*\"_lagged\") sdf[!,newv] = Float64.(sdf[!,v]) for gdf in groupby(sdf, :state) gdf[:, newv] .= CovidRt.smooth(gdf[:,v], w=w) end end mdl = CovidRt.RtModel(sdf, Symbol(\"cases.nyt\"), xvars, x0vars, priors; L1=7, L2=7, time0=r->(r[Symbol(\"cases.nyt\")].>=5)) if !isfile(estfile) || reestimate post = CovidRt.mcmc(mdl; iterations=2000, warmup=warmup) @save estfile post end @load estfile post cc = CovidRt.MCMCChain(post, xvars, x0vars) println(\"## Policies lagged by = $(L)\") println() display(plot(cc)) println(latexify(DataFrame(describe(cc)[1]), env=:mdtable, latex=false, fmt=x->round(x, sigdigits=3))) println(latexify(DataFrame(describe(cc)[2]), env=:mdtable, latex=false, fmt=x->round(x, sigdigits=3))) states = mdl.id S = length(states_to_plot) figs = fill(plot(), S) for (i,st) in enumerate(states_to_plot) s = findfirst(states.==st) figr = CovidRt.plotpostr(mdl.t[s],mdl.dlogk[s],post, mdl.X[s], mdl.X0[s]) l = @layout [a{.1h}; grid(1,1)] figs[i] = plot(plot(annotation=(0.5,0.5, st*\", L=$(L) nx=$(K)\"), framestyle = :none), plot(figr, ylim=(-1,15)), layout=l) display(figs[i]) end end end Policies lagged by = 0 \u00b6 parameters mean std naive_se mcse ess r_hat \u03b3 0.0387 0.00296 6.62e-5 0.000227 210.0 1.0 \u03c3R0 2.56 0.304 0.00681 0.0237 163.0 1.0 \u03b10(constant) 0.397 2.75 0.0616 0.214 122.0 1.0 \u03b10(logpopdens) -0.0609 0.342 0.00764 0.0317 103.0 1.02 \u03b10(Percent Unemployed 2018 ) 0.357 0.551 0.0123 0.0552 64.9 1.0 \u03b10(Percent living under the federal poverty line 2018 ) -0.284 0.25 0.0056 0.0218 128.0 1.0 \u03b10(Percent at risk for serious illness due to COVID) 0.236 0.102 0.00229 0.00775 123.0 1.0 \u03c3R 0.744 0.0517 0.00116 0.00389 211.0 1.0 \u03c3k 0.000889 0.000694 1.55e-5 6.91e-5 93.4 1.0 \u03c1 0.937 0.00636 0.000142 0.000469 169.0 1.0 \u03b1(constant) 3.26 1.84 0.0412 0.166 112.0 1.01 \u03b1(logpopdens) 0.456 0.192 0.0043 0.021 86.2 1.01 \u03b1(Percent Unemployed 2018 ) -0.0754 0.334 0.00747 0.0363 69.6 1.05 \u03b1(Percent living under the federal poverty line 2018 ) 0.0195 0.147 0.00328 0.0141 97.7 1.03 \u03b1(Percent at risk for serious illness due to COVID) -0.0981 0.068 0.00152 0.00537 112.0 1.01 \u03b1(Stay at home shelter in place lagged) -0.977 0.345 0.00771 0.0292 150.0 1.0 \u03b1(Date closed K 12 schools lagged) 0.733 0.418 0.00934 0.0366 107.0 1.0 \u03b1(Closed movie theaters lagged) -0.0981 0.49 0.0109 0.0504 99.6 1.03 \u03b1(Closed non essential businesses lagged) -0.764 0.412 0.00921 0.0451 110.0 1.0 \u03b1(Closed restaurants except take out lagged) -0.101 0.513 0.0115 0.0565 93.4 1.02 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0358 0.0366 0.0378 0.0398 0.0467 \u03c3R0 1.98 2.35 2.56 2.75 3.23 \u03b10(constant) -5.25 -1.65 0.441 2.38 5.66 \u03b10(logpopdens) -0.766 -0.296 -0.0638 0.188 0.578 \u03b10(Percent Unemployed 2018 ) -0.701 -0.011 0.366 0.689 1.52 \u03b10(Percent living under the federal poverty line 2018 ) -0.774 -0.449 -0.282 -0.117 0.195 \u03b10(Percent at risk for serious illness due to COVID) 0.0428 0.165 0.237 0.3 0.445 \u03c3R 0.612 0.719 0.757 0.782 0.81 \u03c3k 4.22e-5 0.00032 0.000757 0.00127 0.00261 \u03c1 0.924 0.933 0.938 0.942 0.949 \u03b1(constant) -0.425 2.14 3.21 4.41 7.23 \u03b1(logpopdens) 0.0766 0.327 0.454 0.575 0.847 \u03b1(Percent Unemployed 2018 ) -0.769 -0.287 -0.0633 0.157 0.525 \u03b1(Percent living under the federal poverty line 2018 ) -0.26 -0.0831 0.0249 0.119 0.309 \u03b1(Percent at risk for serious illness due to COVID) -0.238 -0.14 -0.0983 -0.0538 0.034 \u03b1(Stay at home shelter in place lagged) -1.59 -1.2 -0.999 -0.766 -0.239 \u03b1(Date closed K 12 schools lagged) -0.124 0.452 0.739 1.03 1.49 \u03b1(Closed movie theaters lagged) -0.995 -0.465 -0.1 0.277 0.786 \u03b1(Closed non essential businesses lagged) -1.46 -1.06 -0.787 -0.493 0.0742 \u03b1(Closed restaurants except take out lagged) -1.12 -0.449 -0.0767 0.242 0.922 Policies lagged by = 0 \u00b6 parameters mean std naive_se mcse ess r_hat \u03b3 0.0402 0.00507 0.000113 0.000436 169.0 1.01 \u03c3R0 2.48 0.349 0.00781 0.0256 213.0 1.0 \u03b10(constant) 0.107 2.5 0.0559 0.162 228.0 1.0 \u03b10(logpopdens) -0.0728 0.339 0.00757 0.0216 189.0 1.0 \u03b10(Percent Unemployed 2018 ) 0.488 0.597 0.0134 0.0262 217.0 1.0 \u03b10(Percent living under the federal poverty line 2018 ) -0.229 0.252 0.00565 0.0141 227.0 1.0 \u03b10(Percent at risk for serious illness due to COVID) 0.202 0.107 0.0024 0.00658 220.0 1.0 \u03c3R 0.722 0.0728 0.00163 0.00624 153.0 1.01 \u03c3k 0.000993 0.000685 1.53e-5 4.97e-5 234.0 1.0 \u03c1 0.938 0.00623 0.000139 0.000368 225.0 1.0 \u03b1(constant) 2.73 2.05 0.0458 0.154 158.0 1.01 \u03b1(logpopdens) 0.446 0.2 0.00448 0.0117 247.0 1.0 \u03b1(Percent Unemployed 2018 ) -0.162 0.381 0.00853 0.023 195.0 1.0 \u03b1(Percent living under the federal poverty line 2018 ) 0.0235 0.159 0.00356 0.00895 161.0 1.0 \u03b1(Percent at risk for serious illness due to COVID) -0.0649 0.0702 0.00157 0.00427 211.0 1.0 \u03b1(Stay at home shelter in place lagged) -1.45 0.348 0.00779 0.0205 254.0 1.0 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0358 0.0368 0.0387 0.0417 0.0539 \u03c3R0 1.77 2.25 2.47 2.71 3.16 \u03b10(constant) -4.6 -1.68 0.101 1.88 4.92 \u03b10(logpopdens) -0.667 -0.32 -0.095 0.16 0.601 \u03b10(Percent Unemployed 2018 ) -0.681 0.0772 0.488 0.93 1.59 \u03b10(Percent living under the federal poverty line 2018 ) -0.682 -0.41 -0.24 -0.0492 0.254 \u03b10(Percent at risk for serious illness due to COVID) -0.00405 0.132 0.197 0.271 0.42 \u03c3R 0.53 0.686 0.741 0.776 0.807 \u03c3k 6.6e-5 0.000456 0.000867 0.00141 0.00261 \u03c1 0.926 0.934 0.938 0.943 0.95 \u03b1(constant) -1.42 1.32 2.86 4.11 6.37 \u03b1(logpopdens) 0.0625 0.31 0.446 0.588 0.836 \u03b1(Percent Unemployed 2018 ) -0.972 -0.415 -0.158 0.0836 0.62 \u03b1(Percent living under the federal poverty line 2018 ) -0.258 -0.0907 0.0203 0.128 0.373 \u03b1(Percent at risk for serious illness due to COVID) -0.198 -0.115 -0.0643 -0.0155 0.0645 \u03b1(Stay at home shelter in place lagged) -2.07 -1.71 -1.45 -1.22 -0.771 Policies lagged by = 7 \u00b6 parameters mean std naive_se mcse ess r_hat \u03b3 0.0386 0.00282 6.3e-5 0.000159 195.0 1.0 \u03c3R0 2.6 0.315 0.00705 0.0214 192.0 1.0 \u03b10(constant) -0.0042 2.72 0.0608 0.186 206.0 1.0 \u03b10(logpopdens) -0.126 0.339 0.00757 0.024 171.0 1.0 \u03b10(Percent Unemployed 2018 ) 0.316 0.589 0.0132 0.04 211.0 1.0 \u03b10(Percent living under the federal poverty line 2018 ) -0.182 0.244 0.00545 0.0174 269.0 1.0 \u03b10(Percent at risk for serious illness due to COVID) 0.151 0.103 0.0023 0.00699 264.0 1.0 \u03c3R 0.741 0.0491 0.0011 0.00262 185.0 1.0 \u03c3k 0.000929 0.000686 1.53e-5 3.5e-5 370.0 1.01 \u03c1 0.918 0.0095 0.000212 0.000705 201.0 1.0 \u03b1(constant) 3.44 1.62 0.0361 0.153 147.0 1.0 \u03b1(logpopdens) 0.437 0.144 0.00322 0.00916 218.0 1.01 \u03b1(Percent Unemployed 2018 ) 0.036 0.265 0.00593 0.0149 259.0 1.01 \u03b1(Percent living under the federal poverty line 2018 ) -0.0125 0.11 0.00246 0.00795 196.0 1.01 \u03b1(Percent at risk for serious illness due to COVID) -0.0234 0.0588 0.00132 0.00374 207.0 1.0 \u03b1(Stay at home shelter in place lagged) -0.798 0.337 0.00754 0.03 157.0 1.0 \u03b1(Date closed K 12 schools lagged) -1.32 0.398 0.0089 0.0382 131.0 1.0 \u03b1(Closed movie theaters lagged) -0.504 0.427 0.00955 0.0269 178.0 1.0 \u03b1(Closed non essential businesses lagged) -0.56 0.352 0.00788 0.0207 190.0 1.01 \u03b1(Closed restaurants except take out lagged) -0.621 0.439 0.00981 0.0269 213.0 1.0 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0358 0.0366 0.0378 0.0396 0.0465 \u03c3R0 1.99 2.39 2.59 2.82 3.19 \u03b10(constant) -5.16 -1.86 -0.0926 1.7 5.75 \u03b10(logpopdens) -0.801 -0.348 -0.132 0.0953 0.544 \u03b10(Percent Unemployed 2018 ) -0.819 -0.09 0.305 0.717 1.54 \u03b10(Percent living under the federal poverty line 2018 ) -0.704 -0.35 -0.171 -0.016 0.246 \u03b10(Percent at risk for serious illness due to COVID) -0.0448 0.0836 0.153 0.216 0.352 \u03c3R 0.613 0.717 0.753 0.776 0.805 \u03c3k 4.81e-5 0.00038 0.000766 0.00132 0.00253 \u03c1 0.899 0.912 0.918 0.925 0.937 \u03b1(constant) 0.133 2.38 3.48 4.63 6.41 \u03b1(logpopdens) 0.146 0.347 0.435 0.527 0.728 \u03b1(Percent Unemployed 2018 ) -0.506 -0.131 0.0376 0.23 0.537 \u03b1(Percent living under the federal poverty line 2018 ) -0.212 -0.0911 -0.0175 0.061 0.208 \u03b1(Percent at risk for serious illness due to COVID) -0.136 -0.0631 -0.0226 0.0163 0.0928 \u03b1(Stay at home shelter in place lagged) -1.48 -1.02 -0.807 -0.565 -0.188 \u03b1(Date closed K 12 schools lagged) -2.09 -1.58 -1.34 -1.07 -0.475 \u03b1(Closed movie theaters lagged) -1.31 -0.808 -0.513 -0.198 0.297 \u03b1(Closed non essential businesses lagged) -1.25 -0.796 -0.559 -0.306 0.0925 \u03b1(Closed restaurants except take out lagged) -1.57 -0.904 -0.595 -0.331 0.195 Policies lagged by = 7 \u00b6 parameters mean std naive_se mcse ess r_hat \u03b3 0.0408 0.00545 0.000122 0.000382 166.0 1.0 \u03c3R0 2.5 0.358 0.00801 0.0207 229.0 1.0 \u03b10(constant) 0.549 2.73 0.0611 0.148 344.0 1.0 \u03b10(logpopdens) -0.079 0.34 0.0076 0.0107 354.0 1.0 \u03b10(Percent Unemployed 2018 ) 0.58 0.59 0.0132 0.033 308.0 1.0 \u03b10(Percent living under the federal poverty line 2018 ) -0.256 0.25 0.00558 0.0124 272.0 1.0 \u03b10(Percent at risk for serious illness due to COVID) 0.199 0.11 0.00245 0.00649 248.0 1.0 \u03c3R 0.715 0.0787 0.00176 0.00576 162.0 1.0 \u03c3k 0.000933 0.000678 1.52e-5 2.56e-5 498.0 1.0 \u03c1 0.937 0.0062 0.000139 0.000278 483.0 1.0 \u03b1(constant) 3.31 1.95 0.0436 0.114 359.0 1.0 \u03b1(logpopdens) 0.453 0.199 0.00444 0.00688 402.0 1.0 \u03b1(Percent Unemployed 2018 ) -0.335 0.332 0.00742 0.0186 297.0 1.0 \u03b1(Percent living under the federal poverty line 2018 ) 0.0898 0.133 0.00298 0.00659 307.0 1.0 \u03b1(Percent at risk for serious illness due to COVID) -0.0957 0.0663 0.00148 0.00402 288.0 1.0 \u03b1(Stay at home shelter in place lagged) -0.882 0.309 0.00691 0.018 211.0 1.0 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0358 0.0371 0.0391 0.0424 0.0558 \u03c3R0 1.75 2.27 2.51 2.73 3.16 \u03b10(constant) -5.06 -1.17 0.583 2.34 5.91 \u03b10(logpopdens) -0.765 -0.287 -0.0805 0.133 0.58 \u03b10(Percent Unemployed 2018 ) -0.514 0.154 0.587 0.984 1.72 \u03b10(Percent living under the federal poverty line 2018 ) -0.79 -0.416 -0.244 -0.09 0.228 \u03b10(Percent at risk for serious illness due to COVID) -0.0124 0.121 0.196 0.279 0.404 \u03c3R 0.515 0.677 0.735 0.775 0.813 \u03c3k 4.58e-5 0.000401 0.000802 0.00132 0.00254 \u03c1 0.924 0.933 0.937 0.941 0.949 \u03b1(constant) -0.589 2.04 3.42 4.63 6.85 \u03b1(logpopdens) 0.0661 0.309 0.454 0.594 0.818 \u03b1(Percent Unemployed 2018 ) -1.01 -0.557 -0.324 -0.109 0.3 \u03b1(Percent living under the federal poverty line 2018 ) -0.144 -0.0046 0.0858 0.172 0.361 \u03b1(Percent at risk for serious illness due to COVID) -0.221 -0.141 -0.0952 -0.0519 0.0336 \u03b1(Stay at home shelter in place lagged) -1.52 -1.1 -0.874 -0.666 -0.335","title":"Only policies"},{"location":"rt_onlyp/#results","text":"## data prep using CovidData Error: importing CovidData into Main conflicts with an existing identifier using CovidRt Error: importing CovidRt into Main conflicts with an existing identifier using TransformVariables, Parameters, Plots, StatsPlots, DataFrames, Dates, LinearAlgebra, Distributions, Random, LogDensityProblems, DynamicHMC, MCMCChains, JLD2, Latexify Plots.pyplot() df = CovidData.statedata(policies=:indicators, fillmissingmobility=true) df[!,:log_encounters_rate] = log.(1 .+ df[!,:encounters_rate]) pvars = [Symbol(\"Stay.at.home..shelter.in.place\"), Symbol(\"State.of.emergency\"), Symbol(\"Date.closed.K.12.schools\"), Symbol(\"Closed.gyms\"), Symbol(\"Closed.movie.theaters\"), Symbol(\"Closed.day.cares\"), Symbol(\"Date.banned.visitors.to.nursing.homes\"), Symbol(\"Closed.non.essential.businesses\"), Symbol(\"Closed.restaurants.except.take.out\")] mvars = [:retail_and_recreation_percent_change_from_baseline, :grocery_and_pharmacy_percent_change_from_baseline, :parks_percent_change_from_baseline , :transit_stations_percent_change_from_baseline, :workplaces_percent_change_from_baseline, :residential_percent_change_from_baseline, :percentchangehours, :percentchangebusinesses, :daily_distance_diff, :daily_visitation_diff, :log_encounters_rate] df[!,:logpopdens] = log.(df[!,Symbol(\"Population.density.per.square.miles\")]) df[!,:weekend] = dayofweek.(df[!,:date]) .>= 6 x0vars=[:constant, :logpopdens, Symbol(\"Percent.Unemployed..2018.\"), Symbol(\"Percent.living.under.the.federal.poverty.line..2018.\"), Symbol(\"Percent.at.risk.for.serious.illness.due.to.COVID\")] sdf = filter(x->x.fips<60, df) sdf = sort(sdf, (:state, :date)) sdf[!,mvars] ./= 100 sdf[!,:constant] .= 1 2845-element Array{Int64,1}: 1 1 1 1 1 1 1 1 1 1 \u22ee 1 1 1 1 1 1 1 1 1 Here, we will allow the initial and time varying mean of $R_{s,t}$ to depend on covariates. We will include only the policy related covariates and the non time-varying ones. \\begin{align*} \\tilde{R}_{s,0} & \\sim N(X_{0,s} \\alpha_0, \\sigma^2_{R,0}) \\\\ \\tilde{R}_{s,t} & = \\rho \\tilde{R}_{s,t} + u_{s,t} \\;,\\; u_{s,t} \\sim N(0, \\sigma^2_R) \\\\ R_{s,t} & = X_{s,t} \\alpha + \\tilde{R}_{s,t} \\\\ \\Delta \\log(k)_{s,t} & = \\gamma (R_{s,t} - 1) + \\epsilon_{s,t} - \\epsilon_{s,t-1} \\;, \\; \\epsilon_{s,t} \\sim N(0, \\sigma^2_k) \\end{align*} In computing $\\Delta \\log \\Delta C$, we take backward differences of length 7, so (\\Delta \\log \\Delta C)[t] = \\log (C_t - C_{t-7}) - \\log(C_{t-7} - C_{t-14}) This means that our time $t$ outcome is reflects the average reproductive number from time $t-7$ to $t$. For $X_{s,t}$ we use the moving average of the policy indicator variables from time $t-7-L$ to $t-14-L$, and we try a few different values of $L$. reestimate=true xvarsets = [ vcat(x0vars, Symbol(\"Stay.at.home..shelter.in.place_lagged\"), Symbol(\"Date.closed.K.12.schools_lagged\"), Symbol(\"Closed.movie.theaters_lagged\"), Symbol(\"Closed.non.essential.businesses_lagged\"), Symbol(\"Closed.restaurants.except.take.out_lagged\")) , vcat(x0vars, Symbol(\"Stay.at.home..shelter.in.place_lagged\")) ] rlo=-1 rhi=1.1 states_to_plot = [\"New York\", \"New Jersey\",\"Massachusetts\",\"California\", \"Georgia\",\"Illinois\",\"Michigan\", \"Ohio\",\"Wisconsin\",\"Washington\"] warmup = default_warmup_stages(local_optimization=FindLocalOptimum(1e-4, 100), stepsize_search=nothing, init_steps=100, middle_steps=100, terminating_steps=2*100, doubling_stages=4, M=Symmetric) for L in [0, 7] for xvars in xvarsets K = length(xvars) priors = (\u03b3 = truncated(Normal(1/7,1/7), 1/28, 1/1), \u03c3R0 = truncated(Normal(1, 3), 0, Inf), \u03b10 = MvNormal(zeros(length(x0vars)), sqrt(10)), #truncated(Normal(1, 3), 0, Inf), \u03c3R = truncated(Normal(0.25,1),0,Inf), \u03c3k = truncated(Normal(0.1, 5), 0, Inf), \u03c1 = Uniform(rlo, rhi), \u03b1 = MvNormal(zeros(K), sqrt(10)) ) estfile = \"rt_onlyp_$(L)_x$(K).jld2\" w = vcat(ones(7), zeros(1+2*L+7)) sort!(sdf, (:state, :date)) for v in pvars newv = Symbol(string(v)*\"_lagged\") sdf[!,newv] = Float64.(sdf[!,v]) for gdf in groupby(sdf, :state) gdf[:, newv] .= CovidRt.smooth(gdf[:,v], w=w) end end mdl = CovidRt.RtModel(sdf, Symbol(\"cases.nyt\"), xvars, x0vars, priors; L1=7, L2=7, time0=r->(r[Symbol(\"cases.nyt\")].>=5)) if !isfile(estfile) || reestimate post = CovidRt.mcmc(mdl; iterations=2000, warmup=warmup) @save estfile post end @load estfile post cc = CovidRt.MCMCChain(post, xvars, x0vars) println(\"## Policies lagged by = $(L)\") println() display(plot(cc)) println(latexify(DataFrame(describe(cc)[1]), env=:mdtable, latex=false, fmt=x->round(x, sigdigits=3))) println(latexify(DataFrame(describe(cc)[2]), env=:mdtable, latex=false, fmt=x->round(x, sigdigits=3))) states = mdl.id S = length(states_to_plot) figs = fill(plot(), S) for (i,st) in enumerate(states_to_plot) s = findfirst(states.==st) figr = CovidRt.plotpostr(mdl.t[s],mdl.dlogk[s],post, mdl.X[s], mdl.X0[s]) l = @layout [a{.1h}; grid(1,1)] figs[i] = plot(plot(annotation=(0.5,0.5, st*\", L=$(L) nx=$(K)\"), framestyle = :none), plot(figr, ylim=(-1,15)), layout=l) display(figs[i]) end end end","title":"Results"},{"location":"rt_onlyp/#policies-lagged-by-0","text":"parameters mean std naive_se mcse ess r_hat \u03b3 0.0387 0.00296 6.62e-5 0.000227 210.0 1.0 \u03c3R0 2.56 0.304 0.00681 0.0237 163.0 1.0 \u03b10(constant) 0.397 2.75 0.0616 0.214 122.0 1.0 \u03b10(logpopdens) -0.0609 0.342 0.00764 0.0317 103.0 1.02 \u03b10(Percent Unemployed 2018 ) 0.357 0.551 0.0123 0.0552 64.9 1.0 \u03b10(Percent living under the federal poverty line 2018 ) -0.284 0.25 0.0056 0.0218 128.0 1.0 \u03b10(Percent at risk for serious illness due to COVID) 0.236 0.102 0.00229 0.00775 123.0 1.0 \u03c3R 0.744 0.0517 0.00116 0.00389 211.0 1.0 \u03c3k 0.000889 0.000694 1.55e-5 6.91e-5 93.4 1.0 \u03c1 0.937 0.00636 0.000142 0.000469 169.0 1.0 \u03b1(constant) 3.26 1.84 0.0412 0.166 112.0 1.01 \u03b1(logpopdens) 0.456 0.192 0.0043 0.021 86.2 1.01 \u03b1(Percent Unemployed 2018 ) -0.0754 0.334 0.00747 0.0363 69.6 1.05 \u03b1(Percent living under the federal poverty line 2018 ) 0.0195 0.147 0.00328 0.0141 97.7 1.03 \u03b1(Percent at risk for serious illness due to COVID) -0.0981 0.068 0.00152 0.00537 112.0 1.01 \u03b1(Stay at home shelter in place lagged) -0.977 0.345 0.00771 0.0292 150.0 1.0 \u03b1(Date closed K 12 schools lagged) 0.733 0.418 0.00934 0.0366 107.0 1.0 \u03b1(Closed movie theaters lagged) -0.0981 0.49 0.0109 0.0504 99.6 1.03 \u03b1(Closed non essential businesses lagged) -0.764 0.412 0.00921 0.0451 110.0 1.0 \u03b1(Closed restaurants except take out lagged) -0.101 0.513 0.0115 0.0565 93.4 1.02 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0358 0.0366 0.0378 0.0398 0.0467 \u03c3R0 1.98 2.35 2.56 2.75 3.23 \u03b10(constant) -5.25 -1.65 0.441 2.38 5.66 \u03b10(logpopdens) -0.766 -0.296 -0.0638 0.188 0.578 \u03b10(Percent Unemployed 2018 ) -0.701 -0.011 0.366 0.689 1.52 \u03b10(Percent living under the federal poverty line 2018 ) -0.774 -0.449 -0.282 -0.117 0.195 \u03b10(Percent at risk for serious illness due to COVID) 0.0428 0.165 0.237 0.3 0.445 \u03c3R 0.612 0.719 0.757 0.782 0.81 \u03c3k 4.22e-5 0.00032 0.000757 0.00127 0.00261 \u03c1 0.924 0.933 0.938 0.942 0.949 \u03b1(constant) -0.425 2.14 3.21 4.41 7.23 \u03b1(logpopdens) 0.0766 0.327 0.454 0.575 0.847 \u03b1(Percent Unemployed 2018 ) -0.769 -0.287 -0.0633 0.157 0.525 \u03b1(Percent living under the federal poverty line 2018 ) -0.26 -0.0831 0.0249 0.119 0.309 \u03b1(Percent at risk for serious illness due to COVID) -0.238 -0.14 -0.0983 -0.0538 0.034 \u03b1(Stay at home shelter in place lagged) -1.59 -1.2 -0.999 -0.766 -0.239 \u03b1(Date closed K 12 schools lagged) -0.124 0.452 0.739 1.03 1.49 \u03b1(Closed movie theaters lagged) -0.995 -0.465 -0.1 0.277 0.786 \u03b1(Closed non essential businesses lagged) -1.46 -1.06 -0.787 -0.493 0.0742 \u03b1(Closed restaurants except take out lagged) -1.12 -0.449 -0.0767 0.242 0.922","title":"Policies lagged by = 0"},{"location":"rt_onlyp/#policies-lagged-by-0_1","text":"parameters mean std naive_se mcse ess r_hat \u03b3 0.0402 0.00507 0.000113 0.000436 169.0 1.01 \u03c3R0 2.48 0.349 0.00781 0.0256 213.0 1.0 \u03b10(constant) 0.107 2.5 0.0559 0.162 228.0 1.0 \u03b10(logpopdens) -0.0728 0.339 0.00757 0.0216 189.0 1.0 \u03b10(Percent Unemployed 2018 ) 0.488 0.597 0.0134 0.0262 217.0 1.0 \u03b10(Percent living under the federal poverty line 2018 ) -0.229 0.252 0.00565 0.0141 227.0 1.0 \u03b10(Percent at risk for serious illness due to COVID) 0.202 0.107 0.0024 0.00658 220.0 1.0 \u03c3R 0.722 0.0728 0.00163 0.00624 153.0 1.01 \u03c3k 0.000993 0.000685 1.53e-5 4.97e-5 234.0 1.0 \u03c1 0.938 0.00623 0.000139 0.000368 225.0 1.0 \u03b1(constant) 2.73 2.05 0.0458 0.154 158.0 1.01 \u03b1(logpopdens) 0.446 0.2 0.00448 0.0117 247.0 1.0 \u03b1(Percent Unemployed 2018 ) -0.162 0.381 0.00853 0.023 195.0 1.0 \u03b1(Percent living under the federal poverty line 2018 ) 0.0235 0.159 0.00356 0.00895 161.0 1.0 \u03b1(Percent at risk for serious illness due to COVID) -0.0649 0.0702 0.00157 0.00427 211.0 1.0 \u03b1(Stay at home shelter in place lagged) -1.45 0.348 0.00779 0.0205 254.0 1.0 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0358 0.0368 0.0387 0.0417 0.0539 \u03c3R0 1.77 2.25 2.47 2.71 3.16 \u03b10(constant) -4.6 -1.68 0.101 1.88 4.92 \u03b10(logpopdens) -0.667 -0.32 -0.095 0.16 0.601 \u03b10(Percent Unemployed 2018 ) -0.681 0.0772 0.488 0.93 1.59 \u03b10(Percent living under the federal poverty line 2018 ) -0.682 -0.41 -0.24 -0.0492 0.254 \u03b10(Percent at risk for serious illness due to COVID) -0.00405 0.132 0.197 0.271 0.42 \u03c3R 0.53 0.686 0.741 0.776 0.807 \u03c3k 6.6e-5 0.000456 0.000867 0.00141 0.00261 \u03c1 0.926 0.934 0.938 0.943 0.95 \u03b1(constant) -1.42 1.32 2.86 4.11 6.37 \u03b1(logpopdens) 0.0625 0.31 0.446 0.588 0.836 \u03b1(Percent Unemployed 2018 ) -0.972 -0.415 -0.158 0.0836 0.62 \u03b1(Percent living under the federal poverty line 2018 ) -0.258 -0.0907 0.0203 0.128 0.373 \u03b1(Percent at risk for serious illness due to COVID) -0.198 -0.115 -0.0643 -0.0155 0.0645 \u03b1(Stay at home shelter in place lagged) -2.07 -1.71 -1.45 -1.22 -0.771","title":"Policies lagged by = 0"},{"location":"rt_onlyp/#policies-lagged-by-7","text":"parameters mean std naive_se mcse ess r_hat \u03b3 0.0386 0.00282 6.3e-5 0.000159 195.0 1.0 \u03c3R0 2.6 0.315 0.00705 0.0214 192.0 1.0 \u03b10(constant) -0.0042 2.72 0.0608 0.186 206.0 1.0 \u03b10(logpopdens) -0.126 0.339 0.00757 0.024 171.0 1.0 \u03b10(Percent Unemployed 2018 ) 0.316 0.589 0.0132 0.04 211.0 1.0 \u03b10(Percent living under the federal poverty line 2018 ) -0.182 0.244 0.00545 0.0174 269.0 1.0 \u03b10(Percent at risk for serious illness due to COVID) 0.151 0.103 0.0023 0.00699 264.0 1.0 \u03c3R 0.741 0.0491 0.0011 0.00262 185.0 1.0 \u03c3k 0.000929 0.000686 1.53e-5 3.5e-5 370.0 1.01 \u03c1 0.918 0.0095 0.000212 0.000705 201.0 1.0 \u03b1(constant) 3.44 1.62 0.0361 0.153 147.0 1.0 \u03b1(logpopdens) 0.437 0.144 0.00322 0.00916 218.0 1.01 \u03b1(Percent Unemployed 2018 ) 0.036 0.265 0.00593 0.0149 259.0 1.01 \u03b1(Percent living under the federal poverty line 2018 ) -0.0125 0.11 0.00246 0.00795 196.0 1.01 \u03b1(Percent at risk for serious illness due to COVID) -0.0234 0.0588 0.00132 0.00374 207.0 1.0 \u03b1(Stay at home shelter in place lagged) -0.798 0.337 0.00754 0.03 157.0 1.0 \u03b1(Date closed K 12 schools lagged) -1.32 0.398 0.0089 0.0382 131.0 1.0 \u03b1(Closed movie theaters lagged) -0.504 0.427 0.00955 0.0269 178.0 1.0 \u03b1(Closed non essential businesses lagged) -0.56 0.352 0.00788 0.0207 190.0 1.01 \u03b1(Closed restaurants except take out lagged) -0.621 0.439 0.00981 0.0269 213.0 1.0 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0358 0.0366 0.0378 0.0396 0.0465 \u03c3R0 1.99 2.39 2.59 2.82 3.19 \u03b10(constant) -5.16 -1.86 -0.0926 1.7 5.75 \u03b10(logpopdens) -0.801 -0.348 -0.132 0.0953 0.544 \u03b10(Percent Unemployed 2018 ) -0.819 -0.09 0.305 0.717 1.54 \u03b10(Percent living under the federal poverty line 2018 ) -0.704 -0.35 -0.171 -0.016 0.246 \u03b10(Percent at risk for serious illness due to COVID) -0.0448 0.0836 0.153 0.216 0.352 \u03c3R 0.613 0.717 0.753 0.776 0.805 \u03c3k 4.81e-5 0.00038 0.000766 0.00132 0.00253 \u03c1 0.899 0.912 0.918 0.925 0.937 \u03b1(constant) 0.133 2.38 3.48 4.63 6.41 \u03b1(logpopdens) 0.146 0.347 0.435 0.527 0.728 \u03b1(Percent Unemployed 2018 ) -0.506 -0.131 0.0376 0.23 0.537 \u03b1(Percent living under the federal poverty line 2018 ) -0.212 -0.0911 -0.0175 0.061 0.208 \u03b1(Percent at risk for serious illness due to COVID) -0.136 -0.0631 -0.0226 0.0163 0.0928 \u03b1(Stay at home shelter in place lagged) -1.48 -1.02 -0.807 -0.565 -0.188 \u03b1(Date closed K 12 schools lagged) -2.09 -1.58 -1.34 -1.07 -0.475 \u03b1(Closed movie theaters lagged) -1.31 -0.808 -0.513 -0.198 0.297 \u03b1(Closed non essential businesses lagged) -1.25 -0.796 -0.559 -0.306 0.0925 \u03b1(Closed restaurants except take out lagged) -1.57 -0.904 -0.595 -0.331 0.195","title":"Policies lagged by = 7"},{"location":"rt_onlyp/#policies-lagged-by-7_1","text":"parameters mean std naive_se mcse ess r_hat \u03b3 0.0408 0.00545 0.000122 0.000382 166.0 1.0 \u03c3R0 2.5 0.358 0.00801 0.0207 229.0 1.0 \u03b10(constant) 0.549 2.73 0.0611 0.148 344.0 1.0 \u03b10(logpopdens) -0.079 0.34 0.0076 0.0107 354.0 1.0 \u03b10(Percent Unemployed 2018 ) 0.58 0.59 0.0132 0.033 308.0 1.0 \u03b10(Percent living under the federal poverty line 2018 ) -0.256 0.25 0.00558 0.0124 272.0 1.0 \u03b10(Percent at risk for serious illness due to COVID) 0.199 0.11 0.00245 0.00649 248.0 1.0 \u03c3R 0.715 0.0787 0.00176 0.00576 162.0 1.0 \u03c3k 0.000933 0.000678 1.52e-5 2.56e-5 498.0 1.0 \u03c1 0.937 0.0062 0.000139 0.000278 483.0 1.0 \u03b1(constant) 3.31 1.95 0.0436 0.114 359.0 1.0 \u03b1(logpopdens) 0.453 0.199 0.00444 0.00688 402.0 1.0 \u03b1(Percent Unemployed 2018 ) -0.335 0.332 0.00742 0.0186 297.0 1.0 \u03b1(Percent living under the federal poverty line 2018 ) 0.0898 0.133 0.00298 0.00659 307.0 1.0 \u03b1(Percent at risk for serious illness due to COVID) -0.0957 0.0663 0.00148 0.00402 288.0 1.0 \u03b1(Stay at home shelter in place lagged) -0.882 0.309 0.00691 0.018 211.0 1.0 parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u03b3 0.0358 0.0371 0.0391 0.0424 0.0558 \u03c3R0 1.75 2.27 2.51 2.73 3.16 \u03b10(constant) -5.06 -1.17 0.583 2.34 5.91 \u03b10(logpopdens) -0.765 -0.287 -0.0805 0.133 0.58 \u03b10(Percent Unemployed 2018 ) -0.514 0.154 0.587 0.984 1.72 \u03b10(Percent living under the federal poverty line 2018 ) -0.79 -0.416 -0.244 -0.09 0.228 \u03b10(Percent at risk for serious illness due to COVID) -0.0124 0.121 0.196 0.279 0.404 \u03c3R 0.515 0.677 0.735 0.775 0.813 \u03c3k 4.58e-5 0.000401 0.000802 0.00132 0.00254 \u03c1 0.924 0.933 0.937 0.941 0.949 \u03b1(constant) -0.589 2.04 3.42 4.63 6.85 \u03b1(logpopdens) 0.0661 0.309 0.454 0.594 0.818 \u03b1(Percent Unemployed 2018 ) -1.01 -0.557 -0.324 -0.109 0.3 \u03b1(Percent living under the federal poverty line 2018 ) -0.144 -0.0046 0.0858 0.172 0.361 \u03b1(Percent at risk for serious illness due to COVID) -0.221 -0.141 -0.0952 -0.0519 0.0336 \u03b1(Stay at home shelter in place lagged) -1.52 -1.1 -0.874 -0.666 -0.335","title":"Policies lagged by = 7"}]}